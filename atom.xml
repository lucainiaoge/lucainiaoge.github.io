<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Lucainiao&#39;s blog</title>
  
  <subtitle>coding&amp;music</subtitle>
  <link href="https://lucainiaoge.github.io.git/atom.xml" rel="self"/>
  
  <link href="https://lucainiaoge.github.io.git/"/>
  <updated>2025-11-12T09:43:52.030Z</updated>
  <id>https://lucainiaoge.github.io.git/</id>
  
  <author>
    <name>lucainiaoge</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Welcome! I am Tongyu Lu! 我是路通宇!</title>
    <link href="https://lucainiaoge.github.io.git/2025/11/11/personal-page/"/>
    <id>https://lucainiaoge.github.io.git/2025/11/11/personal-page/</id>
    <published>2025-11-10T16:00:00.000Z</published>
    <updated>2025-11-12T09:43:52.030Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><div id="content"></div><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script><h1 id="About-Me"><a href="#About-Me" class="headerlink" title="About Me"></a>About Me</h1><ul><li>Currently working at Singapore University of Technology and Design (SUTD) as a Ph.D student at ISTD</li><li>Graduated from ETH Zürich as a master student in Electronic Engineering and Information Technology program</li><li>I am interested in music informatics, including automatic music transcription, music generation and computational musicology</li><li>I am an amateur composer</li></ul><p><img src="https://s2.loli.net/2025/11/11/94hlpsAgiRPwCF1.jpg" alt="me_in_sapporo.jpeg"><br><font color=gray> My photo in Sapporo </font></p><div style='display: none'>![me.jpg](https://i.loli.net/2020/07/18/Y9hEZvTqo8Fe4bD.jpg)</div><h1 id="Projects"><a href="#Projects" class="headerlink" title="Projects"></a>Projects</h1><ul><li><p>MelodySim, a similar-music dataset augmented from Slakh2100 dataset, along with a triplet neural network that fits well on this dataset (<a href="https://github.com/AMAAI-Lab/MelodySim">Github</a>|<a href="https://arxiv.org/abs/2505.20979">Paper</a>)</p></li><li><p>DiscoDiff, a coarse-to-fine latent diffusion model architecture that generate coarse RVQ code as the first step and predicts the fine RVQ codes as the final step. (<a href="https://github.com/ETH-DISCO/discodiff">Github</a>|<a href="https://openreview.net/forum?id=19Ukgqdlfg">Paper</a>)</p></li><li><p>A piano hammer-string-soundboard physics-based model simulation (<a href="https://github.com/lucainiaoge/piano-physics-model">Github</a>)</p></li><li><p>MIDI melody track identification (<a href="https://github.com/lucainiaoge/midi-melody-identification">Github</a>)</p></li><li><p>Note-level automatic music transcription (AMT) by Single-chord Fourier Approximation (<a href="https://github.com/lucainiaoge/note-level-amt-basics">Github</a>), a model-based AMT pipeline which has high performance on transcribing linear instruments.</p></li><li><p>Jazzify (<a href="https://github.com/lucainiaoge/jazzify">Github</a>), an open-source rule-based computational musicology system, which is able to detect chord symbols and keys given chord sequence, and generate jazz-style comping.</p></li></ul><h1 id="Music-Work-Selections"><a href="#Music-Work-Selections" class="headerlink" title="Music Work Selections"></a>Music Work Selections</h1><p>I heve kept composing since 2017, and I started learning Jazz since 2021. My works are mostly Jazz (all styles including swing, ballad, latin, funk etc.) and Classical (chamber music, piano solos, orchistral works), along with some adaptations. Here are some selections. <font color=gray > You can find my music collections in my <a href="https://www.youtube.com/channel/UCQ0pDpWcvyYdInvml4cyOgA">YouTube Channel</a>, <a href="https://space.bilibili.com/314174825/video">Bilibili Personal Page</a>, <a href="https://soundcloud.com/lu-tongyu">SoundCloud Personal Page</a> or <a href="https://music.163.com/#/artist/album?id=31150711">Netease Music (网易云音乐) Personal Page</a></font></p><blockquote><ul><li><strong>Waltz Unfrozen</strong>, a jazz waltz; Links <a href="https://youtu.be/3hf1aaWI6CQ">Youtube</a> | <a href="https://www.bilibili.com/video/BV18DxrzSETd">Bilibili</a></li></ul></blockquote><iframe data-testid="embed-iframe" style="border-radius:12px" src="https://open.spotify.com/embed/track/0CKkOzBEQRb0ylYPnc3BtH?utm_source=generator" width="100%" height="152" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture" loading="lazy"></iframe><blockquote><ul><li><strong>Overload Mode</strong>, a fusion funk; Links <a href="https://youtu.be/En7ezm12vRI">Youtube</a> | <a href="https://www.bilibili.com/video/BV1jhRGYkEkD">Bilibili</a><iframe width="100%" height="166" scrolling="no" frameborder="no" allow="autoplay" src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/soundcloud%253Atracks%253A2051426896&color=%23ff5500&auto_play=false&hide_related=false&show_comments=true&show_user=true&show_reposts=false&show_teaser=true"></iframe><div style="font-size: 10px; color: #cccccc;line-break: anywhere;word-break: normal;overflow: hidden;white-space: nowrap;text-overflow: ellipsis; font-family: Interstate,Lucida Grande,Lucida Sans Unicode,Lucida Sans,Garuda,Verdana,Tahoma,sans-serif;font-weight: 100;"><a href="https://soundcloud.com/lu-tongyu" title="Lu Tongyu" target="_blank" style="color: #cccccc; text-decoration: none;">Lu Tongyu</a> · <a href="https://soundcloud.com/lu-tongyu/overload-mode" title="Overload Mode" target="_blank" style="color: #cccccc; text-decoration: none;">Overload Mode</a></div></li></ul></blockquote><blockquote><ul><li><strong>Sonata in e-flat minor</strong>, a piano Sonata in funk style; Links <a href="https://youtu.be/2jJC8d49OJg">Youtube</a> | <a href="https://www.bilibili.com/video/BV1CbJKzxEtU">Bilibili</a><iframe width="100%" height="166" scrolling="no" frameborder="no" allow="autoplay" src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/soundcloud%253Atracks%253A2186916918&color=%23ff5500&auto_play=false&hide_related=false&show_comments=true&show_user=true&show_reposts=false&show_teaser=true"></iframe><div style="font-size: 10px; color: #cccccc;line-break: anywhere;word-break: normal;overflow: hidden;white-space: nowrap;text-overflow: ellipsis; font-family: Interstate,Lucida Grande,Lucida Sans Unicode,Lucida Sans,Garuda,Verdana,Tahoma,sans-serif;font-weight: 100;"><a href="https://soundcloud.com/lu-tongyu" title="Lu Tongyu" target="_blank" style="color: #cccccc; text-decoration: none;">Lu Tongyu</a> · <a href="https://soundcloud.com/lu-tongyu/sonata-in-e-flat-minor" title="Sonata in e-flat minor" target="_blank" style="color: #cccccc; text-decoration: none;">Sonata in e-flat minor</a></div></li></ul></blockquote><blockquote><ul><li><strong>Jazz Trio: Cold Clean Autumn</strong>; Links: <a href="https://youtu.be/p4gObpic9LU">Youtube</a> | <a href="https://www.bilibili.com/video/BV1734y1p7ey">Bilibili</a><iframe width="100%" height="166" scrolling="no" frameborder="no" allow="autoplay" src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/1299397252&color=%23ff5500&auto_play=false&hide_related=false&show_comments=true&show_user=true&show_reposts=false&show_teaser=true"></iframe><div style="font-size: 10px; color: #cccccc;line-break: anywhere;word-break: normal;overflow: hidden;white-space: nowrap;text-overflow: ellipsis; font-family: Interstate,Lucida Grande,Lucida Sans Unicode,Lucida Sans,Garuda,Verdana,Tahoma,sans-serif;font-weight: 100;"><a href="https://soundcloud.com/lu-tongyu" title="Lu Tongyu" target="_blank" style="color: #cccccc; text-decoration: none;">Lu Tongyu</a> · <a href="https://soundcloud.com/lu-tongyu/cold-clean-autumn-tongyu-lu" title="Cold Clean Autumn" target="_blank" style="color: #cccccc; text-decoration: none;">Cold Clean Autumn</a></div></li></ul></blockquote><blockquote><ul><li><strong>Piano Work: Etude in F Major - Ripple</strong>; Links: <a href="https://youtu.be/EwTIvOlMl6s">Youtube</a> | <a href="https://www.bilibili.com/video/BV1ne4y1F7Wy">Bilibili</a><iframe width="100%" height="166" scrolling="no" frameborder="no" allow="autoplay" src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/1471950940&color=%23ff5500&auto_play=false&hide_related=false&show_comments=true&show_user=true&show_reposts=false&show_teaser=true"></iframe><div style="font-size: 10px; color: #cccccc;line-break: anywhere;word-break: normal;overflow: hidden;white-space: nowrap;text-overflow: ellipsis; font-family: Interstate,Lucida Grande,Lucida Sans Unicode,Lucida Sans,Garuda,Verdana,Tahoma,sans-serif;font-weight: 100;"><a href="https://soundcloud.com/lu-tongyu" title="Lu Tongyu" target="_blank" style="color: #cccccc; text-decoration: none;">Lu Tongyu</a> · <a href="https://soundcloud.com/lu-tongyu/etude-in-f-major-ripple" title="Etude in F Major - Ripple" target="_blank" style="color: #cccccc; text-decoration: none;">Etude in F Major - Ripple</a></div></li></ul></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;&#92;assets&#92;css&#92;APlayer.min.css&quot;&gt;&lt;script src=&quot;&#92;assets&#92;js&#92;APlayer.min.js&quot; cla</summary>
      
    
    
    
    
    <category term="blog_start" scheme="https://lucainiaoge.github.io.git/tags/blog-start/"/>
    
    <category term="introduction" scheme="https://lucainiaoge.github.io.git/tags/introduction/"/>
    
  </entry>
  
  <entry>
    <title>Backpropagation - More than Chain Rule</title>
    <link href="https://lucainiaoge.github.io.git/2021/10/04/Back_propagation/"/>
    <id>https://lucainiaoge.github.io.git/2021/10/04/Back_propagation/</id>
    <published>2021-10-03T16:00:00.000Z</published>
    <updated>2025-11-11T13:28:51.794Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><div id="content"></div><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script><p><font color=gray > Pre-requisites:</p><ol><li>Knowing multi-variable differentiation;</li><li>It is recommended that readers have known the concepts of directed graphs.</font></li></ol><p>This is my lecture note of the natural language processing (NLP) lecture in ETH Zurich. Lecturer: Ryan Cotterell. This lecture tells you what backpropagation algorithm really is.</p><span id="more"></span><p>Well, I have to say that it is surprising that backpropagation (BP) is taught in an NLP course instead of a machine learning course.</p><p>To view this article, please download:<br><a href="/download/Lecture_note1_BP.pdf">Lecture_note1_BP.pdf</a></p><p>If I have time, I will implement BP with Python without PyTorch.</p>]]></content>
    
    
    <summary type="html">&lt;div id=&quot;content&quot;&gt;&lt;/div&gt;
&lt;script type=&quot;text/javascript&quot; src=&quot;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default&quot;&gt;&lt;/script&gt;

&lt;p&gt;&lt;font color=gray &gt; Pre-requisites:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Knowing multi-variable differentiation;&lt;/li&gt;
&lt;li&gt;It is recommended that readers have known the concepts of directed graphs.&lt;/font&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This is my lecture note of the natural language processing (NLP) lecture in ETH Zurich. Lecturer: Ryan Cotterell. This lecture tells you what backpropagation algorithm really is.&lt;/p&gt;</summary>
    
    
    
    
    <category term="math" scheme="https://lucainiaoge.github.io.git/tags/math/"/>
    
  </entry>
  
  <entry>
    <title>Neural Network Theory Lecture Note 1 - Approximation Theorem</title>
    <link href="https://lucainiaoge.github.io.git/2021/09/22/Neural_network_theory_course_1/"/>
    <id>https://lucainiaoge.github.io.git/2021/09/22/Neural_network_theory_course_1/</id>
    <published>2021-09-21T16:00:00.000Z</published>
    <updated>2025-11-11T13:28:51.803Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><div id="content"></div><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script><p><font color=gray > Pre-requisites:</p><ol><li>It will be helpful to know some basic concept about functional analysis, e.g. linear functional, normed space, Hahn-Banach Theorem; anyway they will be explained in my note</li><li>Basic form of single-layer neural network.</font></li></ol><p>After the happy summer vacation, I have to attend the master program at ETH Zurich. This is my lecture note for my first course, Neural Network Theory, at ETH.</p><p>Lecturer: Prof. Helmut Elbrächter</p><p>This first note is about the capacity of a single-layer neural network in approximating an arbitrary function whose domain is in ${\rm \pmb{R}}^d$.</p><span id="more"></span><p>To view this note, please download:<br><a href="/download/NNT_note1_tongyulu.pdf">NNT_note1_tongyulu.pdf</a></p>]]></content>
    
    
    <summary type="html">&lt;div id=&quot;content&quot;&gt;&lt;/div&gt;
&lt;script type=&quot;text/javascript&quot; src=&quot;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default&quot;&gt;&lt;/script&gt;

&lt;p&gt;&lt;font color=gray &gt; Pre-requisites:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;It will be helpful to know some basic concept about functional analysis, e.g. linear functional, normed space, Hahn-Banach Theorem; anyway they will be explained in my note&lt;/li&gt;
&lt;li&gt;Basic form of single-layer neural network.&lt;/font&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;After the happy summer vacation, I have to attend the master program at ETH Zurich. This is my lecture note for my first course, Neural Network Theory, at ETH.&lt;/p&gt;
&lt;p&gt;Lecturer: Prof. Helmut Elbrächter&lt;/p&gt;
&lt;p&gt;This first note is about the capacity of a single-layer neural network in approximating an arbitrary function whose domain is in ${&#92;rm &#92;pmb{R}}^d$.&lt;/p&gt;</summary>
    
    
    
    
    <category term="math" scheme="https://lucainiaoge.github.io.git/tags/math/"/>
    
    <category term="neural_network" scheme="https://lucainiaoge.github.io.git/tags/neural-network/"/>
    
  </entry>
  
  <entry>
    <title>REPET Algorithm - Background Music Separation Using Auto-correlation</title>
    <link href="https://lucainiaoge.github.io.git/2021/03/31/REPET_Algorithm_study/"/>
    <id>https://lucainiaoge.github.io.git/2021/03/31/REPET_Algorithm_study/</id>
    <published>2021-03-30T16:00:00.000Z</published>
    <updated>2025-11-11T13:28:51.810Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><div id="content"></div><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script><p><font color=gray > Pre-requisites:</p><ol><li>Knowing the discrete Fourier transform (DFT);</li><li>Knowing the auto-correlation calculation for discrete series.</font></li></ol><p>This is a note for Zafar Rafii’s REpeating Pattern Extraction Technique (REPET) algorithm in its basic form. REPET is a super-simple algorithm which could separate human voice from accompanied music, although it is effective only in typical cases when background music is highly repetitive.</p><span id="more"></span><p>To view this article, please download:<br><a href="/download/REPET_Algorithm_study.pdf">REPET_Algorithm_study.pdf</a></p>]]></content>
    
    
    <summary type="html">&lt;div id=&quot;content&quot;&gt;&lt;/div&gt;
&lt;script type=&quot;text/javascript&quot; src=&quot;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default&quot;&gt;&lt;/script&gt;

&lt;p&gt;&lt;font color=gray &gt; Pre-requisites:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Knowing the discrete Fourier transform (DFT);&lt;/li&gt;
&lt;li&gt;Knowing the auto-correlation calculation for discrete series.&lt;/font&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This is a note for Zafar Rafii’s REpeating Pattern Extraction Technique (REPET) algorithm in its basic form. REPET is a super-simple algorithm which could separate human voice from accompanied music, although it is effective only in typical cases when background music is highly repetitive.&lt;/p&gt;</summary>
    
    
    
    
    <category term="research" scheme="https://lucainiaoge.github.io.git/tags/research/"/>
    
    <category term="mir" scheme="https://lucainiaoge.github.io.git/tags/mir/"/>
    
    <category term="MSS" scheme="https://lucainiaoge.github.io.git/tags/MSS/"/>
    
  </entry>
  
  <entry>
    <title>Beta Regression vs. Logistic Regression</title>
    <link href="https://lucainiaoge.github.io.git/2021/03/21/Beta_Regression_vs_Logistic_Regression/"/>
    <id>https://lucainiaoge.github.io.git/2021/03/21/Beta_Regression_vs_Logistic_Regression/</id>
    <published>2021-03-20T16:00:00.000Z</published>
    <updated>2025-11-11T13:28:51.797Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><div id="content"></div><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script><p><font color=gray > Pre-requisites:</p><ol><li>Knowing the Maximum-likelihood criterion;</li><li>It is recommended that readers have known the concepts and basic applications of Beta distribution.</font></li></ol><p>This article tells you a method to modeling a regression problem whose output is bounded and supposed to be countinuous.</p><span id="more"></span><p>To view this article, please download:<br><a href="/download/Beta_Regression_vs_Logistic_Regression.pdf">Beta_Regression_vs_Logistic_Regression.pdf</a><br>There is a .ipynb notebook for a toy experiment, which could be downloaded from:<a href="/download/BoundedRegression.ipynb">BoundedRegression.ipynb</a></p>]]></content>
    
    
    <summary type="html">&lt;div id=&quot;content&quot;&gt;&lt;/div&gt;
&lt;script type=&quot;text/javascript&quot; src=&quot;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default&quot;&gt;&lt;/script&gt;

&lt;p&gt;&lt;font color=gray &gt; Pre-requisites:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Knowing the Maximum-likelihood criterion;&lt;/li&gt;
&lt;li&gt;It is recommended that readers have known the concepts and basic applications of Beta distribution.&lt;/font&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This article tells you a method to modeling a regression problem whose output is bounded and supposed to be countinuous.&lt;/p&gt;</summary>
    
    
    
    
    <category term="math" scheme="https://lucainiaoge.github.io.git/tags/math/"/>
    
    <category term="statistics" scheme="https://lucainiaoge.github.io.git/tags/statistics/"/>
    
  </entry>
  
  <entry>
    <title>Pytorch - A Seemingly Indifferent 1-D Dimension Leading to Model Failure</title>
    <link href="https://lucainiaoge.github.io.git/2021/03/21/PyTorch_lesson_1D_dimension_leading_to_bad_loss/"/>
    <id>https://lucainiaoge.github.io.git/2021/03/21/PyTorch_lesson_1D_dimension_leading_to_bad_loss/</id>
    <published>2021-03-20T16:00:00.000Z</published>
    <updated>2025-11-11T13:28:51.803Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><div id="content"></div><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script><p><font color=gray > This is a reflection on PyTorch: be careful with the shape of tensor, even for differences between shape[B,1] and shape[B].</font></p><p>Have you encountered such a problem when training a neural network: you are sure that your model is perfectly correct, and your training procedure is also correct. But you cannot get the expect result. Your model outputs seem blurred, and the loss curve does not show obvious descent. What is wrong?<br>Have you encountered python warning like this? <em>UserWarning: Using a target size (torch.Size([12])) that is different to the input size (torch.Size([12, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.</em></p><span id="more"></span><p>There is a lesson behind this. To view this article, please download:<br><a href="/download/PyTorch_lesson_1D_dimension_leading_to_bad_loss.pdf">PyTorch_lesson_1D_dimension_leading_to_bad_loss.pdf</a></p>]]></content>
    
    
    <summary type="html">&lt;div id=&quot;content&quot;&gt;&lt;/div&gt;
&lt;script type=&quot;text/javascript&quot; src=&quot;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default&quot;&gt;&lt;/script&gt;

&lt;p&gt;&lt;font color=gray &gt; This is a reflection on PyTorch: be careful with the shape of tensor, even for differences between shape[B,1] and shape[B].&lt;/font&gt;&lt;/p&gt;
&lt;p&gt;Have you encountered such a problem when training a neural network: you are sure that your model is perfectly correct, and your training procedure is also correct. But you cannot get the expect result. Your model outputs seem blurred, and the loss curve does not show obvious descent. What is wrong?&lt;br&gt;Have you encountered python warning like this? &lt;em&gt;UserWarning: Using a target size (torch.Size([12])) that is different to the input size (torch.Size([12, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.&lt;/em&gt;&lt;/p&gt;</summary>
    
    
    
    
    <category term="machine_learning" scheme="https://lucainiaoge.github.io.git/tags/machine-learning/"/>
    
    <category term="python" scheme="https://lucainiaoge.github.io.git/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>From Beta Distribution to Conjugate Distribution</title>
    <link href="https://lucainiaoge.github.io.git/2021/03/14/From_Beta_Distribution_to_Conjugate_Distributions/"/>
    <id>https://lucainiaoge.github.io.git/2021/03/14/From_Beta_Distribution_to_Conjugate_Distributions/</id>
    <published>2021-03-13T16:00:00.000Z</published>
    <updated>2025-11-11T13:28:51.799Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><div id="content"></div><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script><p><font color=gray > Pre-requisites:</p><ol><li>Knowing the Bayes theorem;</li><li>It is recommended that readers have gone through elementary training about statistics.</font></li></ol><p>This article tells you the basic ideas behind the Beta distribution, and its basic applications. In detail, we could use Beta distribution to model random varibales which represent proportions or probabilities.</p><p>In this article, you could understand why Beta distribution is called “distribution of distributions”, and get an intuition about the concept “conjugate distribution”.</p><span id="more"></span><p>To view this article, please download:<br><a href="/download/From_Beta_Distribution_to_Conjugate_Distributions.pdf">From_Beta_Distribution_to_Conjugate_Distributions.pdf</a></p>]]></content>
    
    
    <summary type="html">&lt;div id=&quot;content&quot;&gt;&lt;/div&gt;
&lt;script type=&quot;text/javascript&quot; src=&quot;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default&quot;&gt;&lt;/script&gt;

&lt;p&gt;&lt;font color=gray &gt; Pre-requisites:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Knowing the Bayes theorem;&lt;/li&gt;
&lt;li&gt;It is recommended that readers have gone through elementary training about statistics.&lt;/font&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This article tells you the basic ideas behind the Beta distribution, and its basic applications. In detail, we could use Beta distribution to model random varibales which represent proportions or probabilities.&lt;/p&gt;
&lt;p&gt;In this article, you could understand why Beta distribution is called “distribution of distributions”, and get an intuition about the concept “conjugate distribution”.&lt;/p&gt;</summary>
    
    
    
    
    <category term="math" scheme="https://lucainiaoge.github.io.git/tags/math/"/>
    
    <category term="statistics" scheme="https://lucainiaoge.github.io.git/tags/statistics/"/>
    
  </entry>
  
  <entry>
    <title>(Chinese) - 记录一个儿时的游戏-&quot;攒&quot; (A Biography for A Game in my Childhood-&quot;Zan&quot;)</title>
    <link href="https://lucainiaoge.github.io.git/2020/12/28/game_chiledhood_zan/"/>
    <id>https://lucainiaoge.github.io.git/2020/12/28/game_chiledhood_zan/</id>
    <published>2020-12-27T16:00:00.000Z</published>
    <updated>2025-11-11T13:28:51.810Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><div id="content"></div><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>This article contains two Chinese articles about my childhood: a Chinese introduction for game "Zan" (see also http://www.wikibin.org/articles/bor-bor-zan-2.html), and a Chinese article regarding my view of points on this game.<span id="more"></span><blockquote><ul><li><a href="/download/Game_instruction_zan_Chinese.pdf">Game_instruction_zan_Chinese.pdf</a></li><li><a href="/download/Memory_zan_Chinese.pdf">Memory_zan_Chinese.pdf</a></li></ul></blockquote><p>If I have spare-time in the future, I will complete the English version.</p>]]></content>
    
    
    <summary type="html">&lt;div id=&quot;content&quot;&gt;&lt;/div&gt;
&lt;script type=&quot;text/javascript&quot; src=&quot;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default&quot;&gt;&lt;/script&gt;
This article contains two Chinese articles about my childhood: a Chinese introduction for game &quot;Zan&quot; (see also http://www.wikibin.org/articles/bor-bor-zan-2.html), and a Chinese article regarding my view of points on this game.</summary>
    
    
    
    
    <category term="misc" scheme="https://lucainiaoge.github.io.git/tags/misc/"/>
    
  </entry>
  
  <entry>
    <title>PyTorch - Use create_graph to Compute Second-order Derivative</title>
    <link href="https://lucainiaoge.github.io.git/2020/12/22/PyTorch_create_graph_is_true/"/>
    <id>https://lucainiaoge.github.io.git/2020/12/22/PyTorch_create_graph_is_true/</id>
    <published>2020-12-21T16:00:00.000Z</published>
    <updated>2025-11-11T13:28:51.803Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><strong>by lucainiaoge</strong></p><hr><div id="content"></div><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script><p><font color=gray > This article assumes that readers have been familiar with the concept of computation graph.</font></p><p>Can we use computation graph to calculate arbitrary-order derivative? The answer is yes, we can. But how to leverage it using PyTorch, and how to understand the whole thing?</p><span id="more"></span><p>To view this article, please download:<br><a href="/download/PyTorch-create_graph-is-true_Tutorial_and_Example.pdf">PyTorch: Use create_graph to Compute Second-order Derivative</a></p><p>And the illustrations in that passage could be downloaded from <a href="/download/create_graph_true_PyTorch_tutorial.ipynb">create_graph_true_PyTorch_tutorial.ipynb</a></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;strong&gt;by lucainiaoge&lt;/strong&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;div id=&quot;content&quot;&gt;&lt;/div&gt;
&lt;script type=&quot;text/javascript&quot; src=&quot;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default&quot;&gt;&lt;/script&gt;

&lt;p&gt;&lt;font color=gray &gt; This article assumes that readers have been familiar with the concept of computation graph.&lt;/font&gt;&lt;/p&gt;
&lt;p&gt;Can we use computation graph to calculate arbitrary-order derivative? The answer is yes, we can. But how to leverage it using PyTorch, and how to understand the whole thing?&lt;/p&gt;</summary>
    
    
    
    
    <category term="machine_learning" scheme="https://lucainiaoge.github.io.git/tags/machine-learning/"/>
    
    <category term="python" scheme="https://lucainiaoge.github.io.git/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>An Introduction to Deep Clustering</title>
    <link href="https://lucainiaoge.github.io.git/2020/12/17/deep_clustering_intro/"/>
    <id>https://lucainiaoge.github.io.git/2020/12/17/deep_clustering_intro/</id>
    <published>2020-12-16T16:00:00.000Z</published>
    <updated>2025-11-11T13:28:51.810Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><strong>by lucainiaoge</strong></p><hr><div id="content"></div><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script><h1 id="Toy-Example"><a href="#Toy-Example" class="headerlink" title="Toy Example"></a>Toy Example</h1><p>Suppose we have a series of vectors $V=[v_n],n=1,2,…,N$, where $v_n\in {\rm R^K}$. We want to cluster together similar vectors, what will we do?</p><span id="more"></span><p>To view the whole passage, please download:<br><a href="/download/AnIntroductiontoDeepClustering.pdf">An Introduction to Deep Clustering</a></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;strong&gt;by lucainiaoge&lt;/strong&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;div id=&quot;content&quot;&gt;&lt;/div&gt;
&lt;script type=&quot;text/javascript&quot; src=&quot;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default&quot;&gt;&lt;/script&gt;

&lt;h1 id=&quot;Toy-Example&quot;&gt;&lt;a href=&quot;#Toy-Example&quot; class=&quot;headerlink&quot; title=&quot;Toy Example&quot;&gt;&lt;/a&gt;Toy Example&lt;/h1&gt;&lt;p&gt;Suppose we have a series of vectors $V=[v_n],n=1,2,…,N$, where $v_n&#92;in {&#92;rm R^K}$. We want to cluster together similar vectors, what will we do?&lt;/p&gt;</summary>
    
    
    
    
    <category term="machine_learning" scheme="https://lucainiaoge.github.io.git/tags/machine-learning/"/>
    
    <category term="research" scheme="https://lucainiaoge.github.io.git/tags/research/"/>
    
  </entry>
  
  <entry>
    <title>Linear-upper-coverage Smoothing for Peak Finding</title>
    <link href="https://lucainiaoge.github.io.git/2020/10/10/linear-upper-coverage-algorithm-for-peak-finding/"/>
    <id>https://lucainiaoge.github.io.git/2020/10/10/linear-upper-coverage-algorithm-for-peak-finding/</id>
    <published>2020-10-09T16:00:00.000Z</published>
    <updated>2025-11-11T13:28:51.810Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><strong>by lucainiaoge</strong></p><hr><div id="content"></div><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script><h1 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h1><p>I came up with this idea on October 9th, 2020, when I was considering how to find the overtone peaks in a spectrogram. I happened to be playing LIMBO the previous day, and that inspired me to come up with my idea regarding Linear-upper-coverage (LUC), which converts the peak finding problem into linear optimization subtasks.</p><span id="more"></span><ul><li><font color=Gray size=3>It is recommended that readers have grasped basic knowledge about calculus, convex optimization and digital signal processing (DSP). Still, if those pre-requisites are not satisfied, it is also OK to understand my ideas and algorithms. Most of those knowledges are helpful when readers want to understand my proofs for the Lemmas or Theorems proposed in this article.</font></li><li><font color=Gray size=3>If [Math Processing Error] occurs or figures are not showing, please refresh this page or switch to another browser (Google chrome is recommended).</font></li><li><font color=Gray size=3>One more tip: this article is a little bit long. However, if you skip my rationales/proofs and go directly to my motivations and experiment results, you will finish reading this article quicker. Anyway, welcome to delve into my math works and logics in order to understand LUC deeply, and welcome to correct me if I made mistakes.</font></li></ul><h1 id="Problem-Definition-and-Motivation"><a href="#Problem-Definition-and-Motivation" class="headerlink" title="Problem Definition and Motivation"></a>Problem Definition and Motivation</h1><h2 id="The-Problem"><a href="#The-Problem" class="headerlink" title="The Problem"></a>The Problem</h2><p>How to find the peaks in the following curve?</p><p><span id="original_curve"> <img src="https://i.loli.net/2020/10/10/jRu3N6WJUfzYT9d.png" alt="Original Curve.png"> </span></p><p>If we manually mark the peaks, the result may normally look like the following figure?</p><p><span id="original_curve_manual_maxima"> <img src="https://i.loli.net/2020/10/10/8I9Dcbk451fXqvp.png" alt="Original_Curve_manually_find.png"> </span></p><p>However, how to design an algorithm to robustly find the desired peaks (local maxima)?</p><p>To answer this question, we have to ask ourselves: what is a desired peak?</p><p>If we just want every local maxima, we may get this  following result:</p><p><span id="original_curve_all_maxima"> <img src="https://i.loli.net/2020/10/10/P4pVHFzLuqvjTtQ.png" alt="Original_Curve_all_maxima.png"> </span></p><p>And according to our current definition of “desired peak”, this ugly result is correct.</p><p>Therefore, you may be willing to design an algorithm which is adaptable according to our variable definitions for a “desired peak”.</p><h2 id="What-Inspired-Me"><a href="#What-Inspired-Me" class="headerlink" title="What Inspired Me"></a>What Inspired Me</h2><p>Well, in addition to the inspiring peak-finding-problem itself, another incentive of my idea is a rolling wheel on a coarse road:</p><p><span id="wheel_olling_analogy"> <img src="https://i.loli.net/2020/10/10/xaNzrKp34MEDJ7T.png" alt="wheel_rolling_analogy.png"> </span></p><p>As you can see: the centroid of the wheels form up a much smoother curve (although still a little bumping) than the original curve. However, several insignificant local maxima are still troublesome. And it is also a little bit hart do model a wheel rolling on a coarse road with a few lines of codes. So how to improve this idea?</p><p>I was lucky to be playing LIMBO the previous day, and one scene in the vedio game LIMBO just struck me:</p><p><span id="LIMBO_scene"> <img src="https://i.loli.net/2020/10/10/unDvZ8GWTBLEY4b.png" alt="limbo_analogy.png"> </span></p><p>Notice the the red arrows: there are tiles covering the roof/hill (whatever it looks like as it is dark).</p><p>So, why not cover our curve with tiles? I drew the following picture to show my idea of tile-covering:</p><p><img src="https://i.loli.net/2020/10/10/HYt1xgTnPkMKsZ6.png" alt="basic_illustration.png"></p><p>First, divide the x-axis into intervals; second, cover the curves in each intervals with tiles; third, find the centroid of each tile; finally, use the centroid scatters to find the local maxima.</p><p>Notice that we can cover over curve with tiles of different lengths, which is equivalent our variable definitions on “desired peak”: if we use short tiles, we will be more sensitive to small local maxima, while long tiles will ignore the local maxima which are insignificant in terms of a smaller measure on $x$.</p><p>Now comes the question: how to implement this idea?</p><h1 id="From-Peak-Finding-to-Linear-Optimization"><a href="#From-Peak-Finding-to-Linear-Optimization" class="headerlink" title="From Peak Finding to Linear Optimization"></a>From Peak Finding to Linear Optimization</h1><h2 id="Deriving-the-Basic-Formulation"><a href="#Deriving-the-Basic-Formulation" class="headerlink" title="Deriving the Basic Formulation"></a>Deriving the Basic Formulation</h2><p>As the title of this section suggests, I utilized linear optimization to solve the problem. Among the four steps in the previous section, you may notice that the phrase “over the curves in each intervals with tiles” is not clearly defined. How can we cover a curve with a tile? Here is where linear optimization comes into being:</p><p>Suppose we got an interval $x \in [x_i,x_{i+1}]$, where a 1-D curve $f(x)$ is defined. The tile is depicted as $l_i(x)=a_i x+b_i$. Obviously, we must have $f(x) \leq l_i(x), \forall x \in [x_i,x_{i+1}]$. With this constraint, we want to find the parameters $(a_i,b_i)$ such that the tile seems to cover the curve.</p><p>Newton’s laws suggest: if you put an object in a gravitatio, it is stable when its gravitational potential energy reaches its minimum. If we assume that the density of our tiles is uniformly distributed, we can conclude that the tile’s gravitational potential energy can be calculated by a particle locating at its centroid, which is $(\frac{x_i+x_{i+1}}{2},l_i(\frac{x_i+x_{i+1}}{2}))$. Therefore, we get our objective function: $l_i(\frac{x_i+x_{i+1}}{2})=a_i\frac{x_i+x_{i+1}}{2}+b_i$.</p><p>To sum up, we get the linear optimization problems:</p><blockquote><p>$\forall i=1,2,…$, solve the linear programming (LP)problem within interval $[x_i,x_{i+1}]$:<br>$$min_{a_i,b_i} \quad a_i\frac{x_i+x_{i+1}}{2}+b_i $$ $$s.t. f(x) \leq a_i x+b_i, \forall x \in [x_i,x_{i+1}]$$</p></blockquote><p>And I may call it linear-upper-coverage (LUC) algorithm.</p><p>Notice that there are infinite constraints, which are intractable. One intuitive way is to sample the interval $x \in [x_i,x_{i+1}]$ to get $x_{i}^{k} \in [x_i,x_{i+1}], \forall k=1,2,…,K$. And consequently, the linear constraints become: $$f(x_{i}^{k}) \leq a_i x_{i}^{k}+b_i, \forall k=1,2,…,K$$</p><p>Until now, we are able to solve that linear optimization problem with inequality constraints! The classical linear programming algorithms (e.g. the Simplex Method) are well-equipped to sove them!</p><h2 id="Formal-LUC-Definition-Generalizing-Interval-Partitions"><a href="#Formal-LUC-Definition-Generalizing-Interval-Partitions" class="headerlink" title="Formal LUC Definition Generalizing Interval Partitions"></a>Formal LUC Definition Generalizing Interval Partitions</h2><p>You may noticed that although I divided the x-axis equally, the lengths of tiles are not the same. Is it necessary to set the tile lengths all the same? This is actually about the choosing the segmentation strategy, i.e. the procedure to get $[x_i,x_{i+1}], i=1,2,…$</p><p>Therefore, if restricted to linear coverage, the most configurable aspect is the segmentation strategy. Not only can we segment in equal length, we can also segment in a log-scale, or even sample randomly. Different segmentation strategy lead to different definitions of “desired peak”.</p><p>Also, it is not necessary to assume that the intervals do not overlap. Instead, we can arbitrarily sample the curve and construct intervals for each of those sample points, even if those intervals can overlap. Such more general definition becomes:</p><blockquote><p><font color=Crimson size=4><strong>Definition 1 (normal LUC):</strong></font><font color=DarkRed size=3> Given $f:D\rightarrow \pmb{R}$, sample data points $x_i\in D,i=1,2,…$. Define intervals $I_i = [x_i^l,x_i^r]$ where $x_i \in I_i$, and define linear segments $l_i(x)=a_i x+b_i, \forall x\in I_i$.<br>Define the linear programming problems $LUC_i$ within intervals<br>$$LUC_i:\quad min_{a_i,b_i} \quad l_i(\frac{1}{2}(x_i^l+x_i^r))$$ $$s.t. f(x) \leq l_i(x), \forall x \in I_i$$ The LUC solution is the set of all optimum linear segments, i.e. $l_i^{\star}(x)$<br></font></p></blockquote><p>From now on, $x_i$ no longer means the left endpoint of interval $I_i$, but the centroid point of interval $I_i$. The left endpoint of interval $I_i$ is written as $x_i^l$ instead. (If I sometime breaks this law, please understand that because those cases are obvious.)</p><p>Moreover, we can cover the curve with actually whatever function we like: circles, ovels etc. I chose lines because they look more simple and intuitive. What about other elements? It might be worth trying, but I am not going to talk about them at this moment…</p><h1 id="Proof-that-LUC-Has-Smooth-Effects-Convex-Case"><a href="#Proof-that-LUC-Has-Smooth-Effects-Convex-Case" class="headerlink" title="Proof that LUC Has Smooth Effects: Convex Case"></a>Proof that LUC Has Smooth Effects: Convex Case</h1><p>If we want to prove that an algorithm can smoothify a curve, we have to prove that the algorithm dampens the high-frequency components in certain ways.</p><p>The main challenge to prove this for LUC is that there are linear-programming calculations in each interval, which is non-trivial. I find it difficult to prove this even convex constraint is considered.</p><h2 id="Two-Lemmas-with-Proof"><a href="#Two-Lemmas-with-Proof" class="headerlink" title="Two Lemmas with Proof"></a>Two Lemmas with Proof</h2><p>I start from the (lower) convex segments defined in $[x^l,x^r]$:<br>$$f(\lambda x^l+(1-\lambda) x^r)\leq \lambda f(x^l)+(1-\lambda) f(x^r), \forall 0\leq \lambda \leq 1$$</p><p>Intuitively, we can reach the following conclusion:</p><blockquote><p><font color=Crimson size=4><strong>Lemma 1 (LUC for convex function):</strong></font><font color=DarkRed size=3> if $f:[x^l,x^r]\rightarrow \pmb{R}$ is convex in $[x^l,x^r]$, then the optimum LUC function becomes $l^{\star}(x)=\frac{f(x^l)-f(x^r)}{x^l-x^r} (x-\frac{x^l+x^r}{2}) + \frac{f(x^l)+f(x^r)}{2}$</font></p></blockquote><p><font color=Gray size=3><strong>Proof:</strong><br>①First prove that the given $l^{\star}$ obeys the constraints of LUC linear programming.<br>That constraint is: $f(x) \leq l(x), \forall x \in [x^l,x^r]$. If we apply $l^{\star}$ to that constraint, we just need to prove: $f(x) \leq l^{\star}(x), \forall x \in [x^l,x^r]$.<br>Plug in the convex assumption on $f(x)$ and we get: $f(\lambda x^l+(1-\lambda) x^r)\leq \lambda f(x^l)+(1-\lambda) f(x^r), \forall 0\leq \lambda \leq 1$.<br>As $f(x^l) \leq l^{\star}(x^l)$ and $f(x^r) \leq l^{\star}(x^r)$, we get $\lambda f(x^l)+(1-\lambda) f(x^r)\leq \lambda l^{\star}(x^l)+(1-\lambda) l^{\star}(x^r) = l^{\star}(\lambda x^l+(1-\lambda) x^r)$.<br>Therefore, we proved that $f(x) \leq l^{\star}(x), \forall x \in [x^l,x^r]$ is true.<br>②Then prove that $l^{\star}$ is the optimum.<br>Recall that the objective function is $l(\frac{x^l+x^r}{2}) = a_i\frac{x^l+x^r}{2}+b_i$.<br>If we want to decrease the objective value $l(\frac{x^l+x^r}{2})=\frac{l(x^l)+l(x^r)}{2}$, either $l(x^l)$ or $l(x^r)$ should be decreased.<br>However, according to the constraints, $f(x^l) \leq l(x^l)$ and $f(x^r) \leq l(x^r)$: once we have $f(x^l) = l^{\star}(x^l)$ and $f(x^r) = l^{\star}(x^r)$, we can assert that $l^{\star}$ reaches the optimum, for neither $l^{\star}(x^l)$ or $l^{\star}(x^r)$ can be decreased. □<br></font></p><p>On the other hand, if we assume that $f(x)$ is bounded in interval $[x^l,x^r]$, it is also intuitive to reach the following conclusion:</p><blockquote><p><font color=Crimson size=4><strong>Lemma 2 (existance of LUC solutions and tightness):</strong></font><font color=DarkRed size=3> if $f:[x^l,x^r]\rightarrow \pmb{R}$ is bounded, then:</font></p><ol><li><font color=DarkRed size=3>There are at least two zero-slackness LUC constraints at $x^{-}$ and $x^{+}$ ($x^{-}\leq x^{+}$); the term zero-slackness indicates that $f(x^{-})=l^{\star}(x^{-})$ and $f(x^{+})=l^{\star}(x^{+})$.</font></li><li><font color=DarkRed size=3>Equality of $x^{-}\leq x^{+}$ is reached only when $x^{-}=x^{+}=x^l$ or $x^{-}=x^{+}=x^r$</font></li></ol></blockquote><p><font color=Gray size=3><strong>Proof:</strong><br>① First prove that there is at least one optimum solution for the LUC problem.<br>As $f(x)$ is bounded in interval $[x^l,x^r]$, assume that $m&lt;f(x)&lt;M_1&lt;M_2$, there exists $l(x)=a_i x+b_i$ such that $M_2&gt;l(x^l)&gt;M_1&gt;f(\forall x)$ and $M_2&gt;l(x^r)&gt;M_1&gt;f(\forall x)$. Therefore, feasible region is not empty.<br>On the other hand, there exists $l(x)=a_i x+b_i$ such that $m&lt;f(x^l)\leq l(x^l)$ and $m&lt;f(x^r)\leq l(x^r)$. This is to say, the objective $\frac{l(x^l)+l(x^r)}{2}&gt;m$. Therefore, the objective cannot be arbitrarily small.<br>In sum, there is at least one optimum solution for the LUC problem.<br>② Then prove that the optimum solution lead to zero slackness. Recall the <a href="https://link.springer.com/referenceworkentry/10.1007/1-4020-0611-x_140">complementary slackness theorem</a>:<br>Given a standard LP problem $$min\quad cx, \quad s.t. \quad Ax \geq  b$$ and its dual problem $$max\quad b^T y, \quad s.t. \quad A^T y \leq  c^T$$ Definition of slackness of the $k^{th}$ constraint is $s_k = A_k x - b_k$.<br>The complementary slackness theorem says that if a feasible solution $x_0$ is optimum (which exists because of ①), and its corresponding dual solution is $y_0$ is also optimum, then $x_0^T (c-A^T y_0)=0$ and $y_0^T (A x_0 - b)=0$.<br>Therefore, for those $y_0^k \neq 0$, we must have $A_k x_0 - b_k = 0, k \in \lbrace k:y_0^k \neq 0 \rbrace$. As a result, $s_k = A_k x_0 - b_k = 0,k \in \lbrace k:y_0^k \neq 0 \rbrace$.<br>Translate this into LUC context: $x_0=(a_{i}^{\star},b_{i}^{\star})$, $A=[x^{[1:K]},ones(1,K)^T]$, $c=[\frac{x^l+x^r}{2},1]$ and $b=[f(x^1),…,f(x^K)]^T$. The “$y_0^k$” in LUC cannot be all zero, or otherwize $c=0$, which is not true. Therefore, there always exists $k$ such that “$A_k x_0 - b_k = 0$”, which is actually $f(x^k)=l^{\star}(x^k)$ (the $k^{th}$ constraint), leading to zero slackness.<br>③ Then prove that there are at least two different tight constraints.<br>According to the convexity of linear feasible region (which is a polyhedron), the optimum solution touches the vertex of that region. As we know, the vertex of a region is an intersection of two hyperplanes (in LUC, they are actually two 2-D lines, because there are only two variables), corresponding to two different constraints. Therefore, if there are at least two constraints which have zero slackness, they are different.<br>④ Finally prove the property when $x^{-}=x^{+}$.<br>We know that each constraint can be linked with an $x$ in $[x^l,x^r]$. Moreover, the statement $x\in [x^l,x^r]$ indicates two more underlying constraints $x\geq x^l$ and $x\leq x^r$. Recall ③: the two constraints at $x=x^{-}$ and $x=x^{+}$ are different. If a constraint at $x=x^{-}$ is tight and $x^{-}=x^{+}$, then this case only happens at $x=x^l$ or $x=x^r$, because: any $x\in (x^l,x^r)$ can be linked with only one constraint $f(x)\leq l(x)$; but at $x=x^l$, there exists one more constraint $x\geq x^l$, which reaches tightness (and the case when $x=x^r$ is similar). In conclusion, the statement $x^{-}=x^{+}$ indicates that two tight constraints sharing the same point, and such case can only happen at $x=x^l$ or $x=x^r$; consequently, $x^{-}=x^{+}=x^l$ or $x^{-}=x^{+}=x^r$.□<br></font></p><h2 id="Explore-the-Effects-of-LUC-on-DTFT-Spectrum"><a href="#Explore-the-Effects-of-LUC-on-DTFT-Spectrum" class="headerlink" title="Explore the Effects of LUC on DTFT Spectrum"></a>Explore the Effects of LUC on DTFT Spectrum</h2><p>Now, we have all the ingradients! What is left is to describe our problem in a proper way. Consider a uniformally-sampled sequence of $f(x)$, which is written as $[f_i] = [f_1,f_2,…] = [f(x_1),f(x_2),…]$.<br>Without downsampling, we do LUC for each interval centered with the $i^{th}$ point, i.e. the interval $[x_i-\Delta x,x_i+\Delta x]$. It is also OK to write this interval as $[x_{i-\Delta i},x_{i+\Delta i}]$ because of equal-partition.</p><p>Therefore, we have the LUC problem formally:</p><blockquote><p>$$min_{a_i,b_i} \quad a_i x_i+b_i $$ $$s.t. f(x) \leq a_i x+b_i, \forall x \in [x_{i-\Delta i},x_{i+\Delta i}]$$</p></blockquote><p>According to Lemma 2, there are at least two points $x_i^{-}$ and $x_i^{+}$ such that $f(x_i^{-})=l_i^{\star}(x_i^{-})$ and $f(x_i^{+})=l_i^{\star}(x_i^{+})$. We can  subsequently determine $l_i^{\star}$ with those two points: $$a_i^{\star} = \frac{f(x_i^{-})-f(x_i^{+})}{x_i^{-}-x_i^{+}}$$ $$l_i^{\star}(x) = a_i^{\star}(x-\frac{x_i^{-}+x_i^{+}}{2})+\frac{f(x_i^{-})+f(x_i^{+})}{2} \quad (*)$$</p><p>Consequently, I write the LUC version of uniformally-sampled sequence as $[f_i^{\star}] = [f_1^{\star},f_2^{\star},…] = [l_1^{\star}(x_1),l_2^{\star}(x_2),…]$</p><p>Assume that $f(x)$ is convex in each interval $[x_{i-\Delta i},x_{i+\Delta i}]$ (no need to be convex in the overall definition interval). Then calculate the DTFT for both $[f_i]$ and $[f_i^{\star}]$:<br>$$F(\omega) = {\rm DTFT}[f_i] = \sum_i f_i e^{\sqrt{-1}\omega i} \quad ①$$ $$F^{\star}(\omega) = {\rm DTFT}[f_i^{\star}] = \sum_i f_i^{\star} e^{\sqrt{-1}\omega i} = \sum_i [a_i^{\star}(x_i-\frac{x_i^{-}+x_i^{+}}{2})+\frac{f(x_i^{-})+f(x_i^{+})}{2}] e^{\sqrt{-1}\omega i} \quad ②$$</p><p>According to the convexity assumption, we can apply Lemma 1, which says that $l_i^{\star}(x)=\frac{f(x_{i-\Delta i})-f(x_{i+\Delta i})}{x_{i-\Delta i}-x_{i+\Delta i}} (x-\frac{x_{i-\Delta i}+x_{i+\Delta i}}{2}) + \frac{f(x_{i-\Delta i})+f(x_{i+\Delta i})}{2}$</p><p>Compare this with $(*)$ and we will get $x_i^{-}=x_{i-\Delta i}$ and $x_i^{+}=x_{i+\Delta i}$.</p><p>Plug this conclusion into $②$ and also apply the equality that $x_i = \frac{f(x_{i-\Delta i})+f(x_{i+\Delta i})}{2}$, we will get:<br>$F^{\star}(\omega) = {\rm DTFT}[f_i^{\star}] = \sum_i \frac{f(x_{i-\Delta i})+f(x_{i+\Delta i})}{2} e^{\sqrt{-1}\omega i}$<br>$= \sum_i \frac{f_{i-\Delta i}+f_{i+\Delta i}}{2} e^{\sqrt{-1}\omega i}$<br>$= \frac{1}{2}({\rm DTFT}[f_{i-\Delta i}] + {\rm DTFT}[f_{i+\Delta i}])\quad ③$</p><p>We know that ${\rm DTFT}[f_{i-\Delta i}]=\sum_i f_{i-\Delta i}e^{\sqrt{-1}\omega i}=\sum_i f_{i}e^{\sqrt{-1}\omega (i+\Delta i)}=e^{\sqrt{-1}\omega \Delta i}\sum_i f_{i}e^{\sqrt{-1}\omega i}=e^{\sqrt{-1}\omega \Delta i}{\rm DTFT}[f_{i}]$</p><p>Therefore, $③$ becomes $$F^{\star}(\omega) = {\rm DTFT}[f_i^{\star}] = \frac{1}{2}[e^{\sqrt{-1}\omega \Delta i}+e^{-\sqrt{-1}\omega \Delta i}]F(\omega) = F(\omega){\rm cos}(\omega \Delta i) \quad ④$$</p><p>Finally, we can reach from $④$ that $\vert F^{\star}(\omega) \vert = \vert F(\omega)\vert \vert {\rm cos}(\omega \Delta i)\vert \leq \vert F(\omega)\vert$</p><p>Summing up the discussions above:</p><blockquote><p><font color=Crimson size=4><strong>Theorem 1 (smooth effect of convex LUC):</strong></font><font color=DarkRed size=3> given $\Delta i &gt; 0$ and bounded $f(x):D\rightarrow R$, sample a sequence $x_i, i=1,2,…$ from $D$, whose corresponding intervals are $[x_{i-\Delta i},x_{i+\Delta i}], i=1,2,…$; the LUC centroids form a sequence $f_i^{\star}=l_i^{\star}(x_i), i=1,2,…$ whose DTFT is $F^{\star}(\omega)$, while the sampled curve becomes $f_i=f(x_i), i=1,2,…$ whose DTFT is $F(\omega)$. Then we have:<br>if $f(x)$ is convex in intervals $[x_{i-\Delta i},x_{i+\Delta i}], i=1,2,…$ separately, then $F^{\star}(\omega)=F(\omega){\rm cos}(\omega \Delta i)$</font></p></blockquote><p>Due to Taylor’s approximation of ${\rm cos}(\omega \Delta i)$: when $\omega$ is near zero, $F^{\star}(\omega)$ is near $F(\omega)$; but when $\omega$ is a little bit far from zero, $F^{\star}(\omega)$ will be dampened. Of course, the choice of $\Delta i$ is also a factor controlling such influence.</p><p>To understand this effect more intuitively, here is an example, in which $\Delta i = 1/2$, and $f(x)$ is convex in every separate interval.</p><p><img src="https://i.loli.net/2020/10/12/HIRO2igyXS7Ms3F.png" alt="LUC_convex_example.png"></p><p>The red line (downsampled results) is more rugged than the green line (LUC centroids), which confers to my previous analysis.</p><h1 id="A-Candidate-set-LUC-Algorithm-for-General-Cases"><a href="#A-Candidate-set-LUC-Algorithm-for-General-Cases" class="headerlink" title="A Candidate-set LUC Algorithm for General Cases"></a>A Candidate-set LUC Algorithm for General Cases</h1><p>In the previous section, we discussed the LUC for a convex segment. More importantly, we proved Lemma 2, which guarentees the existance of solution, and even gives the exact solution: $$a_i^{\star} = \frac{f(x_i^{-})-f(x_i^{+})}{x_i^{-}-x_i^{+}}$$ $$l_i^{\star}(x) = a_i^{\star}(x-\frac{x_i^{-}+x_i^{+}}{2})+\frac{f(x_i^{-})+f(x_i^{+})}{2} \quad (*)$$</p><p>But it did not touch the essencial case of the tile covering a rugged curve whose convexity is ill defined. How to get a more clear mind about the rugged case? My plan is to find candidates in that rugged curve, from which we select two of them as $x_i^{-}$ and $x_i^{+}$ to determine our final result.</p><p>Before delving into this, we look at several examples…</p><h2 id="Intuitive-Examples"><a href="#Intuitive-Examples" class="headerlink" title="Intuitive Examples"></a>Intuitive Examples</h2><p>There are different curves and we will cover each of those with a line.</p><p><img src="https://i.loli.net/2020/10/11/9sZRka3xNpoSD48.png" alt="examples_raw.png"></p><p>Case (c) is a convex, whose solution is that its  $x_i^{-}$ and $x_i^{+}$ are actually the endpoints, which has already been proven.<br>Case (a) and (b) are concave cases, which are intuitively different from the convex case.<br>Case (d),(e) and (f) are rugged cases.<br>Case (g),(h) and (i) are combinitions of convex and concave segments. (h) and (i) has local maxinima, while (g) is monotonic.</p><p>Think for a while about the results…<br>And then, I give my intuitions:</p><p><img src="https://i.loli.net/2020/10/11/mPtEWRMUb7NDukz.png" alt="examples_tentative.png"></p><p>My finding is that: the candidate points (marked in orange) are such typical points:</p><ol><li>The local maximima</li><li>The endpoints $X^l=(x^l,f(x^l))$ and $X^r=(x^r,f(x^r))$</li><li>The curve point $P$ such that the slope of $PX^l$ reaches maximum; the curve point $Q$ such that the slope of $QX^r$ reaches minimum</li></ol><h2 id="Designing-Candidate-Set-Algorithm"><a href="#Designing-Candidate-Set-Algorithm" class="headerlink" title="Designing Candidate-Set Algorithm"></a>Designing Candidate-Set Algorithm</h2><p>My intuition leads to an algorithm to find the candidate points:</p><p>First, deal with the problem of finding local maximima:</p><blockquote><p><font color=Crimson size=4><strong>Algorithm 1 (finding local maxima):</strong></font><font color=DarkRed size=3> $m=locmax(y)$</font><br>(1-based indexing is used) Given sample squence $y = [y_1,y_2,…,y_k,…,y_K]_{1\times K}$</p><ol><li>initialize a buffer $b = [1,0,…,0,…,0,0]_{1\times (K+1)}$</li><li>initialize the result $m = [0,0,…,0,…,0]_{1\times K}$</li><li>for $k=1,2,…,K-1$:</li><li>$\quad$ $b[k+1] = bool(y[k] \geq y[k+1])$</li><li>for $k=1,2,…,K$:</li><li>$\quad$ $m[k] = b[k]·\overline{b[k+1]}$</li><li>return $m$</li></ol></blockquote><p>Then, deal with the problem of finding $P$ and $Q$:</p><blockquote><p><font color=Crimson size=4><strong>Algorithm 2 (finding $P$ and $Q$):</strong></font><font color=DarkRed size=3> $k_P,k_Q=findPQ(x,y)$</font><br>(1-based indexing is used) Given sample squence $y_{1:K}$ and its corresponding x-axis $x_{1:K}$</p><ol><li>$p = (y[2:K]-y[1])/(x[2:K]-x[1])$</li><li>$q = (y[1:K-1]-y[K])/(x[1:K-1]-x[K])$</li><li>$k_P = {\rm argmax}_k p[k]$</li><li>$k_Q = 1+{\rm argmin}_k q[k]$</li><li>return $k_P,k_Q$</li></ol></blockquote><p>Next, we reach the algorithm for getting the candidate set:</p><blockquote><p><font color=Crimson size=4><strong>Algorithm 3 (finding candidate set):</strong></font><font color=DarkRed size=3> $I_c=findCandidate(x,y)$</font><br>(1-based indexing is used) Given sample squence $y_{1:K}$ and its corresponding x-axis $x_{1:K}$</p><ol><li>initialize $I_c = \lbrace 1,K \rbrace$</li><li>$m=locmax(y)$</li><li>$I_m = find(m==1)$</li><li>$k_P,k_Q=findPQ(x,y)$</li><li>$I_c = I_c \cup I_m \cup \lbrace k_P,k_Q \rbrace$</li><li>return $I_c$</li></ol></blockquote><p>Now, take a look at the example (d),(e) and (f) in the last section: as those curves are rugged, the candidate points in $\lbrace (x_{i_c},x_{i_c}): i_c \in I_c \rbrace$ still form a rugged curve. Why not plug those points again into Algorithm 3? Consequently, we get $\hat{I_c}=findCandidate(x[I_c],y[I_c])$, as illustrated in the following figure:<br><span id="candidate_set_algorithm_intuition"> <img src="https://i.loli.net/2020/10/11/RW8vqKDFrm4puBf.png" alt="candidate_algorithm_example.png"> </span></p><p>This leads to the ultimate algorithm:</p><blockquote><p><font color=Crimson size=4><strong>Algorithm 4 (finding  the smallest candidate set):</strong></font><font color=DarkRed size=3> $I_c=findCandidateSmallest(x,y,N)$</font><br>(1-based indexing is used) Given sample squence $y_{1:K}$ and its corresponding x-axis $x_{1:K}$;<br>$N$ denotes the max iteration times;</p><ol><li>initialize $I_c = \lbrace 1,2,…,K \rbrace, \tilde{I}=I_c, \hat{x} = x[I_c], \hat{y} = y[I_c]$</li><li>for $n$ in $range(N)$:</li><li>$\quad$ $\hat{I_c}=findCandidate(\hat{x},\hat{y})$</li><li>$\quad$ if $\vert \hat{I_c} \vert == \vert I_c \vert$:</li><li>$\quad\quad$ break</li><li>$\quad$ else:</li><li>$\quad\quad$ $I_c=\hat{I_c}$</li><li>$\quad\quad$ $\tilde{I} = \tilde{I}[I_c], \hat{x} = \hat{x}[I_c], \hat{y} = \hat{y}[I_c]$</li><li>return $\tilde{I}$</li></ol></blockquote><p>Finally, we reduce the number of constraints to those indexed by $I_c$.</p><h2 id="Reflections"><a href="#Reflections" class="headerlink" title="Reflections"></a>Reflections</h2><p>Why does the candidate-set algorithm work? Obviously, my intuitive explanations are far from compelling. To develop the following sections and to reconcile the effectiveness of candidat-set algorithm, I need to introduce my hypothesis, which is not proved at this moment:</p><blockquote><p><font color=Crimson size=4><strong>Hypothesis 1 (equivalence of candidate-set in terms of LUC):</strong></font><font color=DarkRed size=3><br>if the candidate set for bounded $f(x):I_i\rightarrow R$ is $I_{ci}$, then the normal LUC problem reduce to: $$LUC_i:\quad min_{a_i,b_i} \quad l_i(x_i)$$ $$s.t. f(x) \leq l_i(x), \forall x \in I_{ci}$$<br>Or in the language of Lemma 2: $x_i^{-}\in I_{ci}$ and $x_i^{+}\in I_{ci}$</font></p></blockquote><p>In addition, if you are careful enough, you may find that my definition for candidate-set is flawwed: it does not lead to the equivalent result as the normal LUC. This can be proven by <a href="#candidate_set_algorithm_intuition">the figure in the previous section which illustrates the candidate-set algorithm</a>, which provides a counter-example: the ultimate LUC calculated based on the blue points actually violates the LUC constraints based on the initial black curve!<br>Luckily, although this effect sometimes happens, the  LUC results do not seriously change. I am going to demonstrate this in the experiment section.</p><p>Still, I have my solution which can perfectly solve this flawwed-definition problem. The key is: modify the $3^{rd}$ criterion to get a tentative $4^{th}$ criterion:</p><blockquote><ul><li>For type 1 candidate points $X_k = (x_k,f(x_k))$ (which are local maxima), find curve points $P_k = (x_{k}^{+},f(x_{k}^{+})),Q_k = (x_{k}^{-},f(x_{k}^{-}))$ for each $X_k$, such that</li><li>$x_{k}^{+}&gt;x_k$ and the slope of $X_k P_k$ reaches maximum</li><li>$x_{k}^{-}&lt;x_k$ and the slope of $Q_k X_k$ reaches minimum</li></ul></blockquote><p>Consequently, the candidate-set finder algorithm should be modified according to the $4^{th}$ criterion. Fortunatelly, it is quite easy by changing Algorithm 2 and 3 a little bit. After all, I am going summarize all about candidate-set algorithm in the next section.</p><h2 id="Formal-Definition-for-Candidate-set-Algorithm"><a href="#Formal-Definition-for-Candidate-set-Algorithm" class="headerlink" title="Formal Definition for Candidate-set Algorithm"></a>Formal Definition for Candidate-set Algorithm</h2><blockquote><p><font color=Crimson size=4><strong>Definition 2 (full definition for candidate set):</strong></font><font color=DarkRed size=3> Given bounded $f(x):I\rightarrow R$;the endpoints are $x^l=inf(I),x^r=sup(I)$.<br>Then, the candidate set for $I$ is written as $I_{c}=\lbrace x:x\in I_m, x\in I_{e}, x\in I_{e}^a, x\in I_{m}^a \rbrace$, as defined by the following 4 criteria:</p><ol><li><font color=DarkRed size=3>$I_m = \lbrace x: x\in I \quad AND \quad \exists \delta &gt;0 \quad s.t.\quad f(x)\geq f(x+\epsilon), \forall \vert \epsilon \vert &lt; \delta \rbrace$, named “Maxima Set”</font></li><li><font color=DarkRed size=3>$I_{e} = \lbrace x^l,x^r \rbrace$, named “Endpoints”</font></li><li><font color=DarkRed size=3>$I_{e}^a = \lbrace \arg\max_{x\in I} \frac{f(x)-f(x^l)}{x-x^l},\arg\min_{x\in I} \frac{f(x)-f(x^r)}{x-x^r} \rbrace$, named “Endpoint Accompany Set”</font></li><li><font color=DarkRed size=3>$I_{m}^a = \lbrace \arg\max_{x\in I,x&gt;x_m} \frac{f(x)-f(x_m)}{x-x_m}, \forall x_m\in I_m \rbrace \cup \lbrace \arg\min_{x\in I,x&lt;x_m} \frac{f(x)-f(x_m)}{x-x_m}, \forall x\in I_m \rbrace$, named “Accompany Set”</font></font></li></ol></blockquote><p>As described, I need to modify the Algorithm 2 and 3 a little here:</p><blockquote><p><font color=Crimson size=4><strong>Algorithm 2.2 (finding the accompany set):</strong></font><font color=DarkRed size=3> $I_m^a=findAccompany(x,y,I_m)$</font><br>(1-based indexing is used) Given sample squence $y_{1:K}$, its corresponding x-axis $x_{1:K}$ and its maxima index set $I_m$</p><ol><li>Initialize $I_m^a = \emptyset$</li><li>for $k_m$ in $I_m$:</li><li>$\quad I^{-} = [1:(k_m-1)], I^{+} = [(k_m+1):K]$</li><li>$\quad a^{+} = (y[k_m]-y[I^{+}])/(x[k_m]-x[I^{+}])$</li><li>$\quad a^{-} = (y[k_m]-y[I^{-}])/(x[k_m]-x[I^{-}])$</li><li>$\quad k^{a+} = I^{+}[\arg\max_{k}a^{+}[k]]$</li><li>$\quad k^{a-} = I^{-}[\arg\min_{k}a^{-}[k]]$</li><li>$\quad I_m^a = I_m^a \cup \lbrace k^{a+},k^{a-} \rbrace $</li><li>return $I_m^a$</li></ol></blockquote><blockquote><p><font color=Crimson size=4><strong>Algorithm 3.2 (finding  the full candidate set):</strong></font><font color=DarkRed size=3> $I_c=findCandidate(x,y)$</font><br>(1-based indexing is used) Given sample squence $y_{1:K}$ and its corresponding x-axis $x_{1:K}$</p><ol><li>initialize $I_c = \lbrace 1,K \rbrace$</li><li>$m=locmax(y)$</li><li>$I_m = find(m==1)$</li><li>$k_P,k_Q=findPQ(x,y)$</li><li>$I_m^a=findAccompany(x,y,I_m)$</li><li>$I_c = I_c \cup I_m \cup \lbrace k_P,k_Q \rbrace \cup I_m^a$</li><li>return $I_c$</li></ol></blockquote><h2 id="Stepping-Further-is-it-OK-to-Leave-Out-Linear-Programming"><a href="#Stepping-Further-is-it-OK-to-Leave-Out-Linear-Programming" class="headerlink" title="Stepping Further: is it OK to Leave Out Linear Programming?"></a>Stepping Further: is it OK to Leave Out Linear Programming?</h2><p>Under Hypothesis 1, there seems no need to bother calling linear programming in order to get $l_i^{\star}$: as the candidate set is small, we can just search infinite-many pairs in order to locate $x_i^{-}$ and $x_i^{+}$.<br>This motivates me to think about accompany pairs. What is an accompany pair? Well, I define it as follows:</p><blockquote><p><font color=Crimson size=4><strong>Definition 3 (accompany pair and accompany pair set):</strong></font><font color=DarkRed size=3> Given bounded $f(x):I\rightarrow R$; the endpoints are $x^l=inf(I),x^r=sup(I)$; the maxima set is $I_m$.<br>Then, an accompany pair is such a tuple $p_m = (x_m,x_m^a)$, where:</p><ol><li><font color=DarkRed size=3>$x_m \in I_m \cup \lbrace  x^l,x^r\rbrace$</font>;</li><li><font color=DarkRed size=3>$x_m^a = \arg\max_{x\in I,x&gt;x_m} \frac{f(x)-f(x_m)}{x-x_m}$ or $x_m^a = \arg\min_{x\in I,x&lt;x_m} \frac{f(x)-f(x_m)}{x-x_m}$</font><br><font color=DarkRed size=3>Correspondingly, if $x&gt;x_m^a$, then we can also write this pair as $p_m^{-} = (x_m,x^{a-}_m)$, which is called the left-side accompany pair; if $x&lt;x_m^a$, then we can also write this pair as $p_m^{+} = (x_m,x^{a+}_m)$, which is called the right-side accompany pair.<br>The set of all accompany pairs is written as $P^a(f,I)$, or just $P^a$</font></li></ol></blockquote><p>Easy to know that $x^l$ has no left-side accompany pair, and $x^r$ has no righy-side accompany pair. If there are $M$ elements in $I_m$, then the number of accompany pair is no greater than $2M+2$.</p><p>Lastly, as each accompany pair can determine a linear function, there must exist the best pairs in terms of LUC objective function. Let’s define the best accompany pair step-by-step:</p><blockquote><p><font color=Crimson size=4><strong>Definition 4 (linear accompany function):</strong></font><font color=DarkRed size=3> Given bounded $f(x):I\rightarrow R$; the accompany pair set is $P^a$.<br>Then, for each accompany pair $p=(x_m,x_m^a)\in P^a$, define its linear accompany function as $l_{p_m}(x)=\frac{f(x_m^a)-f(x_m)}{x_m^a-x_m}(x-x_m)+f(x_m), x\in I$.<br></font><br><font color=Crimson size=4><strong>Definition 5 (feasible accompany pairs and their set):</strong></font><font color=DarkRed size=3> Given bounded $f(x):I\rightarrow R$;  the maxima set is $I_m$; the accompany pair set is $P^a$.<br>Then, an accompany pair $p\in P^a$ is feasible i.i.f $l_p(x)\geq f(x), \forall x\in I_m \cup \lbrace x^l,x^r \rbrace$<br>Correspondingly, all feasible accompay pairs consist of the feasible accompany pair set, written as $P^{a_f}$<br></font><br><font color=Crimson size=4><strong>Definition 6 (best accompany pair):</strong></font><font color=DarkRed size=3> Given bounded $f(x):I\rightarrow R$; the endpoints are $x^l=inf(I),x^r=sup(I)$; the maxima set is $I_m$; the  feasible accompany pair set is $P^{a_f}$.<br>Then, the best accompany pair $p^{\star}$ is defined as $p^{\star}=\arg\min_{p\in P^{a_f}}\quad l_p (\frac{1}{2} (x^l+x^r))$<br></font></p></blockquote><p>Equipped with concepts of accompany pairs, I introduce another hypothesis, which is a vital hint for my next steps.</p><blockquote><p><font color=Crimson size=4><strong>Hypothesis 2 (at least one accompany pair is a zero-slackness pair):</strong></font><font color=DarkRed size=3><br>Given $f(x):I_i\rightarrow R$ whose feasible accompany pair set is $P_i^{a_f}$; then, there is at least one accompany pair ${x_i^{-},x_i^{+}}\in P_i^{a_f}, s.t.\quad l_i^{\star}(x_i^{-})=f(x_i^{-}),l_i^{\star}(x_i^{+})=f(x_i^{+})$, where $l_i^{\star}$ is the optimum LUC in interval $I_i$ for $f(x)$.</font></p></blockquote><p>The definitions regarding accompamy pair and Hypothesis 2 are actually paving the way to describe the following algorithm, which I expect to be equivalent to the LP based LUC:</p><blockquote><p><font color=Crimson size=4><strong>Algorithm 5 (LUCA: finding the best accompany pair):</strong></font><font color=DarkRed size=3> $p^{\star}=LUCBestAccompany(x,y)$</font><br>(1-based indexing is used) Given sample squence $y_{1:K}$ and its corresponding x-axis $x_{1:K}$.</p><ol><li>Initialize $P^{a} = \emptyset, y^{\star}=+\infty, x^c = \frac{1}{2} (x[1]+x[K])$</li><li>$m=locmax(y)$</li><li>$I_m = find(m==1)$</li><li>$k_P,k_Q=findPQ(x,y)$</li><li>$P^{a} = P^{a}\cup \lbrace (1,k_P),(K,k_Q) \rbrace$</li><li>for $k_m$ in $I_m$:</li><li>$\quad I^{-} = [1:(k_m-1)], I^{+} = [(k_m+1):K]$</li><li>$\quad a^{+} = (y[k_m]-y[I^{+}])/(x[k_m]-x[I^{+}])$</li><li>$\quad a^{-} = (y[k_m]-y[I^{-}])/(x[k_m]-x[I^{-}])$</li><li>$\quad k^{a+} = I^{+}[\arg\max_{k}a_k^{+}]$</li><li>$\quad k^{a-} = I^{-}[\arg\min_{k}a_k^{-}]$</li><li>$\quad P^{a} = P^{a}\cup \lbrace (k_m,k^{a+}),(k_m,k^{a-}) \rbrace$</li><li>$y_m = y[I_m], x_m = x[I_m]$</li><li>for $(k,k^a)$ in $P^{a}$:</li><li>$\quad y^c = \frac{y[k^a]-y[k]}{x[k^a]-x[k]}(x^c-x[k])+y[k]$</li><li>$\quad \hat{y_m} = \frac{y[k^a]-y[k]}{x[k^a]-x[k]}(x_m-x[k])+y[k]$</li><li>$\quad$if $y^c&lt;y^{\star}$ and $\hat{y_m}\geq y_m$:</li><li>$\quad\quad y^{\star} = y^c$</li><li>$\quad\quad p^{\star} = (k,k^a)$</li><li>return $p^{\star}$</font></li></ol></blockquote><p>See? the result $p^{\star}$ is actually the final decision!<br>Even so, it is still unsolved in terms of judging if LUCA is equivalent with the normal LUC, or verifying Hypothesis 2.</p><h2 id="Unsolved-Problems-and-My-Orintations"><a href="#Unsolved-Problems-and-My-Orintations" class="headerlink" title="Unsolved Problems and My Orintations"></a>Unsolved Problems and My Orintations</h2><p>To finishing the discussions, I have to recapitulate several unexplained phenomena or unjustified hypothesis:</p><ol><li>to prove that the general case LUC (not restricted to convexity) has smooth effects.</li><li>to verify or deny Hypothesis 1 and 2</li><li>to explain the phenomenon “no matter how rugged $f(x)$ is in interval $I$, once covered with LUC, the rug-details will vanish”</li><li>to invent a 2-D version of LUC, or even multi-dimension version</li></ol><ul><li>In terms of task 1, I have an idea (although not strictly proved): because we can get candidate sets $I_{ci},i=1,2…$ according to Algorithm 3.2, we can construct a new function $f_c(x),x\in \cup_i I_{ci}$. Take $f_c(x)$ as $f(x)$ and consider convexity again!<blockquote><p><font color=Crimson size=4><strong>Lemma 3 (candidate reconstruction):</strong></font><font color=DarkRed size=3> if $f:[x^l,x^r]\rightarrow \pmb{R}$ has LUC solution $l^{\star}(x)$, and the equation $l^{\star}(x)=f(x),x\in I$ has solutions $x_n^s,n=1,2,…,N$ then:<br>there exists function $f_c(x)$ such that</font>:</p><ol><li><font color=DarkRed size=3>$f(x)&lt;f_c(x)\leq l^{\star}(x), \forall x\in I-\lbrace x_n^s,n=1,2,…,N \rbrace$</font></li><li><font color=DarkRed size=3>$f_c(x)$ is convex respectively in $[x^l,x_1^s],[x_1^s,x_2^s],…,[x_N^s,x^{r}]$</font></li></ol></blockquote></li></ul><p><font color=Gray size=3><strong>Proof:</strong><br>For any interval $[x_i^s,x_{i+1}^s]$:<br>① if $f(x)$ is convex in $[x_i^s,x_{i+1}^s]$: set $f_c(x)=\frac{1}{2}(l^{\star}(x)+f(x))$ in this interval, which confers to the conditions;<br>② if $f(x)$ is not convex in $[x_i^s,x_{i+1}^s]$: set $f_c(x)=l^{\star}(x)$ in this interval, which confers to the conditions. □<br></font></p><p>After reconstruction using Lemma 3, we get $f_c(x)$, which is a concave version of $f(x)$ and is somehow like the case in Lemma 1, although the intervals are not equally partitioned. This intuition gives us a hint that even though the curve $f(x)$ is rugged, the smooth effects may still be similar to the convex case in Lemma 1 (although not exactly the same). Then, it is easy to see that $f_c(x)$ is smoother than $f(x)$ because of down-sampling. Therefore, as $l^{\star}(x)$ is smoother than $f_c(x)$ and $f_c(x)$ is smoother than $f(x)$, $l^{\star}(x)$ has smooth effects on $f(x)$, and even better than a mere down-sampling.</p><ul><li>In terms of task 2, I think we have to consider all convexity and corresponding behaviour regarding the candidate pairs… To do task 2, we have to think about the relationship with Lemma 2 and (Definition 2,3,4,5 and Algorithm 2.2,3.2,5).<br>I think a conclusion may be of help: (I am not going to utilize this Lemma to solve task 2. I merely think that this conclusion is beautiful and may be of help, therefore I put it here with proof.)<blockquote><p><font color=Crimson size=4><strong>Lemma 4 (LUC for concave function):</strong></font><font color=DarkRed size=3> if $f:[x^l,x^r]\rightarrow \pmb{R}$ is concave in $I=[x^l,x^r]$, then the optimum LUC function $l^{\star}(x),x\in I$ becomes one of the tangents of $f(x)$ at $x^l$ or $x^r$</font></p></blockquote></li></ul><p><font color=Gray size=3><strong>Proof:</strong><br>① first prove that $l^{\star}(x)$ must be tangent to $f(x)$ in interval $I$.<br>Assume that $l^{\star}(x)$ is not tangent to $f(x)$ in $I$, which indicates that equition $l^{\star}(x)=f(x)$ has two different solutions $x^{-}$ and $x^{+}$ where $x^{-}&lt;x^{+}$. Then, for each $x\in (x^{-},x^{+})$, there exists $0&lt;\lambda&lt;1$ such that $x=(1-\lambda) x^{-} + \lambda x^{+}$, and then $f(x)=f((1-\lambda) x^{-} + \lambda x^{+})&gt;(1-\lambda) f(x^{-}) + \lambda f(x^{+})=(1-\lambda) l^{\star}(x^{-}) + \lambda l^{\star}(x^{+})=l^{\star}((1-\lambda) x^{-} + \lambda x^{+})$, which violates the LUC constraints.<br>② then prove that $l^{\star}(x)$ is tangent to $f(x)$ at $x^l$ or $x^r$.<br>Let $l^{\star}(x)=f’(x_0)(x-x_0)+f(x_0)$, therefore the LUC min objective function $obj(x_0)=l^{\star}(\frac{1}{2}(x^l+x^r))=f’(x_0)(\frac{1}{2}(x^l+x^r)-x_0)+f(x_0)$.<br>Take the first derivative of $obj(x_0)$ and get $obj’(x_0)=f’’(x_0)(\frac{1}{2}(x^l+x^r)-x_0)$. When $obj’(x_0)=0$, then $x_0=(\frac{1}{2}(x^l+x^r)$. Unfortunately, when we take the second derivative of $obj(x_0)$ and get $obj’’(x_0)=f’’’(x_0)(\frac{1}{2}(x^l+x^r)-x_0)-f’’(x_0)$, we find that $obj’’(\frac{1}{2}(x^l+x^r))&lt;0$, which indicates that $obj(x_0)$ reaches the maxima at $\frac{1}{2}(x^l+x^r)$. But we want the minima.<br>Luckily, we find that $obj’(x_0)$ is monotonically increasing in $I^l=[x^l,\frac{1}{2}(x^l+x^r)]$ and monotonically decreasing in $I^r=[\frac{1}{2}(x^l+x^r),x^r]$. Therefore, $obj(x^l)&lt;obj(x), x\in I^l$ and $obj(x^r)&lt;obj(x), x\in I^r$. Therefore, we can just compare $obj(x^l)$ and $obj(x^r)$ in order to determine whether the final $l^{\star}(x)$ locates at $x_l$ or $x_r$.<br>③ finally give the condition for whether $x^l$ or $x^r$ is the tangent point.<br>Solve the inequality $obj(x^r)&gt;obj(x^l)$ and we shall get $\frac{f(x^r)-f(x^l)}{x^r-x^l}&gt;\frac{1}{2}[f’(x^r)+f’(x^l)]$. If this equality holds true, we choose $x^l$ as the tangent point; otherwise, we choose $x^r$. □<br></font></p><ul><li><p>In terms of task 3, it is OK to regard LUC a low-pass filter. But even if LUC coverage is relatively smooth, it still has infinite frequency components, for it is not perfectly sinusioid. As a result, the tool of Fourier Analysis may not be enough to explain the phenomenon that “LUC ignores the rugged surface, no matter how rugged the surface is”. I think the potintial explanation should be based on candidate sets.</p></li><li><p>In terms of task 4, my intuition is to segment the definition set into elment cells. Correspondingly, the function is a 2-D manifold in 3-D space. The 2-D LUC task is to cover the manifold with a linear plate, which is definited within each cell.<br>My intuition tells me that Lemma 2 still holds true for the multi-dimension versions. However, it may not be easy to find the centroids of each element cell, therefore making the statements regarding “element cell division” complicated. One example is that there no longer exists “endpoints” in the 2-D case, but margins instead. Also, the convexivity is more complexed.</p></li></ul><h1 id="Implementation-and-Experiments"><a href="#Implementation-and-Experiments" class="headerlink" title="Implementation and Experiments"></a>Implementation and Experiments</h1><p>Finally, I am going to show you the effectiveness of LUC. I am going to show two examples: one is about LUC applied to a hand-crafted curve, and another is about LUC applied to audio CQT spectrograms. In those examples, time consumptions and comparisons are included. Several challenges subsequently emerge. In this section, I will introduce those experiments and detailed problems.</p><h2 id="Experiment-1-Handcrafted-Noisy-Wave"><a href="#Experiment-1-Handcrafted-Noisy-Wave" class="headerlink" title="Experiment 1: Handcrafted Noisy Wave"></a>Experiment 1: Handcrafted Noisy Wave</h2><p>In this example, the function $f(x):D\rightarrow \pmb{R}$ is designed as: $f(x)=10\sin (0.1x)+\cos (4x) + \mathcal{N}(0,2^2), x\in [0,200]$, where $\mathcal{N}(\mu,\sigma^2)$ represents Gaussian Noise parameterized by mean $\mu$ and std $\sigma$. This curve is shown in the following figure:<img src="https://i.loli.net/2020/10/14/rN4X5VSZJmUWaIB.png" alt="exp_curve_original1.png"><br>(a) is the whole plot, and (b) zooms in $[0,20]$.<br>For simplication, I use sample rate $1$ to sample interval $[0,200]$, forming $\pmb{x} = x[0],x[2],…,x[199]$. Notice that in this section, Python-styled $0-based$ indexing is used, for easy link with codes.</p><h3 id="Configurations"><a href="#Configurations" class="headerlink" title="Configurations"></a>Configurations</h3><p>Before implementing the algorithms, the whole problem still needs more specific definition: what is the hop length and the interval size?<br>When I am talking about hop length, I assumed that the sampling strategy is equal-stepped. In the this experiment, data points are equally sampled.<br>If we denote hop length as $\Delta_h i$ and interval size as $\Delta_I$, and each index interval as $I_i$, then: $I_i[0]+\Delta_h=I_{i+1}[0]$ and $I_i[-1]-I_i[0]=\Delta_I$. For example, the first index interval is $I_0 =[0,1,…,\Delta_I - 1] = [0:0+\Delta_I]$, the second index interval is $I_1 = [\Delta_h:\Delta_h+\Delta_I]$, and the third index interval is $I_2 = [2\Delta_h:2\Delta_h+\Delta_I]$, and so forth.</p><p>Because we can use a for-loop to implement LUC for each interval, let’s just focus on implementing LUC in one interval. When it comes to one interval, then its LP, candidate set and candidate pairs come into use. In this experiment, I compared four algorithms, which are:</p><ol><li>(LP-based) normal LUC algorithm, as introduced by Definition 1</li><li>(LP-based) (non-full) candidate-set algorithm</li><li>(LP-based) full candidate-set algorithm</li><li>accompany-pair algorithm</li></ol><p>I used SciPy to implement LP-based methods by calling <a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.linprog.html">the scipy linprog method</a>.<br>One of the problems is to translate the LUC problem into the standard LP problem. The proof for Lemma 2 has already shown how to achieve this.<br>Another problem is to choose a proper method for LP solution. I tried different methods and concluded that the revised simplex method is most efficient.</p><p>For (non-full) candidate-set algorithm, I applied Algorithm 1,2,3,4 to find the candidate set, and then use LP (whose constraints are based on the candidate set) to find the solutions.</p><p>The full-candidate-set algorithm modifies the candidate-set algorithm by replacing Algorithm 3 with Algorithm 3.2.</p><p>For the accompany-pair algorithm, I apply Algorithm 5 only, which takes the role of LP.</p><h3 id="LUC-Results"><a href="#LUC-Results" class="headerlink" title="LUC Results"></a>LUC Results</h3><p>In this experiment, I set $\Delta_h = 10$ and $\Delta_I = 10$.</p><p>First I extract the first two intervals and do LUC for them. Here is the result: <img src="https://i.loli.net/2020/10/14/Rfe92bHUBSqoI5X.png" alt="exp_verify_lemma2.png"><font color=Gray size=3>The yellow lines indicate candidate-sets, while the red lines indicate the original curve.</font></p><p>Those results verify the correctness of Lemma 2 by showing that at least two zero-slackness constraints are reached. They also show that applying full definition of candidate set does not lead to seriously different results compared with the results obtained by the non-full definition.</p><p>Then, I test the whole curve, which is shown in the following figure:<img src="https://i.loli.net/2020/10/14/7PZFAXfUTQr3gDm.png" alt="exp_LUC_all_methods.png"><font color=Gray size=3>The green-star marks indicate local maxima of the centroid sequence, which are marked mostly by blue marks.</font></p><p>From the whole-curve result we can see several phenomena:</p><ol><li>The accompany-pair algorithm result is the same as the normal-LP algorithm result and the candidate-set-full algorithm result.</li><li>There are slight differences between results of the candidate-set-full algorithm and non-full candidate-set algorithm.</li><li>Peaks are correctly detected regardless of serious noise.</li></ol><p>Phenomenon 1 verifies my Hypothesis 1 and 2, because the candidate-set-full algorithm and the accompany-pair algorithm is grounded on Hypothesis 1 and 2.<br>Phenomenon 2 gives us a hint that we can change candidate-set-full algorithm into non-full candidate-set algorithm without losing much accuracy. In the next section I will compare the time consumption between those two algorithms.<br>Phenomenon 3 verifies the effectiveness of LUC algorithm: after smoothed by LUC, it is OK to directly apply the strict $locmax$ function to the centroid serie and get the desired peaks.</p><p>Next, I will compare each algorithm more deeply regarding their time cost and correctness.</p><h3 id="Time-Consumption"><a href="#Time-Consumption" class="headerlink" title="Time Consumption"></a>Time Consumption</h3><p>For each algorithm, I adjusted interval size $\Delta_I$ and LP methods (except accompany-pair algorithm). I used Monte-Carlo method to reduce the variation of time cost estimation. In this test, I run each case for 100 times. Results are shown in the following figure:<br><img src="https://i.loli.net/2020/10/15/aBU3SZX4i7jsImD.png" alt="exp_time_cost.png"><font color=Gray size=3>Time cost experiment results.</font></p><p>This experiment is done by my old laptop, whose CPU is an Intel CORE i5.<br>From the results, we can observe that:</p><ol><li>The most efficient algorithm is the accompany-pair algorithm, whose time cost is much lower than the others</li><li>Candidate-set algorithm did reduce time cost compaired with normal algorithm, when the simplex-family LP methods are used. However, in when interior-point LP method is used, the candidate-set algorithm will be a little bit slower than normal algorithm.</li><li>The revised simplex LP method is most efficient, while the original simplex LP method is least efficient.</li><li>The full-candidate-set algorithm does not increase time cost too much compared with the non-full-candidate-set algorithm. Still, non-full-candidate-set algorithm is faster.</li><li>The candidate-set algorithms show an interesting trend regarding $\Delta_I$: when $\Delta_I$ increases, time cost do not increase, but even decrease. This may be because that candidate-set filered out most irrelevant constraints and therefore there are less constraints left for LP.</li></ol><h3 id="Influence-of-SNR-and-SIR-on-LUC-Accuracy"><a href="#Influence-of-SNR-and-SIR-on-LUC-Accuracy" class="headerlink" title="Influence of SNR and SIR on LUC Accuracy"></a>Influence of SNR and SIR on LUC Accuracy</h3><h3 id="Influence-of-Interval-Partition-on-LUC-Accuracy"><a href="#Influence-of-Interval-Partition-on-LUC-Accuracy" class="headerlink" title="Influence of Interval Partition on LUC Accuracy"></a>Influence of Interval Partition on LUC Accuracy</h3><h3 id="High-order-LUC"><a href="#High-order-LUC" class="headerlink" title="High-order LUC"></a>High-order LUC</h3><p>It is not a must to apply $locmax$ directly after LUC. Insteac, we can do another LUC after LUC, which can be called as 2-order LUC. An example is shown in the following figure:<br><img src="https://i.loli.net/2020/10/16/vfdNsP1DglLuMjn.png" alt="exp_2-order_LUC_example.png"></p><p>The first LUC, namely first-order LUC, adopts $\Delta_{h1}=1$ and $\Delta_{I1}=10$. This smoothifies the original curve, as shown in (a). The second-order LUC adopts $\Delta_{h2}=5$ and $\Delta_{I2}=10$, and then we get the correct peaks.</p><p>Notice that LUC is good at finding peaks with proper x-axis span. For example, in the figure above, the  index width of each peak is around 20; when $\Delta_{h2}=5$, it is prone to find those peaks because 5 is around the same scale as 20, no matter how low those peaks are; when $\Delta_{h1}=1$, however, it is easier to find peaks of shorter x-axis span.</p><h2 id="Experiment-2-LUC-on-Spectrograms"><a href="#Experiment-2-LUC-on-Spectrograms" class="headerlink" title="Experiment 2: LUC on Spectrograms"></a>Experiment 2: LUC on Spectrograms</h2><p>To demonstrate the potentials of LUC on audio analysis, I did another experiment, in which I applied LUC to find peaks in spectrograms.<br>A spectrogram consists of time-variant spectrums. Those spectrums may be FFT, CQT or mel-spectra etc. Normally, we use color to demonstrate the intensity at each time-frequency. An example of CQT spectrogram is shown as following:<br><img src="https://i.loli.net/2020/10/16/NKvDqsXBnyi6ATE.png" alt="exp2_spectrogram.png"></p><p>If those CQT stuff do not make sense to you, no need to worry. Just remember that our task is to find the peaks (bright stripes) in that spectrogram, ignoring noisy points.</p><h3 id="Dealing-with-low-hight-peaks"><a href="#Dealing-with-low-hight-peaks" class="headerlink" title="Dealing with low-hight peaks"></a>Dealing with low-hight peaks</h3><p>Sometimes, we do not want our model to detect low peaks, althought those peaks are wide enough. This leads to a problem: what exactly is our definition on a desired peak? On the one hand, we want a desired peak to be wide enough (otherwise, it is a fake peak); on the other hand, we want to ignore the peaks which are too low compared with the higher peaks. The first condition can be guarenteed by LUC, but LUC does not provide solution to meet the second condition. An example is shown in the following figure:<br><img src="https://i.loli.net/2020/10/16/whfAVBuby3qlC4x.png" alt="exp_2_low_peak_problem.png"></p><p>Therefore, we have to come up with a new way to discriminate those low peaks from high peaks. My solution is to weight the peaks with salience.</p><p>If a spectrogram $\pmb{S}=[s_{ft}]<em>{F\times T}$ is inputted to a 1-order LUC, I hope my model can output a peak-weight map $\pmb{W}=[w</em>{it}]_{L\times T}$. The relationship between $\pmb{S}$ and $\pmb{W}$ is as such:</p><ol><li>If hop length is $\Delta_h$ and interval size is $\Delta_I$, then $L=floor(\frac{F+\Delta_h-\Delta_I}{\Delta_h})$</li><li>$w_{i}$ refers to the weights at the $i^{th}$ interval centroid.</li></ol><h2 id="Experiment-3-Comparing-LUC-with-Existing-Smoothing-Methods"><a href="#Experiment-3-Comparing-LUC-with-Existing-Smoothing-Methods" class="headerlink" title="Experiment 3: Comparing LUC with Existing Smoothing Methods"></a>Experiment 3: Comparing LUC with Existing Smoothing Methods</h2><p>There are all kinds of existing smoothing methods, among which the most common ones include: low-pass filtering, kernel smoothing, moving average smoothing and local regression.</p><p>In order to fairly compare those methods, I use the same pipeline: signal → smoothing (to be tested) → locmax.</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;strong&gt;by lucainiaoge&lt;/strong&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;div id=&quot;content&quot;&gt;&lt;/div&gt;
&lt;script type=&quot;text/javascript&quot; src=&quot;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default&quot;&gt;&lt;/script&gt;

&lt;h1 id=&quot;Intro&quot;&gt;&lt;a href=&quot;#Intro&quot; class=&quot;headerlink&quot; title=&quot;Intro&quot;&gt;&lt;/a&gt;Intro&lt;/h1&gt;&lt;p&gt;I came up with this idea on October 9th, 2020, when I was considering how to find the overtone peaks in a spectrogram. I happened to be playing LIMBO the previous day, and that inspired me to come up with my idea regarding Linear-upper-coverage (LUC), which converts the peak finding problem into linear optimization subtasks.&lt;/p&gt;</summary>
    
    
    
    
    <category term="math" scheme="https://lucainiaoge.github.io.git/tags/math/"/>
    
    <category term="research" scheme="https://lucainiaoge.github.io.git/tags/research/"/>
    
  </entry>
  
  <entry>
    <title>My Music Thoughts</title>
    <link href="https://lucainiaoge.github.io.git/2020/09/03/my-music-thoughts/"/>
    <id>https://lucainiaoge.github.io.git/2020/09/03/my-music-thoughts/</id>
    <published>2020-09-02T16:00:00.000Z</published>
    <updated>2025-11-11T13:28:51.826Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><div id="content"></div><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>This article summarizes my understandings on music composing and appreciation.<span id="more"></span><p>If you have something to add, or if you simply disagree with me, feel free to comment below!</p><h1 id="Starting-from-Sample-Space"><a href="#Starting-from-Sample-Space" class="headerlink" title="Starting from Sample Space"></a>Starting from Sample Space</h1><p>What is the music sample space? The largest (whole) music sample space is the set of all possible combinitions of musical elements. Actually, the whole musical set is far too large. Great composers can extract the exact subsets which are good compositions.</p><p>When composing music, we try to <strong>reduce our sample space</strong>, or <strong>eliminate the uncertainty in our mind</strong>. This process is like <strong>finding a winding path towards a beautiful hidden corner</strong>. For example, <em>theory of harmony</em> tells us what kind of chords are recommended to be used in certain <em>musical contexts</em>, and this reduces the <em>chord sample space</em> to a few so-called <em>consonant chords</em>.</p><p>Now, we may ask: what is the property of those good subsets, and how to reach them? Well, a musician can write a thousand-paged essay to explain that, maybe from the point of view of melody, harmony, counterpoint and music structures… I am not going to expand those topics here. </p><p>Instead, if we are inspired by information theory, we can find the commonplace of good musical works: they bring something unexpected. Those unexpected can be good melodies, satisfying chord prograssions or impressing performance skills etc.</p><p>This may be a little hard to understand. I will explain this “unexpectation theory” in the next section.</p><h1 id="Music-Appreciation-from-Information-Theory’s-Perspective"><a href="#Music-Appreciation-from-Information-Theory’s-Perspective" class="headerlink" title="Music Appreciation: from Information Theory’s Perspective"></a>Music Appreciation: from Information Theory’s Perspective</h1><h2 id="Appreciation-Eliminate-the-Uncertainty"><a href="#Appreciation-Eliminate-the-Uncertainty" class="headerlink" title="Appreciation = Eliminate the Uncertainty"></a>Appreciation = Eliminate the Uncertainty</h2><p>Appreciating music is like travelling: we aim to encounter the unknown world. From my point of view (and also an information theoretrical point of view), appreciation is centered in acquiring knowledge, eliminating uncertainty, or adding up regularity. (And no matter what we appreciate, like music, sculptures, maths etc.) </p><p>Therefore, just like famous attractions have some landmarks which can “surprise” the tourists (e.g. the spectacular landscape of Yello Stone Park which tourists had never experienced on the scene), musical works should contain something out of listeners’ expectations. This is the intuition from information theory, which defines information as the existance to eliminate uncertainty.</p><p>When appreciating music, we try to <strong>cumulate more information</strong> by decoding the music signal. Again, in information theory’s point of view, we are <strong>eliminating the uncertainty of the world</strong>. Our validation music sample space is then enlarged.</p><h2 id="Why-Listening-to-a-Music-Segment-Again-and-Again"><a href="#Why-Listening-to-a-Music-Segment-Again-and-Again" class="headerlink" title="Why Listening to a Music Segment Again and Again"></a>Why Listening to a Music Segment Again and Again</h2><p>You may be curious about the case that we may listen to a piece of music again and again, enjoying an impressing music moment for many times even if we are familiar with that moment. Why are we so keen on the moment which seemingly cannot surprise us? Well… I explain this with our limited capacity of music decoding.</p><p>Remember one of the music pieces which did not impress you when you first hear, but later when you happened to listen to it again, and then it captivated you. You may have listened to a music segment in that piece over and over again, and each time you listened to that piece, you expected to reach that segment. This was because, when you first listened to that music, you did not successfully decode the music signal into exciting information. Later when your decoder worked better, you captured the moment that important information was decipherd, and you wanted to emphasize that moment over and over again until you could easily decipher the similar information.</p><p>You appreciation skills are improved during this process!</p><p>Then comes the question: how to evaluate “appreciation skills”?</p><h2 id="Our-Appreciation-Skills-Need-Training"><a href="#Our-Appreciation-Skills-Need-Training" class="headerlink" title="Our Appreciation Skills Need Training"></a>Our Appreciation Skills Need Training</h2><p>Different people are sensitive on different things, and this is because of the diversity in their capacities of (music) decoders. For example, many listeners cannot be moved by atonal music because they focus on the jarring sound and cannot acquire artistic information which is impressive to musicians, who may be impressed by the organization of the piece or fantastic chord tensions. This is similar to: illiterate people cannot appreciate the beauty of Euler’s $e^{i\pi}+1=0$ because they do not know the prior knowledge associated with this formula.</p><p>Again, our appreciation skills are in fact the capacity of our decoders.</p><p>How to train those skills? First, we need training data. The key is trying to appreciate unfamiliar music and look for the surprising moments, which is like visiting an unknown place on your own. Another choice is to check music reviews (some of which are logs of the beautiful moments of a music piece), and this process is similar to visiting an attraction with a tour guide.</p><p>Of course, even if we are well-trained to appreciate music, we cannot despise the music we have already familar with. After all, we upgraded out decoder system thanks to them. And more importantly, there may remain something we did not discover in the music even if we think we are well familiar with.</p><h1 id="How-About-Music-Composing"><a href="#How-About-Music-Composing" class="headerlink" title="How About Music Composing"></a>How About Music Composing</h1><p>We have established the point that listeners are to be surprised when appreciating music. Therefore, composers have to <strong>surprise the listeners</strong> in order to create impressing works.</p><p>What does <strong>surprising the listeners</strong> mean? This is not necessarily mean that they have to use “$\pmb{pppp} \rightarrow \pmb{ffff}$” to startle the listeners. This is to say that they have to <strong>convey important information which is out of listeners’ expectations</strong>, just as we have already discussed.</p><h2 id="The-Case-of-Pop-Music"><a href="#The-Case-of-Pop-Music" class="headerlink" title="The Case of Pop Music"></a>The Case of Pop Music</h2><p>For listeners who did not receive a lot of appreciation training, a fairly normal chord progression could grasp their attentions and make them feel surprised and happy. Hence, most pop music composers achieve this by applying easy-listening chord progressions and music structures to their music, and they focus on writing “surprising” melodies, which are normally easy to appreciate.</p><p>In this case, the music sample space of the composer may be greatly larger than listeners. Composers should find the music samples at the edge of listeners’ music sample spaces, and this is enough to entertain listeners.</p><p>The intersection of the music sample spaces of most people form the set of universal pop music. What about the rest (which may be a lot larger)?</p><h2 id="The-Case-of-All-Kinds-of-Music"><a href="#The-Case-of-All-Kinds-of-Music" class="headerlink" title="The Case of All Kinds of Music"></a>The Case of All Kinds of Music</h2><p>For listeners who are well-trained, they may seek for an unexpected music element combination (remember, it is actually a sample point of the music sample space). This challenges composers to explore their music sample spaces, and this is the fairly interesting: because not everyone share the same music sample space, the hidden corner you visited is not likely to be visited by others.</p><p>Before surprising the listeners, composers had better first surprise themselves, and this needs composers to have be skillful at appreciation, which means that they have to dig out more and more information. In other words, composers themselves have to own powerful decoders.</p><p>But where do the surprising things come from? You know that even if you have a good decoder, you may not have musical codes to feed into the decoder. And this is where generative models are crutial!</p><h2 id="Randomness-Generative-Models-and-Sampling"><a href="#Randomness-Generative-Models-and-Sampling" class="headerlink" title="Randomness, Generative Models and Sampling"></a>Randomness, Generative Models and Sampling</h2><p>To be frank, we do generation by implementing randomness. We randomly sample music data points from our music sample spaces. Main differences between composers lie in <strong>1. the structure of music sample spaces</strong>, <strong>2. their sampling strategies</strong> and <strong>3. their appreciation skills</strong>. Appreciation skills are analyzed in the previous section. Therefore, I mainly talk about the other two.</p><p>First talk about music sample spaces. Remember the first section? I put it here again…</p><blockquote><p>When composing music, we try to <strong>reduce our sample space</strong>, or <strong>eliminate the uncertainty in our mind</strong>. This process is like <strong>finding a winding path towards a beautiful hidden corner</strong>.</p></blockquote><p>Yeah, good composers know how to reduce their sample spaces. They may use harmony theory to exclude the bad chords, and thus the amount of remaining music data points are smaller. They also have other constraints on their sample spaces, like: melody alignments, music structures, instruments etc. You know, it is fairly easy to sample a data point from a small sample space according to their wills!</p><p>In order to be skillful at reducing the sample space, composers need to know what compact sample spaces look like. Therefore, they had better learn harmony theory, music structures, counterpoint and different music styles. All aspects lead to certain compact sample spaces, and great composers are skilled in pinpointing the required compact sample space.</p><p>Now let’s go to another question: even if we have a compact sample space, how to sample a music data point from that space?</p><h2 id="Randomness-and-Sampling-Stratagies-for-Music"><a href="#Randomness-and-Sampling-Stratagies-for-Music" class="headerlink" title="Randomness and Sampling Stratagies for Music"></a>Randomness and Sampling Stratagies for Music</h2><p>Notice that the famous generative models (e.g. HMM, VAE, GAN) all depend on randomness, and they achieve generation by sampling their <strong>sample space</strong> in various ways. With a good sampling stratagy (e.g. conferring to the thinking pattern of first determining the music structure), you can have a good start point to converge your chaotic mind into a relatively small sample space.</p><p>Music is contextulized. Therefore, we do sampling according to contexts. Most composers may sample their music measure by measure, and the result might be that their music do not have a good structure. This is similar to the strategy of RNNs.</p><p>Another strategy is to first determine some global constraints and then do sampling over time. This is the case of most composers because this safe guards a good music structure. This is similar to the strategy of transformers.</p><p>What about music with unexpected beautiful organizations? Chances are that composers see the music structures as non-deterministic, and they have a unique subset of sample space for music organizations. They first sample a music organization, and then follow the traditional way as described before.</p><p>Of course there are many many other ways I have not mentioned. For example, some avant-guard compsers may record natural sounds and reorganize them as a music work, which is totally unconventional. This is where composers have to explore various of ways of sampling, and this is where to expand the border of art!</p><h2 id="Go-Practice"><a href="#Go-Practice" class="headerlink" title="Go Practice"></a>Go Practice</h2><p>A last topic, how to practice composing music?</p><p>We have to know that, when practicing to compose music or perform music, we try to <strong>revisit the winding paths towards beautiful hidden corners</strong>. This is because we are humans rather than GODs (who know the global maxima), and we have to struggle to do optimization, just like training the machine learning models.</p><p>On the one hand, if you find an unvisited “winding path” (e.g. a unique melody), you can revisit it over and over again until you can introduce it to others, and then you become a composer! You must train yourself to be familiar with the process of <strong>encoding the “winding path” into audios or music language</strong>. Remember not all people have visited those winding paths. Therefore, practicing to efficiently encode your music minds into music signals can let a composer quickly impress the audience.</p><p>On the other hand, your decoder should also be sensitive enough to discover the winding paths in your chaotic mind or the colorful world! In this case, you should try to listen to more music you did not tried, and push yourself into digging out surprising information from them, or even imitate them. Just as I had explained previously.</p><p>Another thing you can really do is to optimize your <strong>sampling stratagy</strong>, or the composition process. You have to try a lot in order to find a desirable process. For me, I am kind of conventional that I use draft scores to compose music instead of use DAW. What about you? Try try try!</p><p>Finally, your chaotic mind, the generation source. Well, your mind can be influenced by external conditions like changing moods or spirits. Therefore, try to find different envirments of composing.</p><p>Go practice, think more, and appreciate more!</p><h1 id="Algorithm-Composing"><a href="#Algorithm-Composing" class="headerlink" title="Algorithm Composing"></a>Algorithm Composing</h1><p>In fact, all of my discussions above can be instructions for designing algorithm composing models.</p><p>Algorithm composing models face the same challenges: to constrain the sample space, to have a sample stratagy, to have a good decoder and a good discriminator, to be optimized in order to be familiar with the “winding paths”…</p><p>Interestingly, you can find corresponding topics in machine learning in terms of each of the aspect I mentioned above. Let’s go and see!</p><h1 id="A-Problem-of-My-Theory-Above"><a href="#A-Problem-of-My-Theory-Above" class="headerlink" title="A Problem of My Theory Above"></a>A Problem of My Theory Above</h1><p>[Updated on 30-April-2021]<br>I might have taken it for granted that we tend to appreciate music which brings us surprise. How to explain the phenomenon that the music which sounds common is popular? For example, experiments have shown that car-radio listeners tend to prefer music which sounds typical (the so-called “sticky music”), rather than classical music which have abundant artistic information. And how can we explain that we listen to a piece of music again and again, even if we know that we are quite familiar with that? For example, after finishing composing a piece of music, I tend to listen to it again and again even if I am the composer and I know that I know a lot about it; and sometimes I listen to a pop song again and again. How to expain them?</p><p>In my previous opinion, I defined happiness as knowing something unexpected. However, a friend of mine inspired me that happiness might also come to us when some of our expectation are met. (We were discussing why people get unhappy, and we found that a great reason is that their expectations, from either subconscious or conscious, are not reached.)</p><p>What is expectation? Can we explain it with a definition, like “surprise is elimination of uncertainty, which is measured by entropy”? Well… For me, it is a big problem to be solved. But I have an idea that habit is a kind of expectation. Most of our habits work in our subconscious; therefore, when we find ourself appreciating a familiar old song, we may say that we find our subconscious is feeding on that old song by meeting its expectation.</p><p>Here, the two theories seem to fight with each other: when we define happiness as eliminating uncertainty, we may say that things are happening out of our expectation (if not, we may not be surprised), but we cannot explain the case when we are appreciating a piece of familiar music and enjoying one particular moment again and again; when we define happiness as meeting our expectation, we cannot explain the euphoria of listening to a great symphony. There must exist a theory which is able to blend those two into one (and I think the great theory of happiness exists because of Hegel’s dialectics).</p><p>I think the main difference between those two theories lie on the quality of happiness: the “surprise theory” dipicts a “tired but happy” case, while the “expectation theory” dipicts a “safe and sound” case. Our habits tend to listen to music which is familiar to us, and they do not consume much of our computation resource in our mind; when we find ourself being able to appreciate a symphony, we have consumed a lot in our mind, and we find that we did not consume it in vain because we found something unexpected.</p><p>How to explain when doing experiments, we get an everything ruined (e.g. unexpect error in coding), and get mad? How to explain when listening to a piece of music, we get startled by a wrong note played by the music performer and get angry? In those cases, our expectations are not met at all, but we consumed a lot of mental energy. It seems that, when knowing something unexpected, we get either happy or unhappy, and we really have to tell the difference between those two cases.</p><p>To sum up, we have four cases:</p><ol><li>we did not consume much mental energy, but get something expected;</li><li>we consumed a lot of mental energy, and get something expected;</li><li>we did not consume much mental energy, but get something unexpected;</li><li>we consumed a lot of mental energy, and get something unexpected.</li></ol><p>We did not discuss case 2 and case 3; but we demonstrated that case 1 brings happiness and case 4 could bring either happiness or unhappiness. When thinking about our experiences, we could find that case 3 could bring either happiness or unhappiness, while case 2 is complicated…</p><p>It seems that happiness is a rather complicated thing to be explained. I believe that it could be measured and decomposed into more elementary concepts. However, my assumption that “elimination of uncertainty brings happiness” might be incorrect; or I should endow this statement a more suitable definition.</p>]]></content>
    
    
    <summary type="html">&lt;div id=&quot;content&quot;&gt;&lt;/div&gt;
&lt;script type=&quot;text/javascript&quot; src=&quot;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default&quot;&gt;&lt;/script&gt;
This article summarizes my understandings on music composing and appreciation.</summary>
    
    
    
    
    <category term="philosophy" scheme="https://lucainiaoge.github.io.git/tags/philosophy/"/>
    
    <category term="music" scheme="https://lucainiaoge.github.io.git/tags/music/"/>
    
  </entry>
  
  <entry>
    <title>Intuition for Statistical Inference</title>
    <link href="https://lucainiaoge.github.io.git/2020/08/03/intuition-for-statistical-inference/"/>
    <id>https://lucainiaoge.github.io.git/2020/08/03/intuition-for-statistical-inference/</id>
    <published>2020-08-02T16:00:00.000Z</published>
    <updated>2025-11-11T13:28:51.810Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><strong>by lucainiaoge</strong></p><hr><div id="content"></div><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script><h1 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h1><p>In a word, statistical inference deal with the problem of “trying to reach the God”. In other words, we observe data, and we try to fit to the distribution of such data. A little bit hard to understand? Hope that this article can help you understand that…</p><span id="more"></span><ul><li><strong>An example: pictures</strong></li></ul><blockquote><p>Suppose you are studying digital pictures $x \in \pmb{R^{M\times M}}$. Accordingly, its distribution is $p_G(x): \pmb{X_{G}} \rightarrow \pmb{R^+}\cup\pmb{O}$. One of our goals is to find exactly the subspace $\pmb{X_{G}}\subseteq\pmb{R^{M\times M}}$ where the pictures $x \in \pmb{X_{G}}$ look like hand-written numbers (correspondingly, $\pmb{X_{G}}$ is the space where the ${M\times M}$ hand-written number pictures are defined). Again, our mission is to find the  $p_G(x): \pmb{X_{G}} \rightarrow \pmb{R^+}\cup\pmb{O}$ given a hand-written number dataset $\pmb{X_{s}}$.</p></blockquote><blockquote><p>We take $\pmb{X_{G}}$ as the “God/Ground-truth dataset” and $\pmb{X_{s}} \subseteq \pmb{X_{G}}$ as the “observation dataset” (e.g. MNIST).</p></blockquote><p>Now, question is: how to fit to that God/Ground-truth distribution? Well… For each question, we have to represent it before we solve it. In this article, I try to represent it clearly.</p><p>This article does not try to solve those questions explicitly. The aim of this article is to remind you what you are really doing when you get lost in some annoying math works.</p><p>By the way, why it is important to estimate $p_G(\pmb{x})$? Because once we know $p_G(\pmb{x})$, we can do such things: 1. to judge whether a given data point $x_0$ belongs to our distribution $p_G(\pmb{x})$, and then we can do classification; 2. to sample data points according to $p_G(\pmb{x})$, and then we can do generation!</p><h1 id="The-Variational-Problem"><a href="#The-Variational-Problem" class="headerlink" title="The Variational Problem"></a>The Variational Problem</h1><p>We have already been familiar with this form: given a vector space $X$ (e.g. $X=\lbrace 0,1,2 \rbrace$) and a function $f$ (e.g. $f(x)=x^2$), we want to solve<br>$$\mathrm{argmax}_{x∈X} f(x)$$<br>What about the argmax problem which finds the optimum function? i.e. given a function space $\mathcal{F}$ (e.g. $\mathcal{F}=\lbrace f: f(x)=x^2+c,c\in \pmb{R} \rbrace$) and a <strong>functional</strong> $F: \mathcal{F}→\pmb{R}$ (e.g. $F[f]=\int_0^1 f^2(x)dx$), we want to calculate:</p><p>$$\mathrm{argmin}_{f∈\mathcal{F}} F[f]$$</p><p>This problem is called a <strong>variational problem</strong>, which aims to find a function $f∈\mathcal{F}$ which minimizes/maximizes a functional $F$.</p><p>We have already encountered this kind of problem in information theory!<br>For example, we have already found the “discrete maximum entropy”</p><p>$$\mathrm{argmax}_{p∈\mathcal{P}} H[p]$$</p><p>If $\mathcal{P}= \lbrace AllDiscreteDistributionsWith\quad M \quad Values \rbrace$, and $H[p(x)]=\sum_{x}p(x)  \mathrm{log}⁡ \frac{1}{p(x)}$, then </p><p>$$\mathrm{argmax}_{p∈\mathcal{P}} H[p]=U(x)$$</p><p>where, $U(x)$ is the uniform distribution on $M$ possible discrete values.</p><h1 id="The-Statistical-Inference-Variational-Problem"><a href="#The-Statistical-Inference-Variational-Problem" class="headerlink" title="The Statistical Inference Variational Problem"></a>The Statistical Inference Variational Problem</h1><h2 id="Problem-definitions"><a href="#Problem-definitions" class="headerlink" title="Problem definitions"></a>Problem definitions</h2><p>What we want to do is: given data $\pmb{x}$, we want to approximate its distribution $p_G(\pmb{x})$. i.e. we want to solve this variational problem:</p><p>$$p^*(\pmb{x})=\mathrm{argmax}_{p∈\mathcal{F}} D[p(\pmb{x}),p_G (\pmb{x})]$$</p><p>The term $p_G (\pmb{x})$ means the God’s distribution of data $\pmb{x}$, or the “Ground truth distribution”. Well, I have to say that we assumed that there is a ground truth (or GOD!), which is our philosophical point of view.<br>Now is the problem:</p><blockquote><ul><li>Problem 1: How to define the functional (distance between distributions) $D[p(\pmb{x}),p_G (\pmb{x})]$?</li><li>Problem 2: How to define the function space $\mathcal{F}$?</li></ul></blockquote><h3 id="Problem-1-where-the-“Maximum-Likelihood”-comes-from"><a href="#Problem-1-where-the-“Maximum-Likelihood”-comes-from" class="headerlink" title="Problem 1: where the “Maximum Likelihood” comes from"></a>Problem 1: where the “Maximum Likelihood” comes from</h3><p>Problem 1: how to find the functional (distance between distributions) $D[p(\pmb{x}),p_G (\pmb{x})]$? Note that we do not know the GOD distribution i.e. $p_G(\pmb{x})$. Thus, it is impossible to calculate this functional by directly calculating the distance between $p(\pmb{x})$ and GOD distribution. However, there is an easy way to define $D[p(\pmb{x}),p_G (\pmb{x})]$ as:<br>$$D[p(\pmb{x}),p_G (\pmb{x})]≜\mathrm{log}⁡p(\pmb{x})$$(Other ways include estimating the momentums or other sufficient statistics. Those are out of the current scope.)<br>For i.i.d. data $\pmb{x}$, we can even write $\mathrm{log}⁡p(\pmb{x})$ as $\mathrm{log}⁡p(\pmb{x})=\sum_{i=1}^N \mathrm{log}⁡p(x_i)$<br>The term $\mathrm{log}⁡p(\pmb{x})$ is called as “log-likelihood”, and the variational problem $p^*(\pmb{x})=\mathrm{argmax}_{p∈\mathcal{F}} D[p(\pmb{x}),p_G (\pmb{x})]$ is called “maximum likelihood”, which we have already been familiar with.<br>(Note that in the scheme of “maximum likelihood”, we did not consider $p_G (\pmb{x})$ explicitly. We assumed that if $\pmb{x}$ is from the ground-truth, $p_G (\pmb{x})$ should always be larger or equal than other $p(\pmb{x})$. We tend to think that “what we see is GOD”. Or in other words, “data (what we observed) are all we know, and we cannot do better unless we know more information (more data, or more observations)”. The “<a href="https://en.wikipedia.org/wiki/Method_of_moments">momentum estimation method</a>” directly applies this philosophical assumption, i.e. calculating the distances between moments in order to make $p(\pmb{x})$ as near as  $p_G (\pmb{x})$.)</p><h3 id="Problem-2-to-parameterize-or-not-to"><a href="#Problem-2-to-parameterize-or-not-to" class="headerlink" title="Problem 2: to parameterize or not to"></a>Problem 2: to parameterize or not to</h3><p>Well… For problem 2, we have two ways: to parameterize or not.<br>What is parameterization? I use an example to illustrate that:<br>Suppose the data $\pmb{x}$ are 1D. And we assume the function space is Gaussian, i.e. $\mathcal{F}=\lbrace AllOneDimGaussianPDFs \rbrace$. We can easily write $\mathcal{F}$ in the form of the space of its sufficient statistics (i.e. $\mu$ and $\sigma$). In other words, the space $\Theta=\pmb{R}\times\pmb{R^+}$ is actually the function space $\mathcal{F}$. And there exists a unique Gaussian Function $G:\Theta→\mathcal{F}$ such that for any $(\mu,\sigma)∈\Theta$, $G(\mu,\sigma)=f(x\vert \mu,\sigma)∈\mathcal{F}$<br>In this case, we parameterized $\mathcal{F}$ with $\Theta$, with the distribution assumption $P:\Theta→\mathcal{F}$. In other words, $\Theta$ are the parameters which control the function space. Thus, the variational problem<br>$$p^*(\pmb{x})=\mathrm{argmax}_{p∈\mathcal{F}} D[p(\pmb{x}),p_G (\pmb{x})]$$</p><p>can be written as an argmax problem for parameters:</p><p>$$\theta^*=\mathrm{argmax}_{\theta∈\Theta} D[f(\pmb{x}\vert\theta),p_G (\pmb{x})]$$</p><p>$$p^* (\pmb{x})=P(\theta^* )$$</p><p>Of course, we can search the $\mathcal{F}$ directly without introducing $\Theta$ and $P:\Theta→\mathcal{F}$. How to search $\mathcal{F}$ given $\pmb{x}$? There are also various ways (e.g. $k-means$). However, we are not talking about those methods right now.</p><h3 id="A-statement-for-a-challenge-how-to-find-the-God-bias-vs-variance"><a href="#A-statement-for-a-challenge-how-to-find-the-God-bias-vs-variance" class="headerlink" title="A statement for a challenge: how to find the God - bias vs. variance"></a>A statement for a challenge: how to find the God - bias vs. variance</h3><p>How to assume a nice function space $\mathcal{F}$ such that the $p^* (\pmb{x})∈\mathcal{F}$ is easy to find and that $D[p(\pmb{x}),p_G (\pmb{x})]$ is relatively small? In other words, the function space $\mathcal{F}$ (or parameter space $\Theta$ in the case of parameterization) should satisfy such properties in order to be a good one:</p><blockquote><ol><li>there exists $p^* (\pmb{x}))∈\mathcal{F}$ such that $D[p(\pmb{x}),p_G (\pmb{x})]$ is small, i.e. $\mathrm{E}_{\pmb{x}\in\pmb{X_G}} [D[p(\pmb{x}),p_G (\pmb{x})]]$ is small;</li><li>$D[p(\pmb{x}),p_G (\pmb{x})]$ cannot be too unstable, i.e. $\mathrm{Var}_{\pmb{x}\in\pmb{X_G}} [D[p(\pmb{x}),p_G (\pmb{x})]]$ is small.</li></ol></blockquote><p>If $\mathrm{E}_{\pmb{x}\in\pmb{X_G}} [D[p(\pmb{x}),p_G (\pmb{x})]]$ is small, we say that the function space F is of small bias compared with the GOD’s function $p_G (\pmb{x})$;</p><p>If $\mathrm{Var}_{\pmb{x}\in\pmb{X_G}} [D[p(\pmb{x}),p_G (\pmb{x})]]$ is small, we say that the function space $\mathcal{F}$ is of small variance compared with the GOD’s function $p_G (\pmb{x})$, or that our model $p^* (\pmb{x})$ has a good ability to generalize. The term “generalize” means that no matter what data $\pmb{x}$ is given, the difference between $p^* (\pmb{x})$ and $p_G (\pmb{x})$ will not change too much.</p><p>Intuition from Hung-yi Lee: see the pictures in<br><a href="http://speech.ee.ntu.edu.tw/~tlkagk/courses/ML_2016/Lecture/Bias%20and%20Variance%20(v2).pdf">http://speech.ee.ntu.edu.tw/~tlkagk/courses/ML_2016/Lecture/Bias%20and%20Variance%20(v2).pdf</a></p><p><img src="https://i.loli.net/2020/08/03/hkIGbLB6nuM73sK.png" width="50%" height="50%"><img src="https://i.loli.net/2020/08/03/OHZu2yWABVl3Cgb.png" width="50%" height="50%"></p><p>Each “sample point $p_s^* (\pmb{x})$” is actually an instance of $p_s^*(\pmb{x})=\mathrm{argmax}_{p∈\mathcal{F}} D[p(\pmb{x}),p_G (\pmb{x})]$, where $\pmb{x}\in\pmb{X_s}$, and $\pmb{X_s}$ (e.g. MNIST) is a subset of the God data set $X_G$ (e.g. all possible  pictures of handwritten numbers).</p><h2 id="Afterwards…"><a href="#Afterwards…" class="headerlink" title="Afterwards…"></a>Afterwards…</h2><p>You have already got an intuition of our challenges. Now, time to solve the challenges! Of course, for several specific problems, simple models are enough! For example, if we want to fit a Gaussian distribution, the most convenient way is to calculate the mean and variance of the dataset (observation). However, most problems are complex in reality. We have to design models which can deal with such complexity.</p><p>A genious way is to introduce Latent Variables to make our models more powerful. We assume that the Latent Variables can reveal the underlying modes of our observations. How to calculate the Latent Variables and find the argmax? We will discuss later when introducing HMM (Hidden Markov Model), GMM (Gaussian Mixure Model), EM (Expectation Maximization) algorithm and variational inference. The Latent Variable trick is in fact a statistical assumption.</p><p>Another genious way is to use Neural Networks in order to fit arbitrary functions. The Neural Networks trick is in fact a structural (connectivism) assumption.</p><p>In order to reduce the variance, more tricks can be considered (e.g. early stopping, dropout, normalization, residual connection, parameter sharing, simplified models…). Details are overwhelming. Not going to introduce them here!</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;strong&gt;by lucainiaoge&lt;/strong&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;div id=&quot;content&quot;&gt;&lt;/div&gt;
&lt;script type=&quot;text/javascript&quot; src=&quot;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default&quot;&gt;&lt;/script&gt;

&lt;h1 id=&quot;Intro&quot;&gt;&lt;a href=&quot;#Intro&quot; class=&quot;headerlink&quot; title=&quot;Intro&quot;&gt;&lt;/a&gt;Intro&lt;/h1&gt;&lt;p&gt;In a word, statistical inference deal with the problem of “trying to reach the God”. In other words, we observe data, and we try to fit to the distribution of such data. A little bit hard to understand? Hope that this article can help you understand that…&lt;/p&gt;</summary>
    
    
    
    
    <category term="machine_learning" scheme="https://lucainiaoge.github.io.git/tags/machine-learning/"/>
    
    <category term="philosophy" scheme="https://lucainiaoge.github.io.git/tags/philosophy/"/>
    
  </entry>
  
  <entry>
    <title>A Summarization for Labs and People in Music Technology (Useful Links Attached!)</title>
    <link href="https://lucainiaoge.github.io.git/2020/08/02/music-computation-labs-and-people-and-useful-links/"/>
    <id>https://lucainiaoge.github.io.git/2020/08/02/music-computation-labs-and-people-and-useful-links/</id>
    <published>2020-08-01T16:00:00.000Z</published>
    <updated>2025-11-11T13:28:51.826Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>(2020) I was trying to summarize labs and researchers around the world who dedicate in music computation. I was writing this list because I really wanted to do researches about MIR and music generation. Of course, this list is far from complete, and will be out-of-date in a few years. If you have recommendations, feel free to comment below!</p><hr><div id="content"></div><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script><span id="more"></span><h1 id="If-You-Did-not-Know-about-MIR"><a href="#If-You-Did-not-Know-about-MIR" class="headerlink" title="If You Did not Know about MIR"></a>If You Did not Know about MIR</h1><p><font color=gray> Here is a superfacial introduction for starters and for people who are interested in music computation.</font></p><p>MIR means Music Information Retrieval. Its relevant topics are broad! If I am talking about MIR, I am refering to the topics which trie to analyze everything about music in a technological fashion. In many cases, MIR is a term which has the same meaning with “music computation”. <font color=gray>By the way, another term “music technology” mainly means topics about synthesizers, digital music formats (e.g. MIDI, mp3) and instruments, which emphasizes differently from the term “MIR”.</font></p><p>You may be curious about how to identify a song by humming, which is an MIR topic called <a href="https://en.wikipedia.org/wiki/Query_by_humming">Query by Humming (wiki)</a>. You may also be curious about how to translate a musical performance into scores, which is an MIR topic called <a href="https://www.researchgate.net/publication/330068609_Automatic_Music_Transcription_An_Overview">automatic music transcription (AMT) (paper)</a>. Other interesting topics include <a href="https://medium.com/@briansrebrenik/introduction-to-music-recommendation-and-machine-learning-310c4841b01d">music recommendation (blog)</a>, <a href="https://medium.com/@krisshaffer/what-is-computational-musicology-f25ee0a65102">computational musicology (blog)</a>, <a href="https://soundtraining.com/synthesis-a-basic-understanding/">sound synthesizing (blog)</a> and <a href="https://en.wikipedia.org/wiki/Algorithmic_composition">algorithm composing (wiki)</a> etc., which are all relevant topics.<br>Search “MIR” in wiki: <a href="https://en.wikipedia.org/wiki/Music_information_retrieval#References">https://en.wikipedia.org/wiki/Music_information_retrieval</a>.</p><p>Those listed above are all tasks/goals. But what about the methodology to achieve them? Remember: music is created by people. Therefore, tasks about understanding musical rules and phenomenons are actually tasks about understanding human thoughts. How to understand them?<br>Well… On the one hand, the nature of music is audio and the nature of musical understandings is human cognition; thus, we have to deal with audio properties and human perceptions. Relevant techonologies include <a href="https://en.wikipedia.org/wiki/Digital_signal_processing">Digital Signal Processing (wiki)</a>, <a href="https://en.wikipedia.org/wiki/Synthesizer">Synthesizer (wiki)</a> and <a href="https://www.researchgate.net/publication/324721430_An_Introduction_to_Cognitive_Musicology_Historical-Scientific_Presuppositions_in_the_Psychology_of_Music">Cognitive Musicology (paper)</a>.<br>On the other hand, music is a kind of rule-based art, and we are interested in such rules. But how to understand and apply such rules? Relevant methods include <a href="https://music.arts.uci.edu/dobrian/CD.music.lang.htm">Music as Language (paper)</a>, <a href="https://en.wikipedia.org/wiki/Natural_language_processing">Natural Language Processing (NLP)(wiki)</a>. We know that the “rules” in rule-based-arts are far from simple. Therefore, we have to use systems which have great complexity to fit to those rules. Such method is <a href="https://www.internetsociety.org/resources/doc/2017/artificial-intelligence-and-machine-learning-policy-paper/?gclid=Cj0KCQjwyJn5BRDrARIsADZ9ykEnMQdP44IZ9_PlHJ2KOTHFgnnQ15DvdeIeIjVRyRo3HWru2BA0YtoaAkX6EALw_wcB">machine learning (paper)</a>.<br>With such tools, we can deal with problems which are directly relevant to music. For example, we can design our “generative music language”, and then apply it for algorithm composing. Or we can apply the DSP methods to identify chords from audio. Of course, every topic has its unique side. Therefore, never stop learning!</p><p><strong>The following links in the rest of this page are all relevant with what I introduced before.</strong></p><h1 id="Labs-Groups-and-Individual-Researchers"><a href="#Labs-Groups-and-Individual-Researchers" class="headerlink" title="Labs, Groups and Individual Researchers"></a>Labs, Groups and Individual Researchers</h1><h2 id="Links-of-Summarizations"><a href="#Links-of-Summarizations" class="headerlink" title="Links of Summarizations"></a>Links of Summarizations</h2><blockquote><ul><li>Research Centers Summarized by SMC:<br><a href="http://www.smcnetwork.org/centers.html">http://www.smcnetwork.org/centers.html</a><br>This is a comprehensive list, which includes groups mainly in Europe and America.</li></ul></blockquote><blockquote><ul><li>Archives, Journals and Societies about “Science &amp; Music” by University of Cambridge, Center for Music and Science:<br><a href="https://cms.mus.cam.ac.uk/links">https://cms.mus.cam.ac.uk/links</a><br>This page is a summarization of research groups and research society mainly in Europe. You may find links of research groups as well as academic sources in this page.</li></ul></blockquote><blockquote><ul><li>Research Centers Summarized by Beici Liang:<br><a href="https://mp.weixin.qq.com/s/2nDWikda9fh2x5o093F6HA">https://mp.weixin.qq.com/s/2nDWikda9fh2x5o093F6HA</a><br>The groups mentioned in this list are mostly in universities. By the way, the wechat official account (in Chinese 中文) in this link is a tutorial for beginners who are interested in music tech.</li></ul></blockquote><p>I give those comprehensive links first. After all, I have to reinvent the wheel because I cannot remember all of them unless I write them down and read them all.</p><h2 id="My-summarization"><a href="#My-summarization" class="headerlink" title="My summarization"></a>My summarization</h2><p>Here is a summarization of research group websites I have visited. My list is far from complete. I am just writing them down in order to have a review on the MIR society I have explored, straightening my mind. After all, I felt dizzy when I first began to search about MIR groups around the world…<br>If you are a starter, hope that the following links can help you. If you are already a researcher, well… hope that my naive list does not bother you and that you can give some suggestions!<br><strong>Note that the information here is limited. I may have left out or misunderstood a lot of information. Therefore, the information in my list is inevitably biased! Again, this list is created mainly for myself and for starters to get familiar with the MIR society. If I wrote something improper, please contact me for correction!</strong></p><p><font color=gray>…To be expanded</gray></p><h3 id="Europe"><a href="#Europe" class="headerlink" title="Europe"></a>Europe</h3><blockquote><ul><li>Center for Digital Music (C4DM), Queen Mary University of London (QMUL)<br><a href="http://c4dm.eecs.qmul.ac.uk/index.html">http://c4dm.eecs.qmul.ac.uk/index.html</a><br>A very big lab with many groups.</li></ul></blockquote><blockquote><ul><li>Digital and Cognitive Musicology Lab (DCML), École polytechnique fédérale de Lausanne (EPFL)<br><a href="https://www.epfl.ch/labs/dcml/">https://www.epfl.ch/labs/dcml/</a><br>Led by <a href="https://people.epfl.ch/martin.rohrmeier">Prof. Martin Alois Rohrmeier</a>. </li></ul></blockquote><blockquote><ul><li>Music Technology Group (MTG), Universitat Pompeu Fabra (UPF), Barcelona<br><a href="https://www.upf.edu/web/mtg/">https://www.upf.edu/web/mtg/</a></li></ul></blockquote><blockquote><ul><li>Center for Music and Science (CMS), Faculty of Music, University of Cambridge.<br>Faculty of Music: <a href="https://www.mus.cam.ac.uk/">https://www.mus.cam.ac.uk/</a>; CMS: <a href="https://cms.mus.cam.ac.uk/">https://cms.mus.cam.ac.uk/</a></li></ul></blockquote><blockquote><ul><li>Prof. Remco Veltkamp, Utrecht University<br><a href="http://www.cs.uu.nl/centers/give/multimedia/music/index.html">http://www.cs.uu.nl/centers/give/multimedia/music/index.html</a></li></ul></blockquote><h3 id="Asia"><a href="#Asia" class="headerlink" title="Asia"></a>Asia</h3><blockquote><ul><li>Laboratory of Audio and Music Technology (FD-LAMT), Fudan University<br><a href="http://homepage.fudan.edu.cn/weili/fd-lamt/">http://homepage.fudan.edu.cn/weili/fd-lamt/</a><br>Led by Prof. Wei Li.</li></ul></blockquote><blockquote><ul><li>Musix X Lab, New York University Shanghai (NYU Shanghai)<br><a href="http://www.musicxlab.com/#/index">http://www.musicxlab.com/#/index</a><br>Led by <a href="https://www.cs.cmu.edu/~gxia/">Prof. Gus Xia</a>.</li></ul></blockquote><blockquote><ul><li>Sound &amp; Music Computing Lab, National University of Singapore (NUS)<br><a href="https://smcnus.comp.nus.edu.sg/">https://smcnus.comp.nus.edu.sg/</a><br>Currently Led by <a href="https://smcnus.comp.nus.edu.sg/ye-wang/">Prof. Ye Wang</a>. </li></ul></blockquote><blockquote><ul><li>Affective Computing and AI Team (AMAAI), Singapore University of Technology and Design (SUTD)<br><a href="https://dorienherremans.com/team">https://dorienherremans.com/team</a><br>Currently Led by <a href="https://dorienherremans.com">Prof. Dorien Herremans</a>.</li></ul></blockquote><h3 id="America"><a href="#America" class="headerlink" title="America"></a>America</h3><blockquote><ul><li>Center for Music Technology, Georgic Tech (GaTech).<br><a href="https://gtcmt.gatech.edu">https://gtcmt.gatech.edu</a><br>Currently Led by <a href="http://www.alexanderlerch.com/">Prof. Alexander Lerch</a>.</li></ul></blockquote><blockquote><ul><li>Center for Computer Research in Music and Acoustics (CCRMA), Stanford University<br><a href="https://ccrma.stanford.edu/">https://ccrma.stanford.edu/</a><br>This is a big lab. There are many groups in CCRMA. See <a href="https://ccrma.stanford.edu/groups/detail">here</a>.</li></ul></blockquote><blockquote><ul><li>Prof. Julian McAuley, Computer Science Department, University of California San Diago (UCSD)<br><a href="https://cseweb.ucsd.edu/~jmcauley/">https://cseweb.ucsd.edu/~jmcauley/</a></li></ul></blockquote><blockquote><ul><li>Music and Audio Research Laboratory (MARL), Dept. of Music and Performing Arts Professions, New York University (NYU)<br><a href="https://research.steinhardt.nyu.edu/marl/">https://research.steinhardt.nyu.edu/marl/</a><br>This is a big group. Its music informatics group is currently led by <a href="https://wp.nyu.edu/jpbello/">Prof. Juan Pablo Bello</a>,</li></ul></blockquote><blockquote><ul><li>Prof. Roger B. Dannenberg, CMU<br><a href="http://www.cs.cmu.edu/~rbd/">http://www.cs.cmu.edu/~rbd/</a><br>A great computer music research, a camposer and a trumpet player. However, he is not accepting students.</li></ul></blockquote><blockquote><ul><li>Centre For Interdisciplinary Research in Music Media And Technology (CIRMMT), McGill University<br><a href="https://www.cirmmt.org/">https://www.cirmmt.org/</a><br>A big lab.</li></ul></blockquote><h3 id="Research-Groups-in-Industry"><a href="#Research-Groups-in-Industry" class="headerlink" title="Research Groups in Industry"></a>Research Groups in Industry</h3><p>…Pending</p><p>An outline: Google Magenta, Spotify, Open AI, NAVIDA, Jukedeck - TikTok London, Tencent Music (TME), Netease Music…</p><h1 id="Useful-Links"><a href="#Useful-Links" class="headerlink" title="Useful Links"></a>Useful Links</h1><h2 id="Pages-of-Conferences"><a href="#Pages-of-Conferences" class="headerlink" title="Pages of Conferences"></a>Pages of Conferences</h2><blockquote><ul><li>ISMIR (International Society for Music Information Retrieval)<br><a href="https://ismir.net/">https://ismir.net/</a><br>“The ISMIR conference is held annually and is the world’s leading research forum on processing, searching, organising and accessing music-related data.”</li></ul></blockquote><blockquote><ul><li>MIREX (Music Information Retrieval Evaluation eXchange)<br><a href="https://www.music-ir.org/mirex/wiki/MIREX_HOME">https://www.music-ir.org/mirex/wiki/MIREX_HOME</a><br>“The Music Information Retrieval Evaluation eXchange (MIREX) is an annual evaluation campaign for MIR algorithms, coupled to the ISMIR conference.”</li></ul></blockquote><blockquote><ul><li>SMC (Sound and Music Computing Network)<br><a href="http://www.smcnetwork.org/">http://www.smcnetwork.org/</a><br>“The SMC Conference is a double-blind peer-reviewed international scientific conference around the core interdisciplinary topics of Sound and Music Computing.”</li></ul></blockquote><blockquote><ul><li>NLP4MusA<br><a href="https://sites.google.com/view/nlp4musa">https://sites.google.com/view/nlp4musa</a><br>“In this context, we propose the First Workshop on NLP for Music and Audio, a forum for bringing together academic and industrial scientists and stakeholders interested in exploring synergies between NLP and music and audio.” “Accepted papers will be published in the ACL anthology.”</li></ul></blockquote><blockquote><ul><li>CSMT (Conference on Sound and Music Techonology)<br><a href="http://www.csmcw-csmt.cn/">http://www.csmcw-csmt.cn/</a><br>CSMT是中国音乐科技相关的研究者交流的很好平台，可以见到很多工业界和学术界的同行。CSMT推动者中国的音乐科技领域的发展合作，也在吸引世界范围内学术界的关注。</li></ul></blockquote><p>Of course, information here is limited due to my limited knowledge… More links pending…</p><h2 id="Dataset-sources"><a href="#Dataset-sources" class="headerlink" title="Dataset sources"></a>Dataset sources</h2><blockquote><ul><li>Datasets summarized by Prof. Alexander Lerch, Gatech<br><a href="https://www.audiocontentanalysis.org/data-sets/">https://www.audiocontentanalysis.org/data-sets/</a><br>A grrrrrreat list of useful music datasets. Brief tags are attached there (e.g. MIDI or not? Labelled or not? Rhythm or melody? Monophonic or Polyphonic…)</li></ul></blockquote><blockquote><ul><li>Datasets summarized by UPF Compmusic<br><a href="https://compmusic.upf.edu/datasets">https://compmusic.upf.edu/datasets</a><br>Mainly about Indian art music, Turkish Makam music and Beijing Opera</li></ul></blockquote><blockquote><ul><li>Magenta Datasets<br><a href="https://magenta.tensorflow.org/datasets">https://magenta.tensorflow.org/datasets</a><br>Mainly about Bach Doodle Dataset, Groove MIDI Dataset, MAESTRO and NSynth</li></ul></blockquote><h2 id="Blogs"><a href="#Blogs" class="headerlink" title="Blogs"></a>Blogs</h2><blockquote><ul><li>Computer Music Conferences Deadline by Yixiao Zhang’s Blog<br><a href="https://yixiao-music.github.io/?sub=SYM,AI,OTHER,AUO">https://yixiao-music.github.io/?sub=SYM,AI,OTHER,AUO</a><br>See also: <a href="https://www.zhihu.com/question/314142299/answer/612302579">his zhihu</a></li></ul></blockquote><blockquote><ul><li>Chinese Blog of rogerkeane<br><a href="http://blog.sina.com.cn/rogerkeane">http://blog.sina.com.cn/rogerkeane</a><br>A little bit old Sina blog. He studied in GaTech. 很有生活趣味的一个博客!</li></ul></blockquote><blockquote><ul><li>Intelligent sound engineering by <a href="http://www.eecs.qmul.ac.uk/~josh/">Prof Joshua D Reiss</a><br><a href="https://intelligentsoundengineering.wordpress.com/">Intelligent sound engineering</a></li></ul></blockquote><blockquote><ul><li>Chris Donahue<br><a href="https://chrisdonahue.com/">https://chrisdonahue.com/</a></li></ul></blockquote><blockquote><ul><li>…To be expanded</li></ul></blockquote><blockquote><ul><li>And… Hey! And my blog here!</li></ul></blockquote><h2 id="Other-Useful-Links"><a href="#Other-Useful-Links" class="headerlink" title="Other Useful Links"></a>Other Useful Links</h2><blockquote><ul><li>dblp: computer science bibliography<br><a href="https://dblp.uni-trier.de/">https://dblp.uni-trier.de/</a><br>“The dblp computer science bibliography provides open bibliographic information on major computer science journals and proceedings.”</li></ul></blockquote><blockquote><ul><li>Papers With Code: The latest in machine learning<br><a href="https://paperswithcode.com/">https://paperswithcode.com/</a><br>“Papers With Code highlights trending ML research and the code to implement it.”</li></ul></blockquote><blockquote><ul><li>imslp: download sheet music<br><a href="https://imslp.org/wiki/Main_Page">https://imslp.org/wiki/Main_Page</a><br>“The International Music Score Library Project (IMSLP), also known as the Petrucci Music Library after publisher Ottaviano Petrucci, is a subscription-based project for the creation of a virtual library of public-domain music scores.” - wiki</li></ul></blockquote><blockquote><ul><li>word2tex and tex2word<br><a href="https://www.chikrii.com/">https://www.chikrii.com/</a></li></ul></blockquote><blockquote><ul><li>Google scholar, Media, Wiki, Zhihu, CSDN…</li></ul></blockquote>]]></content>
    
    
    <summary type="html">&lt;p&gt;(2020) I was trying to summarize labs and researchers around the world who dedicate in music computation. I was writing this list because I really wanted to do researches about MIR and music generation. Of course, this list is far from complete, and will be out-of-date in a few years. If you have recommendations, feel free to comment below!&lt;/p&gt;
&lt;hr&gt;
&lt;div id=&quot;content&quot;&gt;&lt;/div&gt;
&lt;script type=&quot;text/javascript&quot; src=&quot;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default&quot;&gt;&lt;/script&gt;</summary>
    
    
    
    
    <category term="introduction" scheme="https://lucainiaoge.github.io.git/tags/introduction/"/>
    
    <category term="guide" scheme="https://lucainiaoge.github.io.git/tags/guide/"/>
    
    <category term="music" scheme="https://lucainiaoge.github.io.git/tags/music/"/>
    
  </entry>
  
  <entry>
    <title>My Music Explorations (from 2017 to 2020)</title>
    <link href="https://lucainiaoge.github.io.git/2020/07/18/my-music-explorations/"/>
    <id>https://lucainiaoge.github.io.git/2020/07/18/my-music-explorations/</id>
    <published>2020-07-17T16:00:00.000Z</published>
    <updated>2025-11-11T13:28:51.826Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><strong>Welcome! I am Tongyu Lu (路通宇)! This is an introduction of my explorations on composing!</strong></p><hr><p>This is an introduction of my explorations and my musical pieces! <font color=gray > I am far from professional. Instead, I hope that my explorations on composition can inspire more music lovers to try bravely!</font></p><span id="more"></span><p><font color=gray > If my music fails to be played here, it may be because of copyright barriers. You can click the links and listen to them in outside webpages. You can also find my music in my <a href="https://soundcloud.com/lu-tongyu">SoundCloud Page</a> or <a href="https://music.163.com/#/artist/album?id=31150711">Netease Music Personal Page</a></font></p><h1 id="Early-explorations"><a href="#Early-explorations" class="headerlink" title="Early explorations"></a>Early explorations</h1><ul><li>My aunt taught me piano when I was a little boy!</li><li>In around 2012, I began practicing music myself: transcripting the pieces I like into piano scores and practicing piano skills.</li><li>I composed my first collection of <strong>12 Scottish and Irish folk song styled pieces</strong> in 2018 and published it here: <a href="https://music.163.com/#/album?id=75139286">Lucainiao’s Musical Adventures in Ireland (路菜鸟梦游爱尔兰)</a></li><li>Here are several pieces in this collection:<blockquote><p><a href="https://music.163.com/#/song?id=1339507651">Reel In the Summer (夏日的舞会)</a><br><a href="https://music.163.com/#/song?id=1339513121">Wonderland (秘境)</a></p></blockquote></li></ul><h1 id="Trials-on-orchistral-works"><a href="#Trials-on-orchistral-works" class="headerlink" title="Trials on orchistral works"></a>Trials on orchistral works</h1><ul><li><p>I tried composing orchistral works in 2018 just for fun:</p><blockquote><p><a href="https://music.163.com/#/album?id=75541918">Collection of 6 pieces: The Walking of Insects (惊蛰)</a><br>Here are two of this collection:</p><ul><li><a href="https://music.163.com/#/song?id=1346054283">Short orchistral piece: The Walking of Insects (惊蛰)</a></li><li><a href="https://music.163.com/#/song?id=1356722304">Short orchistral piece: Spring Birds (春天的鸟)</a></li></ul></blockquote></li><li><p>The Walking of Insects (惊蛰) was performed in Shenzhen College Music Festival of 2019.</p></li><li><p>Further, I tried to compose a march and an overture in Chinese style:</p><blockquote><p><a href="https://music.163.com/#/album?id=82799337">Lucainiao’s Trial on Orchestral Pieces</a></p></blockquote></li><li><p>In 2020, I realized that I lacked professional skills :)  Then I began studying harmony myself… (I will modify many of my pieces in the future because I am not satisfied with my composing skills in the past… After relistening my works, I found a lot of flaws. Anyway, I am kind of surprised that I composed them even if I did not learn harmony and other basics about composing!) By the way, I am currently fancinated with Brahms Symphony No.4!</p></li></ul><h1 id="Trials-on-chamber-music-and-piano-pieces"><a href="#Trials-on-chamber-music-and-piano-pieces" class="headerlink" title="Trials on chamber music and piano pieces"></a>Trials on chamber music and piano pieces</h1><ul><li><p>Meanwhile, I tried to compose solo piano pieces and chamber music. In early 2019, I composed a few pieces trying to depict my feelings about winter:</p><blockquote><p><a href="https://music.163.com/#/album?id=75865572">Two Quartets and a piano Etude: Charming winter</a><br>Here are the two Quartets:</p><ul><li><a href="https://music.163.com/#/song?id=1353626912">Quartet: Snow and Flying Leaves</a></li><li><a href="https://music.163.com/#/song?id=1353154329">Quartet: Charming Winter</a></li></ul></blockquote></li><li><p>I collected my early piano solo works. Although I play the piano, it is still challenging to write friendly piano pieces (especially when I want to express beauty of skills). I collected many of my piano solo works (old ones and new ones) here:</p><blockquote><p><a href="https://music.163.com/#/album?id=82784553">Piano solo collection of 7 pieces: Lucainiao’s Trial on Piano Pieces</a><br>Here are the two of them:</p><ul><li><a href="https://music.163.com/#/song?id=1400108823">Etude in c minor - phone ringtone</a></li><li><a href="https://music.163.com/#/song?id=1400108795">Etude in g minor - autumn rain</a></li></ul></blockquote></li><li><p>After reflections on my early chamber music, I found that cooperation between different voices is important. Then I tried more:</p><blockquote><p><a href="https://music.163.com/#/album?id=82784570">Chamber music collection of 4 pieces: Lucainiao’s Trial on Chamber Music</a><br>Here are the two of them:</p><ul><li><a href="https://music.163.com/#/song?id=1407112983">Duet for violin and piano: Crazy bug</a></li><li><a href="https://music.163.com/#/song?id=1400124120">Fantasia Trio Fantasia in c# minor - for Flute, Cello and Piano</a></li></ul></blockquote></li><li><p>In late 2020, I plan to explore orchestration topics, and I tried to orchestrate Beethoven’s Piano Sonata No.30, 2nd movement.</p><blockquote><ul><li><strong>Orchestration - Beethoven Piano Sonata No.30 - 2 Prestissimo</strong>; Links: <a href="https://soundcloud.com/lu-tongyu/orchestration-beethoven-piano-sonata-no30-2-prestissimo">SoundCloud</a> | <a href="https://music.163.com/#/song?id=1498903299">Netease</a></li></ul></blockquote></li></ul><h1 id="Explorations-on-jazz"><a href="#Explorations-on-jazz" class="headerlink" title="Explorations on jazz"></a>Explorations on jazz</h1><ul><li><p>In 2018, inspired by a friend who plays saxphone, I tried to write several works in Jazz style. After trying this, I found myself arrested! I began to add something jazzy in my works in late 2019 and early 2020. I created my first collection for my jazzy works in 2018 and early 2019.</p><blockquote><ul><li><a href="https://music.163.com/#/album?id=81658899">Collection of 8 pieces: JAZZ rehearsal room</a><br>Here are the three of them:</li><li><a href="https://music.163.com/#/song?id=1391341109">Rehearsal room for experts (高手的排练室)</a></li><li><a href="https://music.163.com/#/song?id=1391427346">Are you feeling bored (是否感觉无聊)</a></li><li><a href="https://music.163.com/#/song?id=1391341110">A flock of entertainers (喜剧仪仗队)</a></li></ul></blockquote></li><li><p>I then began to read <a href="https://www.amazon.com/Jazz-Piano-Book-Mark-Levine/dp/0961470151"><em>the Jazz Piano Book</em></a> in early 2020, and learned several tricks! Then I composed a few jazz piano solos (and even played and recorded some of them):</p><blockquote><ul><li><a href="https://music.163.com/#/song?id=1412072801">Fantasia for Christmas in C major</a></li><li><a href="https://music.163.com/#/album?id=89536700">My blind mind</a></li></ul></blockquote></li><li><p>In late 2020, I began trying to compose pieces for brass ensambles. Here are several of such pieces:</p><blockquote><ul><li><strong>Jazz Sextet: 6+4</strong>; Links: <a href="https://soundcloud.com/lu-tongyu/jazz-sextet-in-d-major-64">SoundCloud</a> | <a href="https://music.163.com/#/song?id=1803729586">Netease</a></li><li><strong>Jazz Sextet: Walking Freely</strong>; Links: <a href="https://soundcloud.com/lu-tongyu/jazz-sextet-in-f-major-walking-freely">SoundCloud</a> | <a href="https://music.163.com/#/song?id=1475119850">Netease</a></li><li><strong>Brass Quintet in E flat major - A Happy Festival</strong>; Links: <a href="https://soundcloud.com/lu-tongyu/brass-quintet-in-e-flat-major-a-happy-festival">SoundCloud</a> | <a href="https://music.163.com/#/song?id=1470270973">Netease</a></li></ul></blockquote></li></ul><h1 id="Studying-jazz"><a href="#Studying-jazz" class="headerlink" title="Studying jazz"></a>Studying jazz</h1><ul><li><p>In 2021, I realized that my explorations on jazz is actually on “jazz style”. What is real jazz? Improvisation!</p></li><li><p>In the summar of 2021, I began studying jazz piano with Xin. He is really an outstanding music educator. I began learning how to comping, how to interpret Real Book, how to solo, and how to compose a jazz piece etc.</p></li><li><p>During jazz learning, I also started writing my own real jazz pieces. My methodology is: first write a lead-sheet draft on piano, and then use music scoring softwares to compose the full score for the band (including solo), and finally use DAW to turn the midi into audio with the help of VST.</p></li><li><p>For example, I have composed an album &lt;<strong>Jazz Seasons</strong>&gt; in 2022; Links: <a href="https://www.youtube.com/watch?v=qiZWnehUz4o&list=PLGl6-sn5G8fQqf4LSghhLP8C8SOLi2D6p">Youtube</a> | <a href="https://space.bilibili.com/314174825/channel/seriesdetail?sid=2498428">Bilibili</a></p></li><li><p>One day I listened to the music I composed 2 years ago, and I just realized: I am now composing music with better profession, but less ideas. </p></li><li><p>This log currently stops at Mar/2023. I am still learning jazz and composing music. I will carry on, and get back when I am making gread changes.</p></li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;strong&gt;Welcome! I am Tongyu Lu (路通宇)! This is an introduction of my explorations on composing!&lt;/strong&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;This is an introduction of my explorations and my musical pieces! &lt;font color=gray &gt; I am far from professional. Instead, I hope that my explorations on composition can inspire more music lovers to try bravely!&lt;/font&gt;&lt;/p&gt;</summary>
    
    
    
    
    <category term="introduction" scheme="https://lucainiaoge.github.io.git/tags/introduction/"/>
    
    <category term="music" scheme="https://lucainiaoge.github.io.git/tags/music/"/>
    
  </entry>
  
  <entry>
    <title>CNN Note - Back Propagation Alogorithm</title>
    <link href="https://lucainiaoge.github.io.git/2020/04/03/CNNnote2-BP_algorithm/"/>
    <id>https://lucainiaoge.github.io.git/2020/04/03/CNNnote2-BP_algorithm/</id>
    <published>2020-04-02T16:00:00.000Z</published>
    <updated>2025-11-11T13:28:51.797Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><strong>by lucainiaoge</strong></p><hr><h1 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h1><p>This is a detailed derivation and summerization on back propagation (BP) algorithm in fully-connected neural networks and CNN:</p><span id="more"></span><h2 id="References-and-helpful-links"><a href="#References-and-helpful-links" class="headerlink" title="References and helpful links"></a>References and helpful links</h2><blockquote><ul><li><a href="http://cogprints.org/5869/1/cnn_tutorial.pdf">Reference 1: CNN tutorial note of Jake Bouvrie</a></li><li><a href="https://blog.csdn.net/ck1798333105/article/details/52369122">Reference 2: A helpful CSDN blog in Chinese, author - xqp_dream</a></li></ul></blockquote><h2 id="Prerequisites-for-this-note"><a href="#Prerequisites-for-this-note" class="headerlink" title="Prerequisites for this note"></a>Prerequisites for this note</h2><p>neural network concepts, CNN concepts, vector calculus</p><h1 id="First-Part-Review-–-BP-back-propagation-in-fully-connected-layers"><a href="#First-Part-Review-–-BP-back-propagation-in-fully-connected-layers" class="headerlink" title="First Part: Review – BP (back propagation) in fully connected layers"></a>First Part: Review – BP (back propagation) in fully connected layers</h1><h2 id="Review-of-Feedforward-and-BP-formula"><a href="#Review-of-Feedforward-and-BP-formula" class="headerlink" title="Review of Feedforward and BP formula"></a>Review of Feedforward and BP formula</h2><p><img src="https://i.loli.net/2020/04/03/l6dOyAPTnqRcGtS.jpg" alt="Part1_1-1_1.jpg"><br>Just a review, not a tutorial! How to derive the formula? Please go to learn neural network basics.<br>Give <a href="http://ufldl.stanford.edu/wiki/index.php/%E5%8F%8D%E5%90%91%E4%BC%A0%E5%AF%BC%E7%AE%97%E6%B3%95">a link of tutorial from Andrew Ng</a></p><h2 id="Detailed-derivation-of-BP-formula"><a href="#Detailed-derivation-of-BP-formula" class="headerlink" title="Detailed derivation of BP formula"></a>Detailed derivation of BP formula</h2><p><img src="https://i.loli.net/2020/04/03/O9Kr2CpN7iLTegG.jpg" alt="Part1_1-2_1.jpg"><br><img src="https://i.loli.net/2020/04/03/1gUuzNhxtQnrEdY.jpg" alt="Part1_1-2_2.jpg"><br><img src="https://i.loli.net/2020/04/03/mZOnVXgxsQL4tYf.jpg" alt="Part1_1-2_3.jpg"></p><h1 id="Second-Part-math-in-CNN-–-representation-and-BP"><a href="#Second-Part-math-in-CNN-–-representation-and-BP" class="headerlink" title="Second Part: math in CNN – representation and BP"></a>Second Part: math in CNN – representation and BP</h1><h2 id="Math-formalization-of-CNN-feeding-forward"><a href="#Math-formalization-of-CNN-feeding-forward" class="headerlink" title="Math formalization of CNN feeding forward"></a>Math formalization of CNN feeding forward</h2><p><img src="https://i.loli.net/2020/04/03/miqXKzBD7CE1rL3.jpg" alt="Part2-1_1.jpg"><br><img src="https://i.loli.net/2020/04/03/ECVM5AsbKok2xLY.jpg" alt="Part2-1_2.jpg"></p><h2 id="BP-for-convolutional-layers"><a href="#BP-for-convolutional-layers" class="headerlink" title="BP for convolutional layers"></a>BP for convolutional layers</h2><p><img src="https://i.loli.net/2020/04/03/OspeVKBUJvXqGHD.jpg" alt="Part2-2_0.jpg"></p><h3 id="The-start-of-error-terms-and-dealing-with-BP-of-the-L-th-layer-which-is-a-pooling-layer"><a href="#The-start-of-error-terms-and-dealing-with-BP-of-the-L-th-layer-which-is-a-pooling-layer" class="headerlink" title="The start of error terms and dealing with BP of the $L^{th}$ layer (which is a pooling layer)"></a>The start of error terms and dealing with BP of the $L^{th}$ layer (which is a pooling layer)</h3><p><img src="https://i.loli.net/2020/04/03/z3EOHS85xdV4Wai.jpg" alt="Part2-2_1_1.jpg"><br><img src="https://i.loli.net/2020/04/03/5AM3KsWoSx7jvmR.jpg" alt="Part2-2_1_2.jpg"></p><h3 id="Dealing-with-BP-of-the-L-1-th-layer-which-is-a-convolutional-layer"><a href="#Dealing-with-BP-of-the-L-1-th-layer-which-is-a-convolutional-layer" class="headerlink" title="Dealing with BP of the $(L-1)^{th}$ layer (which is a convolutional layer)"></a>Dealing with BP of the $(L-1)^{th}$ layer (which is a convolutional layer)</h3><p><img src="https://i.loli.net/2020/04/03/9b1aSiH2FrcCzqp.jpg" alt="Part2-2_2_1.jpg"><br><img src="https://i.loli.net/2020/04/03/fQND1v9PutTHmCc.jpg" alt="Part2-2_2_2.jpg"><br><img src="https://i.loli.net/2020/04/03/k5PZdEBDzOVWL1r.jpg" alt="Part2-2_2_3.jpg"><br><img src="https://i.loli.net/2020/04/03/dRnJtA8plyIFMbY.jpg" alt="Part2-2_2_4.jpg"></p><h2 id="BP-for-CNN-–-a-summarization"><a href="#BP-for-CNN-–-a-summarization" class="headerlink" title="BP for CNN – a summarization"></a>BP for CNN – a summarization</h2><p><img src="https://i.loli.net/2020/04/03/5NhKxmcvrGFbWZz.jpg" alt="Part2-2_3.jpg"></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;strong&gt;by lucainiaoge&lt;/strong&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h1 id=&quot;Intro&quot;&gt;&lt;a href=&quot;#Intro&quot; class=&quot;headerlink&quot; title=&quot;Intro&quot;&gt;&lt;/a&gt;Intro&lt;/h1&gt;&lt;p&gt;This is a detailed derivation and summerization on back propagation (BP) algorithm in fully-connected neural networks and CNN:&lt;/p&gt;</summary>
    
    
    
    
    <category term="math" scheme="https://lucainiaoge.github.io.git/tags/math/"/>
    
    <category term="machine_learning" scheme="https://lucainiaoge.github.io.git/tags/machine-learning/"/>
    
    <category term="CNN" scheme="https://lucainiaoge.github.io.git/tags/CNN/"/>
    
    <category term="neural_network" scheme="https://lucainiaoge.github.io.git/tags/neural-network/"/>
    
  </entry>
  
  <entry>
    <title>Course Note - Propositional Logic - BN and inference UCLA Adnan Darwiche</title>
    <link href="https://lucainiaoge.github.io.git/2020/03/18/course_note1-propositional_logic-BN_and_inference_UCLA_Adnan/"/>
    <id>https://lucainiaoge.github.io.git/2020/03/18/course_note1-propositional_logic-BN_and_inference_UCLA_Adnan/</id>
    <published>2020-03-17T16:00:00.000Z</published>
    <updated>2025-11-11T13:28:51.810Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><strong>by lucainiaoge</strong></p><hr><h1 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h1><p>This is a fundamental course for those who wanna have a thorough understanding of Baysian Networks:</p><span id="more"></span><blockquote><ul><li><a href="https://www.bilibili.com/video/av44032749">bilibili course link: UCLA Bayesian Networks and Inference - Adnan Darwiche</a></li><li><a href="https://www.youtube.com/watch?v=-6A6b_Z4bIg&list=PLlDG_zCuBub6ywAIrM1DfJp8xaeVjyvwx">youtube course link: UCLA Bayesian Networks and Inference - Adnan Darwiche</a></li></ul></blockquote><p>When studying the course, I was somehow confused partly because the lecture goes too fast. I have to frequently halt and comprehend the slides. Luckily, the slides are very well arranged.<br>Through the first several courses, we are lead to discover the mathematical essence of Baysian Networks (BN).</p><h2 id="Prerequisites-for-this-note"><a href="#Prerequisites-for-this-note" class="headerlink" title="Prerequisites for this note"></a>Prerequisites for this note</h2><p>Knowing what sets are, knowing basic boolean logic, a mathematical mind</p><h2 id="Purpose-of-this-note"><a href="#Purpose-of-this-note" class="headerlink" title="Purpose of this note"></a>Purpose of this note</h2><p>Set up the foundation of probability calculus.</p><p>Link logical calculation with set calculation.</p><h1 id="Constructing-Propositional-Logic"><a href="#Constructing-Propositional-Logic" class="headerlink" title="Constructing Propositional Logic"></a>Constructing Propositional Logic</h1><p><strong>Motivation:</strong> There will be a great deal of definitions. My understanding is that they are like fundations of the magnificent building of probibilistic inference for what we interpret as “events” are explained with the Propositional Logic.</p><p><font color=Crimson size=4><strong>Definition (propositional variable and sentence/event):</strong></font><font color=DarkRed size=3> a propositional variable $p$ is defined on a discrete set P;a sentence or an event $\alpha$ is an assignment of propositional variables. $\alpha$ can hold <strong>true</strong> or <strong>false</strong></font></p><p>In other words,$(p=p_0)=\alpha \in \lbrace \pmb{true},\pmb{false} \rbrace$<br>In the following discussions, we take <strong>True</strong> as T and <strong>False</strong> as F.</p><blockquote><p>e.g. propositional variable: B=”Burglery”, E=”Earthquake”, A=”Alarm”; a sentence: $\alpha$=(B=T,A=F)</p></blockquote><p>When we have a lot of propositional variables, the combinitions of <strong>possible circumstances</strong> are exploding exponentially. To efficiently deal with that is one of our tasks.<br>First we have to define such <strong>possible circumstances</strong> with term “world”:</p><p><font color=Crimson size=4><strong>Definition (world):</strong></font><font color=DarkRed size=3> a world $w$ is an assignment for <strong>all</strong> propositional variables $p_i$.</font></p><p>We can treat worlds as smallest elements of the whole set $\Omega$.</p><blockquote><p>e.g. $p_B$=”Burglery”, $p_E$=”Earthquake”, $p_A$=”Alarm”<br>$w_1=[(p_B,p_E,p_A)=(T,T,T)]$<br>$w_2=[(p_B,p_E,p_A)=(T,T,F)]$<br>$w_3=[(p_B,p_E,p_A)=(T,F,T)]$<br>$w_4=[(p_B,p_E,p_A)=(T,F,F)]$<br>$w_5=[(p_B,p_E,p_A)=(F,T,T)]$<br>$w_6=[(p_B,p_E,p_A)=(F,T,F)]$<br>$w_7=[(p_B,p_E,p_A)=(F,F,T)]$<br>$w_8=[(p_B,p_E,p_A)=(F,F,F)]$<br>$\Omega=\lbrace w_1,w_2,…,w_8 \rbrace$</p></blockquote><p><font color=Crimson size=4><strong>Definition ($w \models \alpha$):</strong></font><font color=DarkRed size=3> a world $w$ holds true if a sentence $\alpha$ is true.</font></p><blockquote><p>e.g. given sentences: $B=[p_B=T]$(means Burglery happens), $E=[p_E=T]$, $A=[p_A=T]$, $\neg B=[p_B=F]$ and so forth<br>Then, $w_1 \models B$, $w_5 \models \neg B$</p></blockquote><p><font color=Crimson size=4><strong>Definition (model of sentence $\alpha$):</strong></font><font color=DarkRed size=3> $Mods(\alpha)=\lbrace w:w \models \alpha ,w\in \Omega \rbrace$</font><br>Model of a sentence is a set. It’s obvious that model of a sentence is unique and given a set of worlds there is a unique sentence whose model is the set.</p><blockquote><p>e.g. $Mods(B)=\lbrace w_1,w_2,w_3,w_4 \rbrace$</p></blockquote><p>Until now, we know that:</p><ol><li>We are studying <strong>Propasitional Variables</strong> which are discrete</li><li>A <strong>sentence/event</strong> is a function for Propasitional Variable vectors (i.e. a value assignment). The function value domain is $\lbrace \pmb{true},\pmb{false} \rbrace$</li><li>A <strong>world</strong> is a sentence considering all Propasitional Variables.</li><li><strong>Model of a sentence</strong> is a set whose elements are worlds that hold true when this sentence holds true.</li></ol><p>Hope you are getting excited: we are linking the logic world of Ture or False with the world of sets. We can really define logical calculations.</p><h1 id="Propositional-Logic-Calculation"><a href="#Propositional-Logic-Calculation" class="headerlink" title="Propositional Logic Calculation"></a>Propositional Logic Calculation</h1><p><font color=Crimson size=4><strong>Definition (Basic Propositional Logic Calculation):</strong></font><font color=DarkRed size=3> given sentence $\alpha$ and $\beta$<br>$\alpha \wedge \beta $ is such a sentence that $Mods(\alpha \wedge \beta)=Mods(\alpha)\cap Mods(\beta)$<br>$\alpha \vee \beta $ is such a sentence that $Mods(\alpha \wedge \beta)=Mods(\alpha)\cup Mods(\beta)$<br>$\neg \alpha $ is such a sentence that $Mods(\neg \alpha)=\Omega \setminus Mods(\alpha)$<br></font><br>You see? Your familiar logical calculation “and”,”or” and “not” is actually set calculation “intersection”,”union” and “complement”.</p><p><font color=Crimson size=4><strong>Definition (relationships of sentences):</strong></font><font color=DarkRed size=3> given sentence $\alpha$ and $\beta$<br>$\alpha$ is <strong>consistent or satisfiable</strong> $\Leftrightarrow$ $Mods(\alpha)\neq \emptyset$<br>$\alpha$ is <strong>valid</strong> $\Leftrightarrow$ $Mods(\alpha)= \Omega$ $\Leftrightarrow$ $\models \alpha$ $\Leftrightarrow$ $\alpha = True$<br>$\alpha$ and $\beta$ are <strong>equivalent</strong> $\Leftrightarrow$ $Mod(\alpha)=Mods(\beta)$<br>$\alpha$ and $\beta$ are <strong>mutually exclusive</strong> $\Leftrightarrow$ $Mods(\alpha)\cap Mods(\beta)=\emptyset$<br>$\alpha$ and $\beta$ are <strong>exhaustive</strong> $\Leftrightarrow$ $Mods(\alpha)\cup Mods(\beta)=\Omega$<br>$\alpha$ <strong>implies</strong> $\beta$ $\Leftrightarrow$ $Mods(\alpha)\subset Mods(\beta)$ $\Leftrightarrow$ $\alpha \models \beta$<br></font><br>I think those definitions are to remind people the importance of such relationships. Also helping people to communicate in a more logical manner…</p><p>A few more definitions of Propositional Logic calculation:<br><font color=Crimson size=4><strong>Definition (More Propositional Logic Calculation):</strong></font><font color=DarkRed size=3> given sentence $\alpha$ and $\beta$<br>$\alpha \rightarrow \beta $ $\Leftrightarrow$ $\neg \alpha \vee \beta$<br>$\alpha \leftrightarrow \beta $ $\Leftrightarrow$ $(\alpha \rightarrow \beta)\wedge (\beta \rightarrow \alpha)$<br></font><br>Worth noticing those definitions.<br>$\alpha \rightarrow \beta $ is in fact telling you that $\alpha$ implies $\beta$, or <strong>contraposition</strong>. $\alpha \rightarrow \beta = True$ means: whenever $\alpha$ is true, $\beta$ is true. So $Mods(\alpha)\subset Mods(\beta)$. (Think the worlds!)<br>$\alpha \leftrightarrow \beta $ is actually <strong>XNOR</strong>. $\alpha \leftrightarrow \beta = True$ means that $\alpha$ and $\beta$ are equivalent.</p><p>Several examples:</p><blockquote><p>given sentences: $B=[p_B=T]$, $E=[p_E=T]$, $A=[p_A=T]$, $\neg B=[p_B=F]$ and so forth<br>$\alpha=(E \vee B)\rightarrow A$<br>$Mods(\alpha)=\lbrace w_1,w_3,w_5,w_7,w_8 \rbrace$<br>$\beta=(E \rightarrow B)$<br>$Mods(\beta)=\lbrace w_1,w_2,w_5,w_6,w_7,w_8 \rbrace$<br>then, $Mods(\alpha \wedge \beta)=\lbrace w_1,w_5,w_7,w_8 \rbrace$</p></blockquote><p>Calculating intersection is in fact adding information, and we throw away world elements by doing this. This is compactible with information theory!</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;strong&gt;by lucainiaoge&lt;/strong&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h1 id=&quot;Intro&quot;&gt;&lt;a href=&quot;#Intro&quot; class=&quot;headerlink&quot; title=&quot;Intro&quot;&gt;&lt;/a&gt;Intro&lt;/h1&gt;&lt;p&gt;This is a fundamental course for those who wanna have a thorough understanding of Baysian Networks:&lt;/p&gt;</summary>
    
    
    
    
    <category term="machine_learning" scheme="https://lucainiaoge.github.io.git/tags/machine-learning/"/>
    
    <category term="BN" scheme="https://lucainiaoge.github.io.git/tags/BN/"/>
    
    <category term="logic" scheme="https://lucainiaoge.github.io.git/tags/logic/"/>
    
  </entry>
  
  <entry>
    <title>Harmonic Constraint in Music Spectrogram Reconstruction</title>
    <link href="https://lucainiaoge.github.io.git/2020/01/15/Harmonic_Constraint_in_Music_Spectrogram_Reconstruction/"/>
    <id>https://lucainiaoge.github.io.git/2020/01/15/Harmonic_Constraint_in_Music_Spectrogram_Reconstruction/</id>
    <published>2020-01-14T16:00:00.000Z</published>
    <updated>2025-11-11T13:28:51.801Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><div id="content"></div><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script><p><font color=gray > It is assumed that readers have known the concepts about harmonic (overtone) structure of musical notes. And readers are recommended to know the non-negative matrix factorization (NMF) algorithm. But anyway, I tried to briefly elaborate it in this article.</font></p><p>This article gives a brief review of harmonic constraints on timbre dictionary. Such harmonic constraints are useful in helping non-negative matrix factorization (NMF) algorithm to converge into a musically meaningful result, which could enable automatic music transcription (AMT) and music source separation (MSS). Noticing the disadvantages of the traditional NMF algorithm and hard-harmonic-constraints, this article proposes a dB-trick for NMF which could loosen the non-negativity constraints, and a soft-harmonic-constraint method based on regularization which gives more freedom to the parameter compared with the existing hard-harmonic-constraints.</p><span id="more"></span><p>To view this article, please download:<br><a href="/download/Harmonic_Constraint_in_Music_Spectrogram_Reconstruction.pdf">Harmonic_Constraint_in_Music_Spectrogram_Reconstruction</a></p>]]></content>
    
    
    <summary type="html">&lt;div id=&quot;content&quot;&gt;&lt;/div&gt;
&lt;script type=&quot;text/javascript&quot; src=&quot;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default&quot;&gt;&lt;/script&gt;

&lt;p&gt;&lt;font color=gray &gt; It is assumed that readers have known the concepts about harmonic (overtone) structure of musical notes. And readers are recommended to know the non-negative matrix factorization (NMF) algorithm. But anyway, I tried to briefly elaborate it in this article.&lt;/font&gt;&lt;/p&gt;
&lt;p&gt;This article gives a brief review of harmonic constraints on timbre dictionary. Such harmonic constraints are useful in helping non-negative matrix factorization (NMF) algorithm to converge into a musically meaningful result, which could enable automatic music transcription (AMT) and music source separation (MSS). Noticing the disadvantages of the traditional NMF algorithm and hard-harmonic-constraints, this article proposes a dB-trick for NMF which could loosen the non-negativity constraints, and a soft-harmonic-constraint method based on regularization which gives more freedom to the parameter compared with the existing hard-harmonic-constraints.&lt;/p&gt;</summary>
    
    
    
    
    <category term="MIR" scheme="https://lucainiaoge.github.io.git/tags/MIR/"/>
    
    <category term="AMT" scheme="https://lucainiaoge.github.io.git/tags/AMT/"/>
    
    <category term="research" scheme="https://lucainiaoge.github.io.git/tags/research/"/>
    
  </entry>
  
  <entry>
    <title>Reflections on Linear Algebra - Range and Nullspace</title>
    <link href="https://lucainiaoge.github.io.git/2020/01/13/Linear_Algebra_Reflection_Range_and_Nullspace/"/>
    <id>https://lucainiaoge.github.io.git/2020/01/13/Linear_Algebra_Reflection_Range_and_Nullspace/</id>
    <published>2020-01-12T16:00:00.000Z</published>
    <updated>2025-11-11T13:28:51.803Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><div id="content"></div><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script><p><font color=gray > This article assumes readers have grasped the basic concepts of linear algebra (e.g. inner product space, subspace, rank of matrix, solving linear equations with Gaussian elimination etc.).</font></p><p>When I was learning about convex optimization, I encountered a statement about feasibility: given constraint $Ax=b$, if $b\notin R(A)$, then this problem is not feasible. I was wondering what $R(A)$ was. After reading this article, hope that the answer will be trivial to you!</p><span id="more"></span><p>To view this article, please download:<br><a href="/download/Linear_Algebra_Reflection_Range_and_Nullspace.pdf">Reflections on Linear Algebra: Range and Nullspace</a></p>]]></content>
    
    
    <summary type="html">&lt;div id=&quot;content&quot;&gt;&lt;/div&gt;
&lt;script type=&quot;text/javascript&quot; src=&quot;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default&quot;&gt;&lt;/script&gt;

&lt;p&gt;&lt;font color=gray &gt; This article assumes readers have grasped the basic concepts of linear algebra (e.g. inner product space, subspace, rank of matrix, solving linear equations with Gaussian elimination etc.).&lt;/font&gt;&lt;/p&gt;
&lt;p&gt;When I was learning about convex optimization, I encountered a statement about feasibility: given constraint $Ax=b$, if $b&#92;notin R(A)$, then this problem is not feasible. I was wondering what $R(A)$ was. After reading this article, hope that the answer will be trivial to you!&lt;/p&gt;</summary>
    
    
    
    
    <category term="math" scheme="https://lucainiaoge.github.io.git/tags/math/"/>
    
  </entry>
  
  <entry>
    <title>2019数模国赛B题解析Part2(Analysis of 2019CUMCM Question-B Part2)</title>
    <link href="https://lucainiaoge.github.io.git/2019/10/02/math-modling-2019CUMCM-answer-2/"/>
    <id>https://lucainiaoge.github.io.git/2019/10/02/math-modling-2019CUMCM-answer-2/</id>
    <published>2019-10-01T16:00:00.000Z</published>
    <updated>2025-11-11T13:28:51.810Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><strong>by lucainiaoge</strong></p><hr><p>这篇文章讲解2019年数学建模国赛B题的求解历程。这是第二篇。</p><ul><li>基础知识required：运动学和牛顿力学，空间向量的概念，最好有点反馈控制的知识（没有也行）</li></ul><span id="more"></span><ul><li>本文物理量如果无特殊说明一律采用国际单位制</li><li>若无法显示公式，或者出现[Math Processing Error]，请尝试shift+F5或者ctrl+shift+F5刷新页面<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script></li></ul><h1 id="Restart-Operate-in-3D-World"><a href="#Restart-Operate-in-3D-World" class="headerlink" title="Restart: Operate in 3D World"></a>Restart: Operate in 3D World</h1><p>上回书说道，为了解决前两问，我们搭建了<del>逼真的物理引擎</del>，然后建立了竖直方向施力的反馈机制。上一文章链接：<a href="https://lucainiaoge.github.io/2019/09/29/math-modling-2019CUMCM-answer-1/">2019数模国赛B题解析Part1(Analysis of 2019CUMCM Question-B Part1)</a></p><p>但是，我们怎么让我们的模型适用于三维世界？我们还有哪些没有做？捋了一遍，发现还差好多！具体总结如下：<br><img src="https://i.loli.net/2019/10/02/g4J72biRmOPfU9j.png" alt="TODO_list.png"></p><p>让我们逐(man)一(man)解决！</p><h2 id="Solution-Get-Feedback-and-Adjust"><a href="#Solution-Get-Feedback-and-Adjust" class="headerlink" title="Solution: Get Feedback and Adjust"></a>Solution: Get Feedback and Adjust</h2><p>在这里依然使用反馈的思路，只不过不能是简单地画一个单调递减函数就能解决的问题了。这回，我们要按照控制论的思想实时进行控制了！</p><p>什么是控制论的思想？就是：首先，我们有一个目标的值，叫做期望值。假如我们想让$\Delta t$时间后，被控制物体的位置$\pmb{r}(t+\Delta t)$变到$\pmb{r_0}$，那么我们就说期望值为$\pmb{r_0}$。</p><p>在这里请允许我借用概率论中求期望的符号:$E[\pmb{r}(t+\Delta t)]=\pmb{r_0}$</p><p>请注意：这里的$E[·]$作用的对象是我们要调整的时变量，我们假定$E[·]$对于这些时变量的期望具有<strong>线性性质</strong>，这么认为的理由在后面会有解释。</p><p>那么接下来，我们就要竭尽所能达成这个期望。我们能干什么？当然是：调整力！牛顿力学的体系下，我们可以认为：力是改变物体运动状态的<strong>原因</strong>！</p><p>接下来，我是用PID（比例积分微分）的方法来进行控制。什么是PID？可以自行百度，这里只是一个名称罢了，代表一种方法，没必要知道工程上如何使用。实现这道题的要求，进行比例控制就够了。</p><p>如果仅使用比例控制，则$E[x]=K_p x$，$K_p$为比例系数。也就是下一次的输出量为期望值乘以一个系数。下文中，出现“求期望”字样，指的是获取目标量的期望值，不是统计学中的期望！</p><h3 id="PID-in-problem-①-amp-②"><a href="#PID-in-problem-①-amp-②" class="headerlink" title="PID in problem ①&amp;②"></a>PID in problem ①&amp;②</h3><p>①好说，每次将要碰撞（球中心距离距鼓面距离等于球的半径）的时候进行一次判断，如果此时球在水平面的投影不落在鼓的投影内部，那么就判负。</p><p>主要讲如何实现②：控制拉力合力的水平分力，使鼓始终跟随球走。</p><p>力和位置，一个是二阶量，一个是零阶量，无法直接得出力的控制方程（就是决定下一时刻的输出量的计算式）。有一个办法：使用串级PID，不过这里我不打算采用这样的方法。</p><p>还有一个办法：我们连推两阶，就可以获取力的控制方程了。</p><p>下一时刻，鼓水平位置的期望值为球水平位置：<br>$E[\pmb{r_d}(i+1)]=\pmb{r_b(i)}$(注意，这里向量都是二维向量)<br>考虑运动方程$\pmb{r_d}(i+1)=\pmb{r_d}(i)+\pmb{v_d}(i)\Delta t$<br>由于实际世界是连续的，我们的迭代步长可以取得足够小，使得：$|\pmb{v_d}(i+1)-\pmb{v_d}(i)|&lt;\epsilon$<br>所以运动方程还可写为：$\pmb{r_d}(i+1)=\pmb{r_d}(i)+\pmb{v_d}(i+1)\Delta t$</p><p>运动方程两边求期望得到：$E[\pmb{v_d}(i+1)]=(E[\pmb{r_d}(i+1)]-\pmb{r_d}(i))/\Delta t=(\pmb{r_b}(i)-\pmb{r_d}(i))/\Delta t$<br>记$\pmb{r_{db}}(i)=(\pmb{r_b}(i)-\pmb{r_d}(i))$<br>则有$E[\pmb{v_d}(i+1)]=\pmb{r_{db}}(i)/\Delta t$<br>仅使用PID比例控制，则可以拆掉期望运算$\pmb{v_d}(i+1)=\pmb{K_{pv}}\pmb{r_{db}}(i)/\Delta t$<br>其中：$\pmb{K_{pv}}=diag(k_{vx},k_{vy})$<br>又根据冲量定理，$\pmb{v_d}(i+1)=\pmb{v_d}(i)+\pmb{F_{xy}}(i)\Delta t/m_d$<br>结合以上式子，经过简单代入和移项，可以推出：</p><blockquote><p>$\pmb{F_{xy}}(i)=\pmb{K_{pv}}\pmb{r_{db}}(i)m_d/(\Delta t)^2-\pmb{v_d}(i)m_d/\Delta t $<br>这就是我们想要的控制方程，按照这个式子设置此时的合力即可使得鼓的水平位置趋向于球的水平位置！</p></blockquote><h3 id="PID-in-problem-③"><a href="#PID-in-problem-③" class="headerlink" title="PID in problem ③"></a>PID in problem ③</h3><p>③的目的是：让鼓始终保持水平。为什么要让鼓保持水平？一个原因是让球更容易被接到；还有一个原因就是减少转动防止力的不均匀性使得鼓过不了多久就转翻了。<br>对于力矩的推导相似，但是更复杂。具体呢：看下面吧！</p><p>我们期望鼓的法向量$\pmb{n}(i+1)$为$z单位向量\pmb{e_z}$，即$E[\pmb{n}(i+1)]=\pmb{e_z}$<br>根据转动定理和连续性，$\pmb{n}(i+1)=\pmb{n}(i)+\pmb{\omega}(i+1)\times\pmb{n}(i)\Delta t$<br>两边求期望得到$E[\pmb{\omega}(i+1)]\times\pmb{n}(i)\Delta t=E[\pmb{n}(i+1)]-\pmb{n}(i)$<br>代入$E[\pmb{n}(i+1)]=\pmb{e_z}$得到$E[\pmb{\omega}(i+1)]\times\pmb{n}(i)\Delta t=\pmb{e_z}-\pmb{n}(i)$<br>我们仅使用比例控制PID，那么可以继续拆掉期望运算，得到：<br>$\pmb{\omega}(i+1)\times\pmb{n}(i)\Delta t=\pmb{K_{pr}}(\pmb{e_z}-\pmb{n}(i))$<br>其中，$\pmb{K_{pr}}=diag(k_{rx},k_{ry},k_{rz})$<br>列出动力学公式$J\pmb{\omega}(i+1)=J\pmb{\omega}(i)+\pmb{M}(i)\Delta t$<br>将动力学公式两边同时叉乘$\pmb{n}(i)$，结合已得到的式子，推出<br>$\pmb{M}(i)\times\pmb{n}(i)\Delta t=J\pmb{K_{pr}}(\pmb{e_z}-\pmb{n}(i))/\Delta t-J\pmb{\omega}(i)\times\pmb{n}(i)$<br>我们最终要得到$\pmb{M}(i)$&lt;所以把这个向量积方程解出来就好了。这个方程怎么解？<br>我们先把和设定值$\pmb{M}(i)$无关的已知量（即时刻$i$的运动参量）挪到一边去，<br>令$\pmb{S}(i)=J[\pmb{K_{pr}}(\pmb{e_z}-\pmb{n}(i))/\Delta t-\pmb{\omega}(i)\times\pmb{n}(i)]/\Delta t$<br>那么这个方程就写成了$\pmb{M}(i)\times\pmb{n}(i)=\pmb{S}(i)$<br>求解过程如下图<br><img src="https://i.loli.net/2019/10/03/XmkEJsN53zDy4gn.png" alt="solve_equation.png"><br>最终得到：</p><blockquote><p>$\pmb{M}(i)=diag(-S_y(i)/n_z(i),S_x(i)/n_z(i),0)$<br>这就是我们想要的力矩的控制方程，按照此式子迭代可以使得鼓始终保持水平</p></blockquote><h3 id="Problem-④-amp-⑤"><a href="#Problem-④-amp-⑤" class="headerlink" title="Problem ④&amp;⑤"></a>Problem ④&amp;⑤</h3><p>问题一个个解决，一半多的理论问题已经被搞定了！那么，三维碰撞怎么描绘？如何刻画使球竖直弹回的条件？</p><h4 id="Describe-3D-Collision"><a href="#Describe-3D-Collision" class="headerlink" title="Describe 3D Collision"></a>Describe 3D Collision</h4><p>先解决碰撞的迭代公式<br><img src="https://i.loli.net/2019/10/03/cd1Tux6BAgvISqG.png" alt="collision_analysis.png"><br>上图是碰撞瞬间部分物理量的示意图。我们需要研究N点两个物体的速度。这涉及到了：鼓在N点的线速度(质心速度和转动线速度之和)、鼓的转动角速度、碰撞点的位置、球的质心速度(之前假设不考虑球的自转)。让我们一一列方程！<br>设鼓的厚度为$h$，球的半径为$R$，用单一字母代表原点到该字母表示点的向量，那么有<br>$\pmb{PQ}=h\pmb{n}/2$,$\pmb{N}=\pmb{O}-h\pmb{n}/2$,$\pmb{Q}=\pmb{P}+\pmb{PQ}$<br>我们知道$平面\sigma:n_x(x-x_Q)+n_y(y-y_Q)+n_z(z-z_Q)=0$<br>其中$n_x,n_y,n_z$为鼓面单位法向量的分量<br>那么球到鼓面的距离为$d_{ON}=|n_x(x_O-x_Q)+n_y(y_O-y_Q)+n_z(z_O-z_Q)|$<br>每次迭代判断一次$d_{ON}\le R?$，如果成立则对碰撞进行迭代：<br>设此时鼓的质心速度为$\pmb{v_d}$，鼓的角速度为$\pmb{\omega}$，$N$点处鼓的旋转线速度为$\pmb{v_{\tau}}$，N点鼓的质点速度为$\pmb{v_{N}}$，球的质心速度为$\pmb{v_d}$，那么我们有：<br>$\pmb{v_{\tau}}=\pmb{\omega}\times\pmb{PN}$<br>$\pmb{v_{N}}=\pmb{v_d}+\pmb{v_{\tau}}$<br>下面，列写动力学方程更新下一时刻鼓和球的运动参量：<br>对物体列冲量定理和碰撞系数定义式<br>$\pmb{P}(i)=m_{b} \pmb{v_b}(i)+m_{d} \pmb{v_d}(i) $（前一时刻动量）<br>$\pmb{P}(i+1)=m_{b} \pmb{v_b}(i+1)+m_{d} \pmb{v_d}(i+1) $（后一时刻动量）<br>$I(i)=\sum \pmb{F}(i) \Delta t-\left(m_{b}+m_{d}\right) g \Delta t \pmb{e_z} $（外力冲量）<br>$\pmb{P}(i)+\pmb{I}(i)=\pmb{P}(i+1) $（冲量定理）<br>$e\left[\pmb{v_b}(i+1)-\pmb{v_d}(i+1)\right]=\pmb{v_d}(i)-\pmb{v_b}(i) $（碰撞系数定义）</p><!--![formula-collision-3D-source.png](https://i.loli.net/2019/10/03/yU9PwAunKDNcYXf.png)--><p>上面$\pmb{\sum F}$为队员拉力的合力。<br>可以求得下一时刻二者的质心速度</p><blockquote><p><img src="https://i.loli.net/2019/10/03/qQ1dcMPTu6bwEUt.png" alt="formula-collision-3D.png"></p></blockquote><p>对系统列角动量守恒得到<br>$J\pmb{\omega}(i)+\pmb{PO}\times m_b\pmb{v_b}(i)=J\pmb{\omega_d}(i+1)+\pmb{PO}\times m_b\pmb{v_b}(i+1)$<br>整理得到下一时刻鼓的角速度</p><blockquote><p>$\pmb{\omega}(i+1)=\pmb{\omega}(i)+\pmb{PO}\times m_b(\pmb{v_b}(i)-\pmb{v_b}(i+1))$</p></blockquote><h4 id="Describe-the-Condition-in-⑤"><a href="#Describe-the-Condition-in-⑤" class="headerlink" title="Describe the Condition in ⑤"></a>Describe the Condition in ⑤</h4><p>下面，我们需要探究碰撞瞬间满足什么条件，就可以将球竖直弹回。<br>如果下一时刻球竖直弹回，那么一定有：<br>$\pmb{v_b}(i+1)\times\pmb{e_z}=0$<br>根据上一部分推出的鼓质心速度$\pmb{v_d}(i+1)$的计算公式，忽略重力影响，得到<br><img src="https://i.loli.net/2019/10/03/FO4jHdkUBqPf3Vl.png" alt="formula-collision-3D-part.png"><br>式子两边同时叉乘$\pmb{e_z}$并移项化简，得到：<br><img src="https://i.loli.net/2019/10/03/8aeiAUXDIf4Lb9x.png" alt="formula-collision-3D-part2.png"><br>写成分量形式并运算向量积，得到：</p><blockquote><p><img src="https://i.loli.net/2019/10/03/gFZpkHW5nCusXoT.png" alt="formula-collision-3D-part3.png"><br>这就是让球竖直弹回应该满足的条件。可以发现，如果不考虑碰撞过程中摩擦等情况，仅调用碰撞系数，球在下一时刻的弹回方向仅由鼓和球的水平质心速度决定，而且二者速度反向共线。</p></blockquote><h3 id="Problem-⑥"><a href="#Problem-⑥" class="headerlink" title="Problem ⑥"></a>Problem ⑥</h3><p>将上一部分推导的条件写成二维向量的向量表达式：<br><img src="https://i.loli.net/2019/10/04/WuKfHAkLJdUxrZY.png" alt="formula-collision-3D-part4.png"><br>下面推导省去脚标$xy$，向量都是二维向量，$水平合力\pmb{F_{xy}}=\pmb{\sum T}$。<br>将此式子中的$ \pmb{v_d}(i)$作为下一时刻鼓速度$\pmb{v_d}(i+1)$的参考值。移项，可以获得：<br>$E[\pmb{v_d}(i+1)]=-(\frac{\pmb{\sum T(i)}-(m_b+m_d)g\pmb{e_z}}{(1+e)m_d}\Delta t + \frac{m_b-em_d}{(1+e)m_d}\pmb{v_b}(i))$<br>仅采用比例控制PID，则可以拆掉期望运算：<br>$\pmb{v_d}(i+1)=-\pmb{K_{pf}}(\frac{\pmb{\sum T(i)}-(m_b+m_d)g\pmb{e_z}}{(1+e)m_d}\Delta t + \frac{m_b-em_d}{(1+e)m_d}\pmb{v_b}(i))$<br>其中$\pmb{K_{pf}}=diag(k_{fx},k_{fy})$<br>结合冲量定理：$m_d\pmb{v_d}(i+1)-m_d\pmb{v_d}(i)=\pmb{\sum T(i)}\Delta t$<br>令$\lambda=(em_d-m_b)/\Delta t$，再参考连续性并化简上式可以得到：</p><blockquote><p>$\pmb{F_{xy}}(i)=\pmb{\sum T(i)}=diag(\frac{\lambda k_{fx}-1}{1+k_{fx}},\frac{\lambda k_{fy}-1}{1+k_{fy}})\pmb{v_b}(i)$<br>这就是迎接球使其竖直弹回需要设定的下一时刻水平合力迭代公式<br>细心的小伙伴会发现：这个式子和之前问题②的迭代式子打架了，不过没关系，我们使用分段PID，在判断球快要碰撞时才采用此表达式。</p></blockquote><h2 id="Results-3D-movement"><a href="#Results-3D-movement" class="headerlink" title="Results: 3D movement"></a>Results: 3D movement</h2><p>先上效果图：<img src="https://i.loli.net/2019/10/04/2lUHrf6sEc4qu17.gif" alt="3D_system_demonstrate_Compress.gif"><br>如何实现的？之前我们的准备工作已经十分充足了！话不多说，现在只需要把迭代公式列一遍：</p><blockquote><hr><ul><li>Section 0: get several values<br>$d_{ON}=|n_x(x_O-x_Q)+n_y(y_O-y_Q)+n_z(z_O-z_Q)|$ (球到鼓面的距离)<br>set $\pmb{K_{pv}},\pmb{K_{pr}},\pmb{K_{pf}},\epsilon_d,\epsilon_v,\epsilon_{collide}$</li></ul><hr><ul><li>Section 1: set $\pmb{M}(i),\pmb{F}(i), status \quad X$<ul><li>角动量设置<br>$\pmb{S}(i)=J[\pmb{K_{pr}}(\pmb{e_z}-\pmb{n}(i))/\Delta t-\pmb{\omega}(i)\times\pmb{n}(i)]/\Delta t$<br>$\pmb{M}(i)=diag(-S_y(i)/n_z(i),S_x(i)/n_z(i),0)$</li><li>水平合力设置<br>$if \quad d_{ON}&gt;\epsilon_d$ ……(距离较远，鼓追球)<br>$\quad\pmb{F_{xy}}(i)=\pmb{K_{pv}}\pmb{r_{db}}(i)m_d/(\Delta t)^2-\pmb{v_d}(i)m_d/\Delta t $ ……(二维向量)<br>$else$ ……(距离较近，鼓迎球)<br>$\quad\lambda=(em_d-m_b)/\Delta t$<br>$\quad\pmb{F_{xy}}(i)=diag(\frac{\lambda k_{fx}-1}{1+k_{fx}},\frac{\lambda k_{fy}-1}{1+k_{fy}})\pmb{v_b}(i)$…… (二维向量)</li><li>竖直合力设置<br>$F_z(i)=min(F_X(i),T_{lim}(z_d(i)))$,$F_X(i)\in \lbrace F_I,F_{II},F_{III},F_{IV} \rbrace$</li><li>根据第一问的状态机更新状态X(此处略去)</li></ul><hr></li><li>Section 2: physics system<ul><li>rotation<br>$\pmb{\omega}(i+1)=\pmb{\omega}(i)+\pmb{M}(i)\Delta t/J$……(转动定理)<br>$\pmb{\Delta n}(i)=\pmb{n(i)}\times\pmb{\omega}(i)\Delta t$……(角速度造成的法向量瞬时变化量)<br>$\pmb{n}(i+1)=\pmb{n}(i)+\pmb{\Delta n}(i)$……(更新法向量)<br>$\pmb{n}(i+1)=\pmb{n}(i+1)/ | \pmb{n}(i+1) |$……(归一化消除长度误差)<br>$\pmb{R_k^o}(i+1)=\pmb{R}(i+1)\pmb{R_k^o}(1)$……(更新鼓的径向,R为旋转矩阵)</li><li>translation<br>drum：<br>$\pmb{f_{d_{air}}}(i) = 0.5 C_d \rho S_d  \pmb{v_d}(i) |\pmb{v_d}(i)|$<br>$m_d \pmb{v_d}(i+1) = (-m_d g\pmb{e_z} + \rho V_d g\pmb{e_z} - \pmb{f_{d_{air}}}(i) + \pmb{F}(i))\Delta t + m_d \pmb{v_d(i)}$<br>$\pmb{r_d}(i+1) = \pmb{r_d}(i) + \pmb{v_d}(i)\Delta t$<br>ball：<br>$\pmb{f_{b_{air}}}(i) = 0.5 C_b \rho S_b  \pmb{v_b}(i) |\pmb{v_b}(i)|$<br>$m_b \pmb{v_b}(i+1) = (-m_b g\pmb{e_z} + \rho V_b g\pmb{e_z} - \pmb{f_{b_{air}}}(i) + m_b \pmb{v_b(i)}$.<br>$\pmb{r_b}(i+1) = \pmb{r_b}(i) + \pmb{v_b}(i)\Delta t$</li><li>collision<br>$if \quad d_{ON}&lt;\epsilon_{collide}$<br>$\quad\pmb{P}(i)=m_{b} \pmb{v_b}(i)+m_{d} \pmb{v_d}(i) $<br>$\quad I(i)=\pmb{F}(i) \Delta t-\left(m_{b}+m_{d}\right) g \Delta t \pmb{e_z} $<br>$\quad$<img src="https://i.loli.net/2019/10/03/qQ1dcMPTu6bwEUt.png" alt="formula-collision-3D.png"><br>$\quad\pmb{\omega}(i+1)=\pmb{\omega}(i)+\pmb{r_{db}}(i)\times m_b(\pmb{v_b}(i)-\pmb{v_b}(i+1))$</li></ul></li></ul><hr><ul><li>Section 3: judge system<br>$if \quad d_{ON}&lt;\epsilon_{collide}$……(接不到球)<br>$\quad if \quad (x_d-x_b)^2+(y_d-y_b)^2&gt;R_d^2$……(简单化处理)<br>$\quad\quad fail=2$<br>$if \quad v_b(i)&lt;\epsilon_{v}$……(球达到最高)<br>$\quad if \quad d_{ON}&lt;0.4$……(球太低的判负)<br>$\quad\quad fail=1$</li></ul></blockquote><h2 id="Implementation-solve-Q4-partially"><a href="#Implementation-solve-Q4-partially" class="headerlink" title="Implementation: solve Q4 partially"></a>Implementation: solve Q4 partially</h2><blockquote><p>Q4: 当鼓面发生倾斜时，球跳动方向不再竖直，于是需要队员调整拉绳策略。假设人数为10，绳长为2m，球的反弹高度为60cm，相对于竖直方向产生1度的倾斜角度，且倾斜方向在水平面的投影指向某两位队员之间，与这两位队员的夹角之比为1:2。为了将球调整为竖直状态弹跳，请给出在可精确控制条件下所有队员的发力时机及力度，并分析在现实情形中这种调整策略的实施效果。</p></blockquote><p>初始条件，按照我们的解读刻画如下：<br><img src="https://i.loli.net/2019/10/04/6N8FTysDujeWCk5.png" alt="Q4_init.png"><br>$\pmb{r_b}(1) =\left(\cos \left(\left(\frac{2 \pi}{N}\right)(k-1)+\frac{2 \pi}{3 N}\right) x, \sin \left(\left(\frac{2 \pi}{N}\right)(k-1)+\frac{2 \pi}{3 N}\right) x, \Delta H\right)$<br>$\pmb{v_b}(1) =\left(\cos \left(\left(\frac{2 \pi}{N}\right)(k-1)+\frac{2 \pi}{3 N}\right) v_{x O y}, \sin \left(\left(\frac{2 \pi}{N}\right)(k-1)+\frac{2 \pi}{3 N}\right) v_{x O y}, 0\right)$</p><p>代入初始条件，依然按照目标规划搜索三组比例系数，z方向直接调用第一问的最优结果(我们跑了很多次，由于搜索时间实在太长，每次都没跑完，所以在这里只取一个有代表性的来演示，论文中用的另一个结果)，得到第四问的决策结果和游戏过程：<br><img src="https://i.loli.net/2019/10/04/3bW2OXLGtzsAx7U.png" alt="Q4_ans3.png"><img src="https://i.loli.net/2019/10/04/9bJFkRmcHQDAEIL.png" alt="Q4_ans1.png"><img src="https://i.loli.net/2019/10/04/fhG7N3bdavXVLtH.png" alt="Q4_ans2.png"></p><h1 id="Complete-the-system"><a href="#Complete-the-system" class="headerlink" title="Complete the system"></a>Complete the system</h1><h2 id="Solve-problem-⑦"><a href="#Solve-problem-⑦" class="headerlink" title="Solve problem ⑦"></a>Solve problem ⑦</h2><p>这个问题是本队翔哥解决的，在这里直接贴出来原汁原味的总结：<br><img src="https://i.loli.net/2019/10/04/PzwODfaCUV4nMeh.png" alt="problem7_summary.png"><br>按照这个规则分解以后，代入问题4的初始条件，出来结果是这样子：<br><img src="https://i.loli.net/2019/10/04/TwVOfL2Zgx4mhSc.png" alt="Q4_ans4.png"><img src="https://i.loli.net/2019/10/04/NhzecI2pO86jMS9.png" alt="Q4_ans5.png"></p><h2 id="System-Summary-and-Robustness-Analysis"><a href="#System-Summary-and-Robustness-Analysis" class="headerlink" title="System Summary and Robustness Analysis"></a>System Summary and Robustness Analysis</h2><p><img src="https://i.loli.net/2019/10/04/TQUHp4E9myc3k5a.png" alt="system.png"><br>可以看到，大部分我们已经做完，就差最后一个验证了。计算接近度，我们使用的是相关系数。将上面搞出来的分力合成以后再次代入系统，发现：原来设定25000步，运行了11584步就输掉了。大概是因为重新合成的力没有引入反馈吧，误差会累计。不过结果已经相当不错了。<br>计算一下接近度（标注part的是只算了11584步的接近度）<br><img src="https://i.loli.net/2019/10/04/5xljGHzE2dRwisa.png" alt="close_ofe.png"><br>发现即使力非常接近（都是1），运行轨迹也不是很接近。反馈的重要性可见一斑了。</p><p>一个遗憾：时间和能力有限，我们没有做分力代入系统的实时反馈以及考虑了力矩的合力分解。</p><p>啊写了好多！鲁棒性分析就贴图好了。<br><img src="https://i.loli.net/2019/10/04/DVPKA4tYnduq1JI.png" alt="e_sensitive_1.png"><img src="https://i.loli.net/2019/10/04/8Rf7GXJchDY3Vxe.png" alt="e_sensitive_2.png"><br>结果是：系统至少可以支持碰撞系数0.68&lt;e&lt;0.99的变化，在此区间内可以无限颠球。</p><h1 id="At-last"><a href="#At-last" class="headerlink" title="At last"></a>At last</h1><p>先写到这里吧，期间有许多细节也略过了，毕竟要总结的东西特别多，要抓住重点。</p><p>总觉得这次数学建模以后，<del>我就可以去游戏公司开发3D游戏了！</del><br>其实自己写出仿真程序还是很爽的，体验了一把决定论哲学下的上帝视角！今后用到控制、用到三维世界描述的时候，也会更加得心应手。</p><p>数学建模还是很占精力的，尤其是当你不是为了划水得奖而是认认真真研究问题的时候。不过闹了半天，我也没有用上什么特别先进特别现代的算法，也没用上什么近代的数学知识。不过也不要好高骛远，慢慢成长慢慢来，时间可以填补知识空白。</p><p>祝大家学业有成，参加数模的小伙伴遇到自己心仪的问题，有志于科研的小伙伴遇到自己心仪的课题（祝我自己）！</p><h1 id="2019数学建模系列传送门"><a href="#2019数学建模系列传送门" class="headerlink" title="2019数学建模系列传送门"></a>2019数学建模系列传送门</h1><ul><li><a href="https://lucainiaoge.github.io/2019/09/15/math-modling-2019CUMCM-summary-1/">2019数学建模国赛总结 Part 1 (2019 CUMCM Summary)</a></li><li><a href="https://lucainiaoge.github.io/2019/09/15/math-modling-2019CUMCM-summary-2/">2019数学建模国赛总结 Part 2 (2019 CUMCM Summary)</a></li><li><a href="https://lucainiaoge.github.io/2019/09/15/math-modling-2019CUMCM-summary-3/">2019数学建模国赛总结 Part 3 (2019 CUMCM Summary)</a></li><li><a href="https://lucainiaoge.github.io/2019/09/15/math-modling-2019CUMCM-summary-4/">2019数学建模国赛总结 Part 4 (2019 CUMCM Summary)</a></li><li><a href="https://lucainiaoge.github.io/2019/09/29/math-modling-2019CUMCM-answer-1/">2019数模国赛B题解析Part1(Analysis of 2019CUMCM Question-B Part1)</a></li><li><a href="https://lucainiaoge.github.io/2019/10/02/math-modling-2019CUMCM-answer-2/">2019数模国赛B题解析Part2(Analysis of 2019CUMCM Question-B Part2)</a></li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;strong&gt;by lucainiaoge&lt;/strong&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;这篇文章讲解2019年数学建模国赛B题的求解历程。这是第二篇。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;基础知识required：运动学和牛顿力学，空间向量的概念，最好有点反馈控制的知识（没有也行）&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    
    <category term="math" scheme="https://lucainiaoge.github.io.git/tags/math/"/>
    
    <category term="math_moding" scheme="https://lucainiaoge.github.io.git/tags/math-moding/"/>
    
    <category term="MATLAB" scheme="https://lucainiaoge.github.io.git/tags/MATLAB/"/>
    
    <category term="physics" scheme="https://lucainiaoge.github.io.git/tags/physics/"/>
    
    <category term="simulation" scheme="https://lucainiaoge.github.io.git/tags/simulation/"/>
    
  </entry>
  
</feed>
